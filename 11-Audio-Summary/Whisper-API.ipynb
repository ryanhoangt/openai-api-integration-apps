{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0c70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from decouple import Config, RepositoryEnv\n",
    "config = Config(RepositoryEnv(\"/workspaces/openai-api-integration-apps/.env\"))\n",
    "\n",
    "openai.api_key = config(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48852b3",
   "metadata": {},
   "source": [
    "## Lec01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24907697",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = open(\"./11-Audio-Summary/audio/0m-25m.m4a\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3310f97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好了 同学们好 我是李悦 这学期呢 我和谭天老师呢 一同为大家上这门软件分析的课程 这是我们真正正式上课的 面对自己的学生 是第一次 那么第一次呢 就遇到了网课 所以我很有压力 感觉备课还算比较认真 还在备当中 但是上下效果 或者是有些东西讲得不清楚 如果同学们感觉有东西听不清楚 请及时反馈 我好积极感受 好吧 我简单的介绍一下 我们 我和谭天呢是 去年九月中下旬 我们就在 去年九月中下旬加入了南京大学 计算机科学与技术系 我是南大计算机科学与技术系的副教授 那谭天老师是助理教授 那么我们在十月 去年的十月成立了 程序设计语言与静态分析研究组 只是我们的一个简单介绍 好吧 那么 从第二页开始 我们就开始用英文的课件了 这个 因为很多术语 还是说英文比较方便 而且呢毕竟是一个国际的课程 International这么一个 一个课 所以说采用英文的课件 但是我会拿中文说 这里面强调一点的是 如果我在上课的时候 会中英文切换 大家不要介意 我尽量去克服 我觉得这个切换 这个是一个主要原因是 这个 就是英文的课件嘛 然后看到一些词就 不忍心 不注意就读出来了 然后还有一个主要原因就是 有一些专业的词 我也不知道它中文的 真正的精确的翻译是什么 怕给大家带来误导 所以说还是用英文的说比较好 好吧 这门课程叫 英文名词Static Program Analysis 我们都以后简称Static Analysis 就叫静态分析 但是我们现在说是软件分析 这是中文名 一个最主要的原因是 怕如果我写了这个静态程序分析 很多选课的同学 感觉很怪的一个名字 就不敢选了 所以说叫软件分析 听起来大气一点 实际上我们都是来讲 静态程序分析的 我现在感觉有点虚 主要原因是 没有人说话 我是不是掉线了 你们提醒一下我 如果掉线 你也提醒不了我 就是偶尔来一个反馈 好吧 我怕我掉线了 好 那么我们今天讲的是Introduction 讲简单点内容 Introduction讲什么呢 主要是讲 我们为什么学这门课 我个人感觉还很重要 然后学这个课 对你毕业了 有什么帮助 对你以后有什么帮助 对你理解 整个计算机课程 尤其是在程序设计语言方面 又有什么帮助 然后我们会讲一讲 静态分析到底是什么东西 我们如何从整体上 概念上来把握静态分析 比如说有同学说 就讲第一节课听一听 那么我希望你也别白来这两个小时 你听完第一节课 我也希望你从一个整体上 用一句话 能够了解清楚静态分析是什么 这我们都会讲 然后我们会接着讲technical 也就是技术上的 我们怎么从至顶上下 一个高无见龄的 给静态分析的技术上 建立一个核心的体系 进行一个简单的介绍 这样大家在后续的课程的学习当中 你就会像填八股文一样 你会把你学到的一些细节的算法 概念都填到这些 技术上的核心框架里 这都是我们今天要简单涉及到 那么然后我们还会讲 这门课程设置 我们的教学计划是什么 我们每一节课讲什么内容 不同节课之间的 衔接的关系是什么 然后相应的配套的作业是什么 整个课程的评价体系是什么 也就是你怎么得分 这都是大家比较关心的问题 那么现在我们就正式来讲解 好吧 今天也会讲具体内容 会讲一些 那么在讲之前呢 我简单介绍一下 这门课程的主讲教室 我和谭天老师 实际上呢 我和谭天不仅仅是同事的关系 也是非常非常要好的朋友 我们俩现在认识了已经快有十年了 应该是十年了 那么我20 我们俩都是西北工业大学本科毕业 我2010年在西工大 做研一的硕士的时候呢 谭天是大三 我当时是他的助教 然后我发现谭天能力非常强 所以我在研二的时候 就带着他一起去科研 对对对 我比他大三岁 他是大二 那时候研一是大二 然后呢我带着他一起去科研 然后我一二年之后 硕士毕业之后 就去了澳大利亚的新南威尔市 这个读博士 然后他2013年 一年后呢 谭天也来到同一个地方去读博士 所以说我们在 我在悉尼待了五年 谭天在悉尼待了四年 然后我们毕业之后呢 又一起去了丹麦的 阿尔胡斯大学的程序设计语言 与这个研究组 做了两年的博士后 然后这个19年 2月份我们一起回了国 然后我们当时就想着这个 这个 由于这个事业上 想搭一个伙伴 因为自从到合 我们俩做起科研来 非常的怎么说呢 默契 非常非常的默契 所以就一直想 最后决定一起回国 然后选择咱们南京大学 计算机科学技术系 希望回国之后 能为咱们国家的计算 这个计算机学科里面的 程序设计语言方向 培养更多的人才 也就是在座的各位 好吧 那么这就是关于这门课的 两位主讲教师的background 我怕很多同学好奇 我就提前讲一下 好吧 这门课程 我们来看一下 我们讲什么 第一节课 我每节课之前 都会有一个这样的目录 那么第一节课 首先我们来讲一下PL是什么 因为我和谭靖老师的研究方向 就是程序设计语言 PL 那么静态分析和PL之间 是什么关系 实际上它是一种 从属的关系 因为静态分析要涉及到 一个语言的语法语义 以及它的类型系统 所以说它是一个从属关系 那具体什么关系 那么我们来 后面继续来看 好吧 那么讲完第一部分 我们第二部分讲 为什么要学习静态分析 听起来这个名字有点怪 那么我为什么学习它 然后呢 第三部分我们讲 到底什么是静态分析 整体上从概念上 怎么把握静态分析 那第四部分我们就讲 静态分析的一些关键的特征 我们并且 用一些例子 来逐一的介绍这些特征 通过这些特征 技术关键点去理解静态分析 然后呢 我们就来讲我们的教学计划 最后我们来看 这整个课程的评价体系 就是大家的得分 我们怎么来算 好吧 这是这一门课的 今天这节课的一个提纲 好 我们开始讲静态分析 那programming languages PL 就像有同学说的 国内之前研究PL的很少 我想说 现在也很少 那么PL实际上它有 60来年的这个研究的历史 如今呢 在国际上 它也是一个非常活跃 而且研究的人还蛮多 当然没有其他的领域多了 因为它有一个门槛 难度比较高 所以说 但是还是有很多活跃的人在研究 尤其是在国际上 一些顶尖的高校 可以这么说 就是说排名世界 真正是前50的那种高校 顶级的高校 但凡它的计算机学科 比较大 有一定规模 它都会有搞PL的人 那么也是 讲解相应的编程语言的课程 那么相比较而言呢 我们国内呢 PL的人才呢 特别特别的少 那么南大同学属于幸运的 因为像我们国内顶尖的PL的教师 比如说冯新宇老师 梁洪锦老师 都是我们南大的老师 那么我和谭天呢 也是这个国外结束7年 这个学术生活之后呢 我们也属于PL的吧 那这个也加入咱们南大 这是PL的一个大的背景好吧 那么我个人倾向于 将PL分为三个部分 分别是理论部分 环境部分 那么还有应用部分 这三个部分啊 大家读到这里面 有的同学 如果你上知乎 你可能看到知乎的某个人 他在写关于PL的文章 分析的文章 他提到过 好像跟我这里面那个 写的结构很相像 因为他是中文写的 我只不是英文 但是在这里面 要提醒大家一下 这个课程设置 是我谭天老师共同完成的 整个设置 包括具体内容 可以说 课间里面的所有的东西 98%以上 都是我们自己原创的 好吧 就是说我们自己去做的 那如果你发现这个 和知乎上的某个人 写的东西很像 你可以大胆的想象一下 也许写那个东西的人 就是我 这里我就不多说了 咱们继续来讲 这个理论部分 理论部分 那它当然涉及到一些 我怎么设计一个语言 对吧 关于language的design 然后这个语言的 类型系统是什么 它的形式语义是什么 有同学提到过 梁洪剑老师上就是形式语义 是吧 程序逻辑是什么等等 那么整个这方面是关于 我怎么样构建出来一个语言 那么构建出一个语言之后 大家想一想 如果我这个语言设计起来 我得让它跑起来 用起来 对吧 所以就有一套相应的支撑 这个语言运行的一套系统 我们称为environment 好吧 那么这套环境系统 比如说 把这个语言语法解析了 把人写的高级语言 编译成字节码 这都是编译来做的事情 那编译成字节码之后 比如说有很多语言 虚拟机上 比如Java之类的 Python 它都需要一个运行式系统 Runtime System 来让这个语言 保证它能运行起来 这里面涉及到一些内存分配 是吧 管理等等 好了 有了支撑系统 有一个语言 基本上这个语言 从设计到实现到运行都可以了 但是 语言本身是一个非常复杂的系统 我们如何能保证这套系统 它是可靠的 它是安全的 它运行起来 别太慢 等等 这些都属于 程序设计语言里面应用部分 要做的事情 应用里面包含 程序分析 也就是我们今天要讲的部分 我们在语言的框架下 谈到程序分析 指的就是静态程序分析 也就是我们这门课要学的 也包括程序验证 程序合成等等 这都属于应用部分 程序合成就相当于说 你怎么自动生成一个程序 那么实际上 程序验证的很多知识 程序分析都会讲 好吧 这是关于静态分析的一个大背景 它属于语言分支里面的 我个人倾向 它分类是它属于语言分支里面的 application应用下的 一个非常重要核心的一个研究内容 是程序分析 大家如果看到有一些 实际上有些老师的 他都会写他的interest是程序分析 但是一般 从软功能角度来看 程序分析指的 很多人是搞的是动态分析 但是我们从PL的角度来讲 这个分析指的是静态分析 我这个PPT会放出来 会给大家放出来的 好吧 我们PL角度来讲 这个程序分析都是静态分析 好吧 那好了 我们现在有这样一个 PL的一个知识体 整个的一个结构 那么我们接下来就要看一看 这个结构理解之后 我们再看看 这个整个PL的历史发展 对于学习静态分析 它作为PL当中 一个非常重要的分支 在如今这些年来 为什么这么重要 我们来分析一下原因 好吧 那是因为过去啊 这十多年当中 尤其是过去的这十多年 也就是大概是从 2001年往后吧 这将近20年的时间 好吧 实际上语言的内核 这么多年 实际上变得非常的小 你可以看到很多语言的出现 琳琅满目的 但是真正语言的核心的部分 我们说为这个 Core of language 它没有太大的变化 语言到现在 也无非分为三类 第一类 Imperative languages 也就是我们说的命令式变成语言 大家平时在课堂学的 Java C++ C等等 这都是命令式变成语言 就是一条一条的指令执行下来 按照就是你命令嘛 你命令它执行第一条 第二条第三条 它把语句一点点拆解 它把逻辑拆解成一个个指令 就像这个字解码一样 就像这个 有的人说这个冯诺依曼体系是吧 就相当于汇编式的 你告诉他 有一个指令 然后在内存里面去执行 加载到内存上执行 一条一条去执行 命令式变成语言 那么还有第二种语言 是函数式语言 Functional languages 那么像Haskell 对吧 还有这个 实际上Javascript 这种命令式语言 它是命令式和函数式相结合的 像Python 都有支持这个functional programming 那functional实际上 它就是把逻辑呢 就是包装起来 形式化了 这个函数本身也是一些 也是一种数据类型 这个就细节我们这两天不讲了 就概括一下 第三种语言呢 第三种类别是逻辑式语言 Logic programming 实际上我们这个课程 在最后课程设计 我们会讲一点 用逻辑语言去编写静态分析器 逻辑语言 其实比如说很简单 逻辑语言介绍一下概念 大概就是说 我们这门课程 现在整个咱们群里的 软件分析这门课程里面的 所有人 男性 再加上且 这个人岁数要大于28的 我估计最后出来两个结果 就是我和谭天老师 好吧 就是像声明逻辑嘛 一条条逻辑声明出来 它也叫Declarative 就是声明式语言 那通过逻辑的与或非 那声明 然后呢把与或非 这些逻辑操作做好之后呢 最后出一些结果 这是关于声明式逻辑的 这个编程语言 那就这三类语言 好了 有了 这三类语言 我们可以看到 实际上这核心的过去的 十几年来并没有变化 但是语言的核心没有变 什么变了呢 语用环境变了 什么叫语用环境变了 也就是说语言 你想想语言没有变 但是拿语言写的软件 程序变得越来越复杂 越来越大 为什么呢 因为需求越来越多 现在各行各业 你现在买个菜都能扫微信 对吧 各行各业 金融啊 这包括小的行业 那么大的到什么卫星啊等等 航天 这些东西里面都会用软件 对吧 那么随着业务需求的 慢慢复杂 软件会变得越来越复杂 越来越大 那么我们就带来了一个新的挑战 注意到这里面写新的挑战 写的是 How to ensure the reliability security and other promises of large scale and complex programs 这里面提到就是 那么你语言没变 但是你语言写的程序变得大了 又复杂了 那我们保证这种大的复杂的软件呢 它的可靠性安全性和其他性能啊 就变成了新的 在过去的十几年当中新的挑战 这也就是为什么 这个应用部分 在过去的十几年当中 变得越来越重要 越来越重要 越来越重要 所以说Program Analysis 作为应用里面最重要的分支之一 它的用户质地 在过去的十多年当中 越来越多 好吧 这就是整个PL和静态分析的相关的一个背景 也点出了我们历史上说 为什么最近十几年当中 静态分析作为PL的一个应用 变得越来越重要 这是第一个slide要说的事情 好吧 那么好了 我们说完说它很重要 那么具体来看看 我们为什么需要它 为什么重要 首先我们前面说到 说静态分析呢 对保证提高程序的可靠性非常有帮助 那么举个随便举个简单的例子 比如说non-pointer dereference 就是一个空指针应用 我们知道 你这程序里面如果有variable 出自这个这个 你去dereference 就是说你用它的时候 但是它没有define 那么就空指针异常了嘛 空指针异常会带来很多bug对吧 程序崩溃了 这属于对程序的可靠性造成的影响 还有memory leak 比如说你c 你买lock一个东西 你没有free掉 你想想如果你买lock多了 你的内存还是有限的 受控的一个系统 比如说嵌入式的系统 你买lock一堆最后没有free掉 那最后你内存被占满了 你就程序运行不下去了 也崩掉了 这都是跟程序的可靠性相关的 那么静态分析可以帮助检测到这些 引起可靠性的bug 那么是对可靠性有用的 那相应的它对程序的安全性也有帮助 比如说private information leak 那属于私有信息的泄露 比如说你现在安卓里面 你去输入自己的账号密码 银行密码等等 那如果不加保护 你现在想这个应用你输入进去之后 被另一个应用通过中间平台劫持了 这个你的密码信息通过另一个应用 从后台又盗取了 这些东西静态分析能帮助检测到 Injection attack 这是另一种security问题 安全问题 比如说我们现在有个网页 你在网页里面浏览器里面 输入网页里面输入 咱们都是正常人好吗 好人 我们不是黑客 所以说如果是好人的话 你正常说这个输入你的用户名密码 你的年龄 你的出生地 但是黑客他可能会输什么 他会输一段命令 叫Injection 这个Injection attack 输入一段命令 这个命令可能是 这个命令就是比如说 它设计的巧妙一点 它可以绕过服务器里面的一些杀核 或者是隔离的机制 比如说我准备删除 当前目录下所在文件 所在目录所有文件 或者是某个文件 这个东西跑到了服务器上 那是不是就是 删除了服务器里面的某一个文件 那不就把服务器attack攻击到吗 这属于Injection attack 这些东西 都是可以通过静态分析来 静态检验出来 等会我们会讲什么叫静态检验 实际上这里面简单提一句 静态分析 实际上就是在你运行程序之前 静态室在编译时刻 完成所有的安全和可靠性的一项检验 也就是说我不用运行你的程序 我只要分析 静态时候分析你的程序 我就能检测出前面提到的 reliability security 所有这些问题 这是前两个 那它还有什么应用呢 编译优化 这些同学肯定很听过了 编译优化是编译后端非常高级的部分 也就是说我可以让你程序 你这些写成一个狗屎 最后它会运行的非常的快 比如说你用-O1-O2甚至-O3 去优化一个程序 比如前面可能运行一个小时 后面可能运行只有20分钟 前面你自己写程序运行一分钟 后面甚至优化之后 可能两秒就出来了 这是编译优化 大部分的编译优化很多 我们不说JIT那种 这种online的这种优化先不说 就大部分的静态优化 用的都是静态分析技术 很简单的意思 比如说Dead Code Elimination 什么意思呢 Dead Code死代码 你这个code写在那里 但是它总也不被调到 就是死代码 那当然它要被删除了 要不然是占资源 Code Motion 比如说你写一个负循环 你偏偏把一个int i 等于比如说2乘以10的六十方 这么一句话 这个写在那个负循环的里面 你每次循环都要重新计算 这个i值 对吧 那每次都要消耗资源 对吧 那你把这个code 把这个int i 这个定义 这句话放在一个 负循环的外面 初始化一次就可以了 是吧 那这样你循环就没 不用每次编译的时候 都要执行它 那是属于Code Motion 等等 有非常非常多的优化 好吧 那么这也是静态分析干的事 好吧 那静态分析还对什么有用呢 比如说Program Understanding 理解一个程序 比如说 你现在上一个企业里面了 然后呢 你想了解这个企业里面 以前的它的内部的一个软件 好了 一头雾水 这个人前面可能刚离职 那你需要用IDE吧 打开这个工具 去帮助你理解 比如说你见到一个code 你想知道这个function code 这个函数调用 它是被哪些方法调到的 它又会调到哪些方法 这些IDE都会有提示 它怎么提示的 实际上很多IDE提示 是通过静态分析技术来完成的 它不用运行程式 你只要把鼠标放在那上 它就会提示你一些类型信息 包括这些调用关系等等 这就是静态分析要干的事情 比如说还有type indication等等 那么从可靠性安全性 编译优化 编译优化是为了性能 也就是程序的性能 还要理解一个程序等等 还有其他还有debug 调试程序等等 其实静态分析都可以帮助他们 这就是我们为什么要学习静态分析 好吧 具体的东西 我们等一会儿有时间时候再讨论 好吧 比如说这个同学问的 死代码里会触发异常 比如初零可以优化吗 你死代码里面 如果你能识别出来死代码 你就把它eliminate掉了 所以运行时就不会触发 任何死代码里面的异常 好吧 好了 那么我们说它 这确实有帮助 对很多应用 但是静态分析是市场什么 我们说点功利的东西 这可能有一部分同学是很感兴趣 就说我学到这个东西 我到底毕业了能干什么 那么咱们就谈点跟钱有关的东西 我们先说industry工业界 我这里列出的所有的大公司 但是我先说大公司 因为事物的发展就是这样 尤其是软件方面 就是很多国外先进的大公司 它先重视 然后它发现这个东西不重视不行了 它要损失钱 它损失安全性 它损失它的信誉 损失它的市场 所以说它要找一批人 来开始做这方面的事情 然后大公司国外慢慢跟进之后 中国的新的 中国里面像大公司 像华为这样的公司 阿里巴巴这样的公司也跟着跟进 然后再轮到一些公司的 中国的一些再中等的公司 再小的公司 就是这样一个发展的一个进程 那么在工业界 用这里面列入的所有的公司 比如说macrosoft oracle  IBM 谷歌等等 他们都有自己软件分析的团队 就是用静态分析 去分析本公司代码的 可靠性 安全性 性能 OK 那么国内现在 是华为像阿里巴巴 这种顶尖的软件的 就是有软件方面的这样大公司 也在 也开始用静态分析技术 来分析本公司 主要是在他们研发部门 因为毕竟属于这门槛比较高 属于高级技术 那么人才还非常少 所以他们也在挖各种 国内的静态分析的人才 加入他们的研发部门 那么这里面还列到一些公司 比如说 Grammar Tech CML 还有Sourcebrite 这都是专门因为静态分析技术 而成立的公司 它就是靠静态分析发家的 它就是为这些大的公司'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b4d94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_2 = open(\"./11-Audio-Summary/audio/25m-50m.m4a\", \"rb\")\n",
    "translation_2 = openai.Audio.translate(\"whisper-1\", audio_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6b02d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "or a large company with a software analysis team. If they have money and support a software analysis team, they will have it. If they don't have a software analysis team, they can't afford such people and don't have so many talents. They have to ensure the reliability and security of their own company's complex software. So they have to find these companies that specialize in static analysis to help analyze their code. How much does it cost to analyze one line or several lines? That's how they sell their products. This is about industry. Academic. A lot of students have graduated, and some of them have chosen to study mathematics. Mathematics and static analysis are also very marketable. For example, what does static analysis analyze? All software. Programmers have this advantage. No matter which field you are in, as long as it is related to the computer industry, you at least have a program. A program has the need for reliability, security, performance, etc. Of course, static analysis technology is needed for a lot of fields. PL, software engineering, systems, security, etc. These fields that rely on programs will have a corresponding static analysis technology. This is what the article said. So it can be said that whether it is academic or industrial, the talents in static analysis are extremely short-term. I can say this very responsibly. Because of our country's current static analysis, how can I say this? There are very few people who teach this course. As far as I know, Mr. Wei from Peking University is teaching this course. We started this course in the first year of Nandan University. We teach static analysis systematically. In the past seven years, Tan Tian and I have been doing this. So there are not many courses that teach systematic, in-depth, and fundamental analysis technology like this. How can I say this? Everything is expensive. If you choose this course, you will also be able to learn some resources that other universities may not be able to learn about static analysis. I would also like to give a few specific examples. These are some examples I have experienced. I will share with you what are the benefits of taking this course. When I was a Ph.D. student in 2013, I did a project with Tan Tian. It was about reflection, a part of static analysis, and a part of fundamental analysis. After that, Oracle, the headquarters of Oracle Australia in Brisbane, invited me to give a lecture. I heard that this technology has a certain breakthrough. Many people in Oracle's department were very interested in static analysis. Of course, reflection analysis was a challenge. At that time, Oracle had a special team for software analysis. They specialized in analysis. Li Lian, a professor and researcher at the Chinese Academy of Sciences, also established his own company about static analysis. He was one of the core members of Oracle Australia. In 2018, Tan Tian and I did a project on static analysis. At that time, the head of the software analysis team and the technical manager of Oracle's headquarters contacted Tan Tian and told him that Oracle also has its own software analysis team and needed such talent. Tan Tian teased me and offered me a very high salary. He wanted me to join his team. Oracle is a big foreign company. In fact, they all need software analysis talent. Let's talk about Huawei. For example, when we went to an interview in 2019, we went to the software office of the Chinese Academy of Sciences to give a speech. It was not a speech, but a report. It was an internal report. Many people didn't know about it. I saw someone whom other people didn't know. When we were talking, I found out that he was a talent that Huawei had just acquired from the US. He was the technical manager of Huawei's new network security and privacy protection laboratory. He found out that we were talking about software analysis technology. He said he needed such talent. I want to use these three examples to tell you that software analysis requires talent. For example, our team was just established in Nanjing. Our team's doctor has already been targeted by Huawei's R&D department. They asked him if he could do an internship and if he could come to their company. I haven't told you the details yet. The market is very open in the software analysis industry. There are many talented people. We are now standing in the right place. There are not many people teaching this course. If you are really interested in this course and want to learn some knowledge, I hope you will study hard. I will try my best to teach. You should study hard. I think it will open a new path for you in the future. That's all about the technical part of this course. That's all. I want to talk about something not so technical. For example, I may not work in the software industry or I may not engage in software analysis technology or I may not join the R&D department. Let's take a look at the added value of this course. I will summarize it in Chinese. I will summarize it in Chinese. In my opinion, there are two benefits of learning static software analysis in depth. First, the knowledge we learn can help us better understand the grammar and meaning of programming languages. What does it mean? If we want to analyze a program, we must analyze it based on the grammar and meaning of a language. The meaning of a language represents a kind of behavior when running. These things are abstracted in a formalized way. How do we understand them? The understanding of the language is a kind of deepening. We will talk about the type system later. Second, we use static analysis to design algorithms to analyze the reliability, safety, and performance of a program. Of course, when you see a code, you will know that the program will run slowly if you write it in this way. If you write it in this way, it will be unreliable and may have a bug. You will know it because you write it and analyze it strictly. These algorithms are self-cultivation of a high-level program. Since we are talking about this, as a teacher, I will say a few more words. All of you here are students of Nanjing University. You are the top students of Nanjing University in the past years. I believe that according to my experience, not every student still has that kind of impetus. Today's society is very complicated. After graduation, many people compare whether they can find a good job, whether their annual salary is higher than that of their classmates, whether they can afford to pay the down payment, whether they can buy a house, and how they will live in the future. This kind of materialistic social values and environment require a lot of caution. As a college student, a top college student in China, you should have self-consideration. In fact, there is a lesson in life that we often remember, which is to know yourself and discover yourself to see what can make you happy, what can make you willing to spend time and energy to know yourself. It doesn't matter if you don't know it now, but if you don't think about it, you will be left behind. You can be a top student and he can be a top student. You can do this to work overtime. You can have more choices in your life, but you don't. At least since our class, you have chosen such a professional choice class. If you have other students who have participated in such a competition and have such good grades, you feel that you have no advantage after graduation. Don't think too much about it. These things are because you are impatient and willing to compare with others. I hope you start thinking about a question from now on, even if you want to open a milk tea shop and you have chosen this professional choice class. Can you spend some time and energy to tell yourself that as long as I study some professional basic knowledge, I can learn it well. Look at how far you can go in your professional field. From now on, give yourself more choices in your life, including when you open a milk tea shop and when you open a milk tea shop. In fact, I can still learn it well, but I didn't choose to be a programmer in the end. Give yourself an explanation. I hope you can put more effort into it. As a college student, a free-thinking person, you should have your own judgment, your own life, and your own values. This is what I have told you and shared with you through this course. Here, I will use English to summarize. Static analysis analyzes a program P to reason about its behaviors and determines whether it satisfies some properties before running P. This sentence actually conveys a very simple concept, which is marked in red. Before I want to run a program P, I need to understand all the related behaviors, and I need to know whether the properties of these behaviors can be satisfied. In other words, static analysis is you write a program and then analyze it. The program you write is your so-called analyzer. How do you understand these words? Before you run a program, I know some characteristics and I will give you an example. We want to know whether there is a possibility of private information leaks in this program before we run it. We want to know such information. This is what we care about. This is about the security of the program. This is the behavior of the program. If there are some private variables when it is dynamically running, the variables store some private information. In the end, which input can make the information leak? This is the behavior of the program. Static analysis can judge it. For example, whether there is a possibility of an empty fingerprint. Have all the variables in the program been initialized before use? All the cast operations, for example, in Java, you need to have a cast before you can use it. Is this behavior right? For example, two variables v1 and v2 in the program may point to the same address in the memory when it is running. What is the use of this? For example, if you are a mutated program, if these two variables point to the same memory address, it may cause competition. If it causes data competition, there are a lot of big programs in the program that need to be tested. Add some asserts. If you add these asserts, will it fail when it is running in static state? Or as mentioned earlier, is this code a dead code? Can you remove it before running? It can run faster. This is about optimization, etc. It is before running a program in static state to complete such analysis. It can do such static analysis. This is static analysis. Unfortunately, RICE theorem is a theorem called Dummy Theorem. There is no such approach to determine whether p satisfies such non-trivial properties. The static analysis I just mentioned is very good. I can judge it. It is a very old theorem. It says that there is no such approach. It can accurately judge giving exact answer. It can accurately judge giving yes and no. Whether the program satisfies these properties. For example, is there any information leakage in the program? There is no such approach to accurately tell you whether there is or not. There is no such approach to accurately tell you whether there is or not. In other words, this is actually a RICE theorem. It sounds complicated. I will explain it later. It says that any non-trivial property of the behavior of a program in an RE language is innumerable. It says that any non-trivial property of the behavior of a program in an RE language is innumerable. In fact, I was in a breakdown when I read this sentence. It is a non-trivial property of a RE language. It is a non-trivial property of a RE language. It is a non-trivial property of a RE language. It is basically a non-trivial property of a RE language. If you don't understand the sentence, you can look it up in a translation. If the program is written by the non-trivial property of a RE language, the non-trivial property will be incontrovertible. What is non-trivial? It is a very simple concept. It is not that simple. It is important. Let's look at the non-trivial property. It is a very difficult sentence. I will explain it later. First, I will give you a formal explanation. Then I will explain it. What is non-trivial property? A property is trivial if it is not satisfied by any RE language. If it is satisfied by all RE languages, otherwise it is non-trivial. What does it mean? You don't need to understand it. It is non-trivial. It is very simple. All languages have it or don't have it. As long as it is interesting, it is non-trivial. In other words, what is interesting can be further explained. I understand that this property is related to runtime behaviors. If this property is related to the behavior of your program, we think it is interesting. It is non-trivial. It is non-trivial. It is non-trivial. It is non-trivial. Based on these interpretations, I will give you a definition. I will use very common language to explain this. I saw that many textbooks are very complicated. I need to read a lot of information. I will translate it to you. It means that if you think the dynamic runtime behavior is useful, if you are interested, for example, if you want to give it an exact answer, it is non-trivial. It is non-trivial. It is non-trivial. It is non-trivial. It doesn't matter if you don't understand it. It is not important. It tells us a fact that a perfect static analysis does not exist. I will emphasize it again. What is a perfect static analysis? It is a method that can determine whether a program can satisfy its non-trivial property. whether its non-trivial property can satisfy its non-trivial property. It does not exist. It does not exist. What about a perfect static analysis? It is a method that can determine whether a program can satisfy its non-trivial property. It does not exist. It is a method that can determine whether a program can satisfy its non-trivial property. It does not exist. A perfect static analysis is a method that can determine whether a program can satisfy its non-trivial property. It does not exist. It does not exist. A perfect static analysis is a method that can determine whether a program can satisfy its non-trivial property. It does not exist. Let's take a look at the following diagram. For example, let's look at choose. You can imagine that the circle between choose and choose is a collection. For example, non-pointer is a bug. If your program has 10 non-pointer inputs no matter what path you choose, 10 will be called choose. But what are these 10 inputs? Is there any way to determine whether it is 10 or 11 or 9? All the possible true program behaviors can be determined by choosing. However, it does not exist. It does not exist. It does not exist. What is sound and complete? Sound is a program that has 10 non-pointer inputs. The result of sound is to include all 10 inputs. You can have 10,000, or 11, or 12. In short, no matter how many you have, they are all included. So we call it over-approximation. You can also interpret it this way. It is convenient. In fact, it is an over-approximation. If I were sound, I would include all 10 inputs. Do you understand? Complete is exactly the opposite. Complete means under-approximation. Let's say there are 10 non-pointer inputs in your program. Let's say there are 5, 6, 1, 2, or even none. They are all your non-pointers. As long as I have some, it must be in your initial. In other words, there is no non-pointer in complete. What I have, what I have in complete, must be initial. That is, what I have in complete is not false. What I have in sound is that I can have false. We will discuss this later. You need to understand the relationship between sound and complete. We said that there is no both sound and complete. There is no method that can accurately give such a combination. There is no perfect standardization. Does it mean that there is no perfect standardization? Why did we learn this lesson? Why have people been talking about and studying about the world, but not having perfect standardization? As long as it is useful, the world is not perfect. As long as you can work and it is useful, it is good. We said that since there is no both sound and complete sound and complete, then how can we define useful? There is a simple logic. For example, if I compromise soundness, I can get a useful standardization. What does compromise soundness mean? It means that I will produce a false statement. Or you compromise completeness, you can also produce a useful standardization, but you will produce a false statement. How to understand this sentence? There is a very important concept in this sentence. Let's look at the following example. What does compromise soundness mean? Compromise soundness means that we become incomprehensible. What does it mean? Let's take a look. Incomprehensible means that we reduce the circle and reduce it to this part. For example, if you compromise soundness, then you don't include these things. If you don't include these things, then these things are true, but you don't include them, so you cause a certain leak. There were 10 bugs, but now there are only 5 bugs, so you leak 5. Compromise soundness will also cause a leak. Compromise completeness will also cause a leak. This is also compromise soundness. As long as it is not complete, then it is OK. Let's look at these things outside. There are 10 true and false statements. There are 3 fake statements outside. These 3 bugs are actually fake. Because all the real bugs are here. These 3 fake statements are called false positives. This is a leak and a false statement. You may think it is so complicated. The use of static analysis is either compromise soundness or compromise completeness. Compromise soundness will cause a leak. Compromise completeness will cause a leak. Is it so complicated? In fact, it is not necessary. You just need to remember one sentence. That's because in the real program, most of the static analysis is compromise completeness. In other words, we are pursuing sound analysis as much as possible. We don't want compromise soundness. We want compromise completeness. Compromise completeness will cause a leak. In other words, if it is not a bug, then it is not accurate. Although it is sound, it is not accurate. However, this kind of analysis is still a very useful static analysis.\n"
     ]
    }
   ],
   "source": [
    "print(translation_2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f9c7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_3 = open(\"./11-Audio-Summary/audio/50m-75m.m4a\", \"rb\")\n",
    "translation_3 = openai.Audio.translate(\"whisper-1\", audio_file_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "510123a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is it that almost all of the calculations are summed? The compromise is completeness. To achieve a sum, it may not be precise, but it must be summed. Let's go down and see why so many calculations are summed. It's 11 o'clock now. It's been 50 minutes. Let's take a 5-minute break, OK? Can you hear me? I said take a 5-minute break. Take a 5-minute break. Take a 5-minute break. Take a 5-minute break. Take a 5-minute break. Take a 5-minute break. Take a 5-minute break. Take a 5-minute break. Take a 5-minute break. Take a 5-minute break. OK? OK. Let's continue. Take a break. OK. Let's continue. As I mentioned earlier, sum is very important. Basically, all static analysis must ensure that it is summed. Then, the compromise is completeness. That is, it can produce a sum. Right? It can become less accurate. We say this is useful. This is useful static analysis. Most useful things need to be done. Then we have to ask why sumness must be guaranteed. Because sumness, if you simply translate it into Chinese, you can understand it as correct. You think your analysis is correct. If you get the wrong conclusion, then it is sum. For example, sumness is critical to a collection of important static analysis applications, such as compiler optimization and program verification. What this means is sumness is necessary for static analysis applications such as compilation optimization and program verification. In other words, if you don't sum, your optimization is wrong, and verification is the wrong conclusion. So critical is very important. Let's take an example. For example, let's talk about verification. What do I want to verify? Look at the right part. Look at this part first. I created an object called b and gave it the attribute a.field. If we say what type of attribute a.field is, it is type a. Similarly, c used an object, a type c, and gave it the attribute a.field. But because it is type b, it is type c, and because they are the attributes of the a interface, there is no problem. They can be copied. But here, when a.field is used, it casts a type b, and gives it the attribute b. What we want to ask is whether this cast is a safe cast. If your analysis, as we said earlier, let's understand what static analysis means. It means your analysis is sound, which means all the operational behavior of your program, no matter what input it has, and what kind of input it executes, your analysis can be covered, it can be included, and it can be processed. We say this is a sound analysis. If we only analyze such a data stream, let's say this is a code block in a program, and this is another code block, and then analyze it through this convenient program. Now let's say we only analyze such a blue data stream. You can understand sound analysis in a comprehensive way. It may be easier for you to understand than me. It's better. If you only analyze this path, let's take a look at a.field cast b, there is no problem. You say this is a safe cast, but because as the student said, you are not comprehensive, right? You missed it, missed this path, and you came to a conclusion of a safe cast. In fact, it's wrong. Because once there is an input to execute this path, this path goes from c to here, and then cast. If c is a type, like you cast b, and there is no relationship between them, your cast is wrong, right? This is a fail. What will you throw when running? What is abnormal when running? Cast fail exception, right? So if you only analyze one path, not comprehensive, not sound, for example, only analyze the blue one, you will come to a wrong conclusion. This is why in fact, there is a path when running dynamically that can make this cast fail. Fail. Abnormal. Cast. Cast is this. It's equivalent to forcing type conversion, right? Safe cast. You understand it this way. Safe cast is my conclusion. I say you are safe. In fact, what I want to ask is if this cast is safe. Yes, it is type conversion. Is this cast safe? Then you only analyze a part of the path, which is not sound analysis. If you only consider the blue path, then you will say it is safe. Because it is normal that B is cast as B. You are right. In fact, you should consider all the paths, blue and green. So you will say OK. If you consider all of them, you will say it is not sound. Right? If it is not sound, sorry, you will say it is not safe. In other words, because there is a type C, if you want to cast B, it is not safe. Right? So you will get a correct conclusion. In fact, it is not safe. Okay? So this is why we say sound analysis is needed for verification and optimization. This is a simple example. This is a verification example. You verify if this cast is safe. You say this type conversion is not safe. Then this is the correct conclusion. But if you only cover the analysis, only cover a blue path, you will say it is safe. In fact, this is a mistake. So, this is why for some applications, sound analysis is very important. Because after it is comprehensive, you can get a correct analysis conclusion. Okay? Some applications sound analysis is necessary. If you make a mistake, you will get a wrong conclusion. However, the better you are at it, the better. For example, sound analysis is better than light analysis for almost all other analysis. The better sound analysis is, the better the result. Why? For example, okay, bug detection is a tool to detect a bug. There are a total of 10 bugs. For example, if you say there are only 2 errors in this program, and you miss 8, what if the bug is triggered when the program is running? Will the program crash? However, if you tell it there are 12 bugs in this program, including sound, although there are 2 errors, you can detect at least 8 bugs and the program will run safely. Right? There will be no impact on reliability. So, in general, sound analysis is guaranteed for all programs. However, there are some advanced analysis, such as optimization and verification, which are necessary. Otherwise, you will give some wrong conclusions. This thing is just that all the things in the first class are just points. We will have a lot of courses and other specific knowledge to assist and further help understanding. Okay? Sound. All advanced analysis are guaranteed sound and can sacrifice accuracy. Because there is a lot of things I want to say in this presentation. Okay. What are we going to say in this page? We are going to talk about a general concept. Can we use one sentence to summarize static analysis and grasp static analysis from the concept? Basically, we need to explain it clearly. Is there a sentence that I often use in this example? Because I have been thinking about this example for a long time. I want to make it as simple as possible so I call it bird's-eye view. It means we can see everything from a bird's eye view. It is a general overview. Can we use one sentence to summarize static analysis? I will give you a simple example. There is a very simple program. On the left, you can see a branch. It says if input equals true, x equals 1. Otherwise, x equals 0. Okay. What is static analysis? I said this program is satisfied with some properties. For example, I want to judge for this example that at this point in static analysis, I will give a conclusion. I said x equals what? What does x equal in static analysis? I can have many conclusions. I will list two simple conclusions here. The first conclusion is when input is true, x equals 1. When input is false, x equals 0. Now, I will start to ask questions. Which of these two conclusions do you think is correct? Come on, leave a comment. Is the first conclusion correct or the second one? No one answers. Okay. Okay. Okay, that's it. Both of these conclusions are correct. They are all correct. You must understand this well in order to master the simplest in static analysis. However, it is the easiest thing for a beginner to judge wrongly. Because we usually make it a kind of dynamic thinking. What does it mean? It means that you have to follow the program to debug. Right? It is a kind of dynamic thinking. It is very difficult to break this dynamic thinking. It is static. I just need to give a conclusion. I don't need to run the program. I can analyze all the behaviors when running in advance. This is what static does. We need to create a kind of static thinking. It is correct. Because static means x is the input at this point. It is true that x is equal to 1, but the input is false. You can say that if you read the program well, you can get this conclusion. It is correct. If the program is written like this, there are only two ways to input. Either 1 or 0. You have considered both. Your conclusion is correct. It is sound. From the perspective of static analysis, it is sound. Why? Because the program is either 1 or 0. If you say all the possible results of the two programs in the static analysis, your conclusion is also correct. Because it is sound. It includes all the correct behaviors. In other words, if you say your program I am asking now. Answer the question. I have the third conclusion. x at this point is equal to 1 equals 0 equals 3,4,5,6,7,8,9,10. Is this correct? Answer the question. I have the third conclusion. The result of static analysis is that x at this point is equal to 0,1,2,3,4,5,6,7. Is this conclusion correct? It is sound. Yes. From the perspective of static analysis, if you say it is sound, you can think it is correct. This is a better understanding. OK. OK. I will ask another question. I have the third conclusion. x at this point is equal to 1 equals 0 equals 2,3,4,5,6,7. OK. I will ask another conclusion. At this point, there is another conclusion. x is equal to negative 1 or equal to 0. Is this conclusion correct? Yes. It is wrong. OK. Let's review. The third point I said is equal to 0,1,2,3. Right? OK. 1,2,3,4,5,6,7. Which one? We say it is sound. It is sound, but there is a mistake. Right? Static analysis is sound, but it is useful. But there is a mistake. What is the mistake? 0 and 1 are not a mistake. Because sometimes it is equal to 1. Sometimes it is equal to 0. These are all correct ways. The mistake is 2,3,4,5,6,7. Right? Then what is our fourth conclusion? We say x is equal to negative 1 or x is equal to 0. Then x is equal to negative 1. It is not sound because it is not either 0 or 1. So it is not sound. It is negative 1 except for 0,1. So it is not sound. Right? OK. These are the two concepts. In fact, these two concepts and these two conclusions can reflect two results. We can observe some other characteristics from these results. What are the characteristics? We said earlier that these two conclusions are all sound. No problem. But the first conclusion is relatively accurate because it specifically says that it is directly related to x is equal to 1. It is more specific and more accurate. Although the second one is sound, it is not so accurate. Right? It is very simple and rough. It says x is equal to 0 or 0 to 1. I don't know how exactly it is equal to 0 or equal to 1. OK. But the first conclusion is that although it is accurate, it also has a feature that it is expensive. This is from the point of view of the speed of analysis. Because this example is relatively simple. It maintains an upper and lower text information. It maintains a pass information. When maintaining an input, it is x is equal to 1. The input is false. So it uses extra resources to maintain some information and calculate some upper and lower text information. So its analysis will be slower. Of course, this example is very simple. It will not be too obvious. If it is really complicated, it will be slower. Although it is not accurate, it does not need to maintain these upper and lower text information. So its analysis will be faster. We call it cheap analysis. Actually, it means fast. So from this example, we can deduce a sentence from static analysis to summarize static analysis. That is, we need to ensure that in the case of soundness, we make an effective balance between the speed and the accuracy of the analysis. Good trade-off. What does it mean? Soundness must ensure that the analysis result is correct. Then the speed and accuracy of the analysis sometimes, you say I need accuracy. Of course, the more accuracy, the better. But think about it. In the past, a normal analysis may run for 2 minutes or 1 minute. If you want it to be particularly accurate, you need to run for 5 hours. In the past, if you wrote a compiler optimization algorithm, you ran for 5 hours. You waited for the compiler to run for 5 hours to optimize a program. Do you think you will accept it? You won't accept it. Some analysis, for example, Mr. Tan Tian will talk about index analysis later. The basic analysis runs. You may not run all your life. You can't run all your life. What kind of progress do you say you want to pursue? You have no result. What kind of progress do you want to make? So sometimes it has to be between accuracy and speed. If you sacrifice some speed, the accuracy will improve. If you sacrifice some accuracy, the speed will speed up. You have to make an effective balance. Here, I mentioned get close to again. This is an exception. Some analysis we will talk about later. In fact, the language we are talking about is PL. The entire language system is very complicated. In fact, some language systems are complicated in some dynamic characteristics. For example, native code, local code. If Java is really running, some C code will be dropped. C++ code. Including Java's dynamic extension, 累积值, etc. They will actually affect the real soundness. In fact, there is no real soundness. At this time, I want to mention the closer to soundness, the better. But so far, you just need to remember the first part. In a word, static analysis is to ensure the premise of soundness, to ensure the premise of accuracy, in the accuracy and speed analysis, to make an effective balance to achieve a real and useful static analysis. Useful static analysis. Okay? This is a sentence to outline static analysis. Do you understand? Accurate soundness. Balance of accuracy and speed. Okay? Okay. This is a bird's eye view. In a word, to understand soundness, to understand static analysis, to understand its essence in terms of concept. Okay? Okay. Next, from a technical point of view, from a technical point of view, let's talk about what kind of big steps static analysis needs to complete. Here, I want to summarize static analysis in two words, abstraction and over-approximation. It may be translated like this. Over-approximation. It is over-approximation. In fact, what is the purpose of over-approximation? Sound. To make the result sound. How to understand these two words? Let's move on. Okay. We want to use an example for everyone to understand. This example is a simple static analysis. How much can you understand? How much do you understand? Okay? Just to give you an initial impression. This example is very simple. Let's take a look. It judges all the variables in a program. Is it positive, negative, or zero? This is what static analysis needs to do. This is the application of my analysis. Didn't I say before? Is there a bug in your program? Is there a security loop in your program? Can your program be optimized and run faster? My analysis is very simple. I just do one thing. What is the symbol of my program? What is the symbol of each variable? This is an example we are going to make. Okay? A static analysis example. However, such a simple example is actually useful. For example, if you know whether the program is positive, negative, or zero, you can judge whether it is negative or zero. You can judge whether there is a negative or zero error. At the same time, if you can judge whether it is positive or negative, you can also check if the input is negative. If it is negative, you can also check. Let's move on and look at the example. Such a simple static analysis application also has some practical help. These two small help. The first step is to abstract. It is impossible to analyze the normal 0, 1, 2, 3 of the analysis. Right? We analyze all of them. We do static analysis and abstract. After the abstraction is done, based on the data of the abstraction, what is done? Static analysis. Static analysis is divided into two aspects. One is called transfer function static analysis. The other is control flow static analysis. It doesn't matter if you don't understand this aspect now. I will talk about it one by one later. Remember, abstract and static analysis. Let's talk about abstract first. What is our task? It is to determine a program to determine the positive and negative and zero of each variable in a static analysis. Right? Let's say our program is these. It has a concrete domain. It is the specific value. There must be a variable and an int in the program. Let's say it is an int. Right? There must be some sentences. There must be some specific values. We want to determine the specific value. What do we really care about? It doesn't matter if it is 1,000, 1, or negative 1. What we care about is positive, negative, zero, or zero. Right? Therefore, we need to abstract it into the domain that we need to operate in a static analysis. We care about positive, negative, and zero in this domain. Right? Now, look at this. This is good. 1,000 is positive. 1 is positive. Negative 1 corresponds to negative 1. Zero corresponds to zero. Look at this. This is an expression. It is an expression. Right? This expression is true. For example, it is true. This expression is 1. It is false. It is negative 1. This sentence corresponds to negative 1. It may be 1. It may be negative 1. In this case, there are only three choices, positive, negative, and zero. However, in this case, if you want to operate in a static analysis, you need to consider every situation. Right? Therefore, we need to add a symbol called unknown. It may be positive or negative depending on 1. However, in static analysis, we cannot measure the value of 1. We do not calculate a specific value. We only analyze this sentence. Then, if it may be positive or negative, we add a symbol called unknown, which is top. Look at this. W is zero. Any number is zero. Some students may feel that I did not explain the connection in the static analysis in the following lecture because there is no connection between the static analysis and Galois. So, in the following lecture, we will talk about the standard static analysis. Keep listening. W is zero. Any number is zero. Any number is zero. W is zero. Any number is zero. Any number is zero. Any number is zero.\n"
     ]
    }
   ],
   "source": [
    "print(translation_3['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6d1595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It can be a mistake. A mistake is also a kind of operational behavior in a program, right? You have to abstract it and analyze it to judge it. What should you do? Which one can represent a mistake? None. So you need to have an undefined. We call the other symbol bottom. We will talk about why these two symbols are called later. We will talk about it in the next class. It should be the next class. Then we will introduce this symbol to introduce all the undefined in the program. For example, through a check, this kind of behavior is expressed through an abstract value, okay? Then what is the abstract value? The abstract value is to print the specific value to the abstract value. Okay, make a print. So far, we have done the abstract. How much can you understand? We will talk about these things in the whole course later, okay? But now I will use the simplest example to tell you. The following can be complicated in many ways. But in fact, it is far more complicated than this. So, through an example, let's start with the first class. I will let you feel the concept, the technical concept. Okay, abstract. First, abstract the specific value of the whole real program from the abstract values we analyze and pay attention to. After the abstract is done, we have to do the printing. How to do the printing? We use the transfer function. In fact, the transfer function, whether it is a conversion function or a conversion method, it actually defines a set of rules. What are the rules? So, in static analysis, the transfer function does this thing. It evaluates different program statements on abstract values. In the beginning, we abstracted the abstract value, right? You abstract the abstract value. Then, in fact, the analysis of the transfer function is to give these abstract values a conversion rule for each sentence of the program statement. So, what is the definition of the abstract function? The rule has a principle, right? What do you do in the first step and what do you do in the second step? According to what rule does the principle define the conversion rule? It is based on the goal of the problem you analyze. What is the goal of our analysis? It is to determine a variable symbol, positive or negative, right? And according to the meaning of each statement in the program, based on these two common rules, to design your transfer function in a comprehensive way. It doesn't matter if you hear it here. Let's look at it with an example. What are we going to do? We are going to determine a program symbol, a variable symbol in a program. Let's assume that there are these sentences in our program, right? First, let's look at what our transfer function is defined on. It is defined on the abstract value, right? These are all abstract values, not V1 and V2. These are all symbols that have been abstracted, plus, minus, zero, and so on. So, according to what definition and the goal of your analysis, our goal is to determine a variable symbol, right? Then, for example, there is a plus sign in each sentence. What is the meaning of a positive number along with a positive number? It is a positive number. What is the meaning of an additional number plus a negative number? Normally, we follow our mathematical formula to determine the meaning of the two sign figures. A negative number must be constructed. What is a zero plus a zero? What is the rule of this? It is 0, right? Alright, what is the rule of the zero 그 0 and negative the plus that equal minus the plus? Negative number plus negative number gives positive number, and positive and negative number get positive number. Right? These are the rules we need to keep in mind. Alright. Positive and negative, positive and negative get positive, these are all improper rules. Alright, let's take a look at this one. What is a positive number plus a negative number? It is hard to tell at this point. A positive number plus a negative number. If you add 1 to 100, it is a negative number. If 100 plus negative 1 is 99, it is a positive number. Don't forget our static analysis. We said that based on your analysis problem, right? And the meaning of the language. The meaning of the language feels like it depends on a specific value. We don't know what it is. But our analysis is static analysis. Right. Static analysis is sound. It may be a positive number or a negative number. That is unknown. Very good. OK. Unknown. What about this one? Minus 0. We mentioned it before. Minus 0 is wrong. It is a line. But we need to have a corresponding abstract value. What is it? It is n-define. We call it bottom. Top is above the bracket. We will talk about lattice later. We will talk about the grid later. Alright. Bottom is below the bracket. Alright. Alright. These are the conversion rules. With these conversion rules, we will put them in here. This is a bit like our martial arts, how to say? This set of martial arts tells you what to punch in the first set and what to punch in the second set. Anyway, the rules of martial arts are here. Alright. According to these rules, now there is a real program. These are the sentences. Right. Our analysis goal is to judge all the variables of x and y. Its symbol value. Alright. According to the rules on the left, these conversion rules, transfer function to judge the symbol. First, x is equal to 10. Then I ask you, y is equal to negative 1, 0. It doesn't matter. This is very simple. Positive number, negative number, 0. Alright. a is equal to x plus y. What is the symbol of a? Let's see. What is the number of x? x is a positive number. What is the number of y? y is a negative number. Alright. This is plus. Then what is a positive number plus a negative number? Let's see. A positive number plus a negative number. There is this rule. What is a positive number plus a negative number? Top. It's the opposite. Because it may be positive or it may be negative. Right? But if the students look at this, if you use 10 plus negative 1, it must be 9. It must be a positive number. But modern analysis is not like this. Modern analysis operates on abstract values. Right? It operates on abstract values. Alright. z divided by y. What is z? 0. What is y? y is negative. A 0 divided by a negative number. In fact, a 0 divided by any number is 0. Right? So b is equal to 0. a divided by b. What is the symbol of c? What is a? a is top. Right? No. b is 0. Alright. What is divided by a 0? It's here. What is top divided by a 0? Undefined. It's an abnormality. So c is undefined. Continue. Array. y. What is y? It is a lock. y is a negative number. It's an abstract value in here. Right? A negative number and a lock. Of course, a negative number and a lock. I didn't list the rules here. It's like dot, dot, dot. Think about it. According to a normal grammar rule, if the lock in a number is a negative number, it must be wrong. So p is also undefined. It's also wrong. Corresponding arrow a. What is a? a is a positive or negative number. Right? Positive or negative. Because it's a top. It's a positive or negative number. A positive or negative number can also be a negative number. So if you want to do an analysis, you have to consider this situation. So q can also refer to a negative index. Index. Right? So it can also be a bottom. From this very simple example, we can see that there are two interesting conclusions. The first one is that we have already found a elimination error by judging its symbol. Elimination error by judging its symbol. If it's a zero, it must be a zero. Elimination error. Then in these two cases, we actually found a lock in a number is a negative number. The lock in a number is a negative number. We also found an error. So these two examples of 1 and 2 can actually be used in static analysis. Because it can find some errors. But in the third example, we can see that although this static analysis is useful, but sometimes it is too static. Right? For example, it will produce some errors. Because look at this example. For example, in the actual operation of this program, a x plus y 10 plus negative 1 is equal to 9. This is always 9. But if you report it now, it may be that the lock in a number is a negative number. So you reported an error. The error is false. This is an error. Right? But there is no way in static analysis. You say a. Our measure here is a top. Because we don't know the specific value is 10 and negative 1. We only measure this value. Right? So it may be a positive number. It may be a negative number. Then we must have the above results. So at this time, you report this. Although you report it, the second case is really wrong. Because y is a negative value. Right? Then a. But there may be positive and negative. So from this example, it is an error. The third example I want to say is that although static analysis is useful, but sometimes it produces errors. Okay? This is the program. This small example allows us to go from abstract to transfer function. Let's go through it again. But as we said earlier, the transfer function is defined according to two things. One is the meaning of each statement. Right? To define. This is the meaning of each statement. Positive plus positive. Negative plus negative. Minus 0 or something. This is the meaning of each statement. In fact, I just mentioned it earlier. In fact, this static analysis also needs to have what? Program flow. Control flow is control flow. What is control flow? It is the flow of the program execution. For example, this example shows a control flow. This picture is the control flow. It is the control flow of the small program corresponding to the left. See? X equals 1. Then, Y equals 10. Go to this branch. Y equals negative 1. Go to that branch. Right? Then, Z equals X plus Y. After these two branches end the EF branch, we have to go here. Z equals X plus Y. Okay. Now I will continue to do the example in front of us. What is this example? Determine each symbol. If X is positive, we don't write it. What is Y? Y is positive. In this branch, Y is negative. Now I want to determine whether Z is positive or negative. We want to know X. We want to know Y. We know X is positive. Then what is Y? Y may be from this branch. It may be from this branch. What is Y? This involves a control flow to draw a line. Everyone should remember all the places where the control flow is gathered. It includes a very simple branch. If you want a loop, for example, let's draw a loop. If it is a loop, just go back. It is a loop, right? Then, let's not draw this. Let's say there is this in front of this. There is a branch. Connect it to another stream. It is a loop. This is also called a gathering. Okay. All the points of the control flow gathering, we have to merge them. Merge. Draw a line. It is positive here. It is negative there. What is the point between the execution of this sentence and the previous one? What is the point of the gathering? We have to draw it. It is positive here. It is either positive or negative. It is easy to understand. Because it may be from the left branch or from the right branch. In order to go up, you have to tell it to consider both sides. So it is top. The point of Y is top. Then top is no. It is either positive or negative. So everyone remember because we can't merge all the paths. It is very simple to merge two paths here. You can. But the real program has thousands of paths. Different inputs make it explode. You can't merge all the paths in the actual application. So flow merging as a way to draw a line in the control flow, it is a way to merge in static analysis by default. By default. You just need to understand it. You just need to understand it through examples. You don't have to understand it clearly. Because we are talking about these things later. We will talk about them one by one through real examples. Okay. Let me summarize it here. First, let's talk about abstract and static. Right? Abstract is easy to understand. It is converted from the specific value of the different variables into the symbol value. So what is static? What do you have in a program? From a static analysis point of view, it is the connection between each sentence and each sentence. If you draw a picture, it is the arrow between each node and node. Right? So the static of the control flow is the static of the arrow. Right? The rule. The static of each sentence is the transfer function in front of it. Right? The conversion function. In fact, each sentence and the control flow constitute a real program. If you put them all in, and put them separately, then the whole program will be in. This is a general picture. Okay? Okay. Let me give you a simple example. You can understand it. Now let's talk about the teaching plan of this class. What do we talk about in this class? Tentative. It means temporary. We may have micro-structures. But in general, we talk about these things. Okay? In the first eight chapters, I will talk about the following chapters. I will talk about the last chapter with Mr. Tan Tian in the 9th to 15th chapters. Today we are talking about introduction. Not tomorrow. In the next chapter, we will talk about Intermediate Representation. It is AR. Those who have learned programming know that in the previous course survey, I saw that some students did not learn programming. It doesn't matter. We set up the course. Mr. Tan Tian and I designed this course and we didn't plan to let everyone have programming skills. It doesn't matter. But those who have learned programming, right? I see that many students have learned programming. As you know, what we did was mainly to analyze the grammar. Is it correct? Or do some simple type checks. These simple grammar checks. The AR we used was abstract grammar. AST, right? The real modern analysis is done on the so-called 3D code. AR is done on a similar 3D code. In other words, we now transform the formal programming into an intermediate form of expression. We call it the AR of the 3D code. Then all of our subsequent analysis is done on AR. We will talk about why AR is not AST in the next class. What are the benefits of AR? What are the benefits of AST? We will talk about all of them. If you don't understand programming, we will talk about the programming process in the next class. Then we will talk about the relationship between static analysis and programming. We will talk about all of them in detail. After the second class, the third class, the fourth class, and the fifth class will talk about a very important basic knowledge in static analysis, which is data flow analysis. Some students may say, Mr. Tan, I have taken programming classes before. Our programming teachers will simply talk about data flow analysis and some applications. When I was reading Long's book, I felt that it was quite simple. Here, I want to give you a warning. That is to say, you have to understand it first. You read the book, you understand it. You said in the last class that you should know. It's normal for you to understand it after reading it over and over again. It has to make you understand it. Otherwise, the person who wrote it is not good, right? But when you understand it, you may not really master this knowledge. After you finish reading this thing, you may forget it in the next two or three days. How can you learn other things with this knowledge in the future? The premise is that you must master it. So we plan to have nearly three classes. It may be a bit of a problem. We will talk about data flow analysis systematically. Because I think now, because Mr. Tan and I are reading this class, we can say that we are really doing our best to memorize it seriously. Basically, every class, I spend two to three weeks to memorize it. I will collect normal information and then understand it. I found that in fact, some foreign information is not very good in this regard. I don't think it's easy to understand. It can also make some theoretical things clearer. So I'm going to re-design it with Mr. Tan. I'm going to re-memorize this part. I only memorized the third part today. I haven't finished it yet. But I want to integrate the fourth and fifth parts. Okay? Some students say that it seems to be different from Mr. Xiong's teaching plan. Okay? Mr. Xiong is a software analytics teacher in Peking University. Mr. Xiong, we have seen his teaching plan. His teaching plan is broad. He will introduce many things that are related to static analysis. Basically, it covers everything. If you want to do static analysis in various fields, including applications, including what I just said, program repair, symbolic execution, he will introduce them all. If you want to do more, if you want to know what applications are there in static analysis, you can refer to Mr. Xiong's teaching plan. I personally think that our teaching system is very different from Mr. Xiong's. Because we focus on the depth. Mr. Tan Tian and I have been doing this for the past seven years. Then we want to go deeper into these things. Because what? There is an advantage of going deeper. That is to say, you can turn this knowledge into a part of you. You will remember it very well. In the future, you will be able to reflect on it. Now, this knowledge is not just about being able to do static analysis in the end. In the end, you will be able to understand programming or some advanced and complex software. It is correct, reliable, and safe. This includes some mathematical theories and algorithms. How to ensure that some other topics that you need to satisfy will be designed in the future. About analysis, verification, and so on. Some of your needs will be reflected. So there is a good foundation. It will also allow you to grow a little bit from the theory of mathematics to the real application and to complete it by hand. This is the core of our entire set of courses. I think that all static analysis courses are now a big drawback. Either it is very shallow, or it is very deep. Some people abroad are very deep. Some courses are either shallow or deep. I don't understand. So Mr. Tan Tian and I will try our best in this course. Because our personal ability is also limited. So we will try our best to make it possible for everyone to transform the complex knowledge that we spend time on through our understanding into something that is easy for students to understand. After all, students from Nanjing University are okay with static analysis. As long as you are from Nanjing University, I hope that as long as you are serious about learning, I hope that other people's comments on you will definitely be met. No problem. As long as you are from Nanjing University, you are tough. This requires teachers and students to work together. Okay? So as a teacher, because the teacher's ability is indeed limited, it is the first time to teach. So the knowledge structure itself is also constantly learning and strengthening. So I will try my best and hope that my students will cooperate with me. Okay? Okay. The first part of the sixth class is about data flow analysis. It is very shallow. It will talk about the intro, which is within the process method. It does not involve the call between methods. It also does not involve all the variables are scalar variables, which is to say, ordinary variables. It doesn't need to be named. All the related names, such as 9, 10, and 11, are very important for the basic analysis. This is what Mr. Tan Tian will talk about. Okay? So the first three, four, and five are scientific and practical theories. But they are also deep. From the mathematical theory, I will build it up for you a little bit. Build it into an application. Then let's talk about why this application may be this theory. Why? Sometimes when we look at the proof, we don't know why we have to prove it. We have to learn this thing. It's boring. Then the teacher will only tell you the things that really affect the algorithm in the future. Then he will connect it to you. He will build it for you. He will build it for you. Then six is about whether the real program is cross-functional. He will talk about how to analyze the whole program. Then seven. I have discussed with Mr. Tan Tian many times. I will definitely tell you about seven. CF-Reachability is quite easy to understand. It is equivalent to analyzing some upper and lower languages and converting them into our so-called upper and lower languages. This is quite easy to understand. But in the analysis of IFDS, a lot of popular frameworks use this knowledge. A lot of static analysis departments don't talk about it because it is very difficult. I can only say this. Many doctors who specialize in static analysis may not be able to understand IFDS clearly even if they graduate. They only know how to use it. They may not understand it. But Mr. Tan Tian and I feel that this thing is very important. Understanding it can further help you to avoid obstacles. In the future, if you are engaged in this industry, whether you are an academician, an industrialist, or a senior computer scientist, you will be enlightened after learning it. I understand it this way. You will get all the knowledge points through it. Although it is difficult, you can understand it. So I want to introduce IFDS to you again. Try to explain it to him clearly. Because as the saying goes, individual ability is limited. Try to know yourself. I will explain it to you in an easy-to-understand way. The eighth topic is a very cutting-edge part of static analysis. The basic theory of our statistical system design is to talk about it from the beginning. Some of you have to talk about it. It is important to talk about it. Then the difficult part, we think it is important, we will talk about it like IFDS. Then the cutting-edge research direction, such as your analysis, you use it in actual programs. Is it really useful? As we said earlier, get close to soundness. Sometimes you can't reach soundness. It is called soundiness. How to analyze reflection? How to analyze dynamic loading? These things in real programs. How to analyze cross-language call? Java call C. We have to cover the cutting-edge things. So after you go out of the whole course theory, you will have an understanding of the most cutting-edge and basic things from theory to practice. I hope that although this course is for masters, this course is for masters, including researchers. This is what I want to talk about. Then, from the ninth chapter, to be honest, qualitative analysis is very important. It is the basic technology of static analysis. Basically, all the static analysis applications you use such as error detection and security, including some optimization, will build the whole infrastructure with basic analysis. For example, if static analysis is an English software, then qualitative analysis is the operating system technology. Let me give you another example. If you say the static analysis we talked about earlier or the error detection and security tools we use now, they are all about building a bridge or building a building. Then qualitative analysis can be said to be the technology of earth and wood engineering. It is a common sense technology. Mr. Tan Tian is very suitable to talk about this part. Although Mr. Tan Tian is very young, he was born in 1991. But Mr. Tan Tian, he is not a child to you, but Mr. Tan Tian is internationally in qualitative analysis. I can say without shame that Mr. Tan Tian is the top expert in qualitative analysis internationally. He is definitely the top expert. So I think it is more suitable for him to talk about this part. Okay. There are many foreign static analysis courses that are not related to the explanation of qualitative analysis. Mr. Tan Tian will talk about 12 modern portalizers. After Mr. Tan Tian finishes his talk, he will tell you what the static analysis does to security. You will find that as long as you learn qualitative analysis, you can naturally modify what is security and directly check the security. The privacy I mentioned earlier, data leakage, injection attack, these five-point analysis can be directly analyzed through qualitative analysis. It is very easy. Let everyone feel the application of qualitative analysis. Then Mr. Tan Tian will talk about data log. Data log is the type of language distribution I mentioned earlier, right? The order is the function type and the statement type. The logic type is data log. Why do I talk about data log to everyone? In fact, this course does not want to talk about some messy things. I still want to tell you in depth about things that are purely related to qualitative analysis. But we consider that data log is really the most advanced mainstream now. For example, the qualitative analysis machine or qualitative analysis for Java is all written with data log. So at this time, I hope everyone can also understand the most advanced practical aspects. For example, you go to a big company and ask if you can develop an analyzer for us. Then you say you are familiar with the most advanced analyzer. You look at data log. At that time, many people were not familiar with data log at first glance. They don't want to look at it. Think about it. Data log is thousands, thousands, five or six thousand logical rules. They are afraid. In fact, you don't have to be afraid. Data log is not that difficult. Mr. Tan will tell you. He will give you some details. He may also tell you. In fact, when I was a PhD student, Mr. Tan said that some of our quantitative analysis is written with data log. In fact, it is not that difficult. Let everyone feel how the real popular quantitative analysis is realized. At the same time, talking about data log allows everyone to have a supplement in terms of language. Because you may have learned that the command is a language. You may have learned that the function is a language. But you may not have learned that the logic is a language. So there is a supplement in data log. All right. After talking about it, the previous classmate just started talking about abstract interpretation. Abstract interpretation. Mr. Tan and I were thinking about whether to talk about it in this class. But we have to talk about it. Why? That's because abstract interpretation is a very, very important part of the quantitative analysis. It comes from Europe and France. How to say it? It is passed down from generation to generation. That is to say, the researchers who have a similar background have been using abstract interpretation to do quantitative analysis. From my perspective, I can say that if we talk about quantitative analysis and if we talk about the techniques of quantitative analysis, for example, if we learn martial arts, what we teach in the beginning is Wudang and Shaolin. But abstract interpretation is so important. Things like Huashankongtong need to be taught to everyone because it is martial arts after all. Sorry. I was a little stuck just now. A little stuck. What did I say just now? I was stuck. It seems that I don't blame you. Did you hear what I said about martial arts? Is it stuck now? Can you hear me now? Okay. Maybe it's a problem with my computer. Did you hear what I said about martial arts just now? I said, why do we need to talk about abstract interpretation? Yes, Huashankongtong. Yes, what I said in the beginning is that the quantitative analysis we learned in the beginning belongs to Wudang and Shaolin. I will also talk about the important branches of Huashankongtong later. In fact, abstract interpretation and quantitative analysis in the beginning are interlinked. It is necessary to tell you. Finally, we will summarize the whole course. This course is now starting. This course is difficult because if you think about it, it must be difficult to learn something without talent. But because Mr. Tan Tian and I have limited personal ability, we can't guarantee that everyone will understand it in one day. But we will try our best to provide everyone with a good course. Even if we don't want most of the research time, we will focus on preparing this course for everyone first. I can't say that this is the first class for everyone. The first class is quite noisy. It will ruin your students. So I will prepare this course for everyone as much as possible. I will try my best to teach it to everyone. But it is really difficult. I hope everyone can understand. Okay? In the 16th class, I will...\n"
     ]
    }
   ],
   "source": [
    "audio_file_4 = open(\"./11-Audio-Summary/audio/75m-100m.m4a\", \"rb\")\n",
    "translation_4 = openai.Audio.translate(\"whisper-1\", audio_file_4)\n",
    "print(translation_4['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f9af549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For example, in the previous lecture, we talked about how data analysis belongs to Wudang Young People. Later, I will talk about the important part of cross-sectional control. In fact, the abstract interpretation and the data analysis in the previous lecture are interlinked. I think it is necessary to talk about it. Finally, we will summarize the whole course. The course is now starting. This course is difficult. Because you think about it, it is definitely difficult to learn something without talent. But Mr. Tan and I, due to our limited personal ability, can't guarantee that everyone will understand it in one day. But we will try our best to provide everyone with a good course. Even if we don't need most of the research time, we will focus on preparing this course for everyone. I can't say that this is the first class for everyone. The first class is a bit noisy. It will ruin your students. So I will try my best to prepare this course for everyone. And I will try my best to teach it well. But it is really difficult. I hope everyone can understand it. Okay? In the 16th class, we will review all the points of knowledge. After reviewing, we can reduce the time for reviewing. I also hope everyone can get a good grade in the end of the semester. Okay? Okay. Evaluation criteria. How do we evaluate everyone's score in this course? Since the last class, if you want your students to learn something, we must have an experiment. The experiment is worth 50 points. The end of the semester is worth 50 points. This is our plan. What kind of experiments do we have? The experiment we designed is like this. There are five experiments. The first experiment is to do a const propagation. It is a compilation optimization. In fact, it will calculate and propagate the const value in a static way. It doesn't matter if you don't understand it. I will tell you something. If you can understand it, you can understand it. Okay? But the first exercise is all intra-procedure. We talked about data flow in the previous class. The second one is data code elimination. What can const propagation do? For example, as I mentioned earlier, the most commonly used data code elimination in compilation optimization is to realize a high-level part of a compilation machine. Based on const propagation, we use eliminate to make an application. For example, what is code elimination? For example, if b is equal to true, then if b, we know that if there is a const propagation in front, we know that b is a const value. It is always equal to true. In other words, it can only execute the if branch. Else, if there is a data code, you can throw it away. This is the example. 12 points for now. After talking about assignment 2, let's talk about class hierarchy. The first two examples are layer-by-layer. But what can they only analyze? Intra-procedure. It is the code that can only be analyzed in one method. So, the third assignment of class hierarchy is to let you write a algorithm that can be called in the process. Consider all the calls between different methods and build a call graph. Then, from this assignment, you can analyze cross-functional analysis. The whole process is analyzed. So, class 321 is a layer-by-layer. The fourth part is an interface-based assignment. In the previous part, we talked about the algorithm of build a call graph. The algorithm of the if branch is actually not accurate. As I said before, the guarantee is that the accuracy and speed must be balanced. In this part, we will introduce a more accurate method of cross-functional analysis to make your analysis more accurate than the original third assignment. You will find that your analysis will produce fewer errors and more useful analysis variables. The last assignment is to talk about how to make it more accurate on the basis of cross-functional analysis. For example, contact sensitivity. You will feel it in this assignment. You will really feel the speed balance. So, the first example is to build it up little by little. The last one is a full-procedure one. The whole call graph is very accurate. You can do this kind of const-programming and compilation optimization task. So, each experiment is a base on the above assignment. However, considering that this is the first class, this experiment may be a little difficult. So, we think that we should be able to handle a degree in the first class. So, when I and Tan Tian designed this experiment, we designed simple codes to make it easier for everyone to implement. We decoded some codes and let everyone fill them in. As long as you pay attention and listen carefully in class, it should not be difficult, okay? So, in other words, this is the first class. I say this, as long as you pay attention and listen carefully in class, I will definitely let you pass. Unless you don't listen to what I say, you don't understand, and you don't do your homework. If you don't pass, there's nothing you can do, right? I discussed with Tan Tian that the first class is to let everyone learn both knowledge and make it easier to pass. This is one of our designs and one of our intentions. We will see how everyone learns at that time, okay? We don't really analyze the real programs for this homework. Because the real programs are particularly complicated. Your workload is too large. It's a bit of a choice. After all, we want to learn knowledge. So, for example, a real language, we may only analyze a part of this language. For example, you don't need to analyze the long one. You don't need to analyze anything. At that time, our test case will be a simple test case, not a real complex program. Okay? Let everyone do their homework better. As for when to release the code, we will discuss this later. Because we are in a tense class, how to replace it? If there is no replacement, the exam is the final examination. It's the last 50 points. The experiment is these five experiments. 50 points. Okay? We will consider this later. We haven't decided yet. You see, it also says Tentative. Okay? So, is there a bonus? Right? What you want to say is this... Can students who are listening pay attention to the experimental material? Yes, no problem. But please don't spread it out, okay? Because after all, right? Your Nanda students should be qualified to enjoy this resource first. Okay? It's like this. In order to reduce everyone's burden, I usually don't leave homework. Only experimental homework. Do you understand? And then, I will talk about what each homework says later. Okay? It's like this. The acts you need to understand in this lecture. Every lesson of mine, every lesson of Mr. Tang Xin and I, there will be such an act you need to understand. What is this thing? This thing is this section. It doesn't matter if you don't fully understand what you hear. But you must master these points. In other words, it also helps. You don't have to do homework. To reduce your burden. But at the end of the exam, these bullets are important. This may be the focus of your paper exam. Okay? It's equivalent to drawing the focus for you in advance. So even if you don't do homework when you get home, you have to go through these problems by yourself. For example, today, you need to understand what is the difference between static analysis and dynamic testing. And then, understand that soundness, completeness, false negatives, and false positives. And then, we will give an example later why a lot of static analysis is needed for soundness. Everyone will take care of sound. Why? Understand. And then, how to understand abstraction and over-abstraction. I will give you an example to explain it to you. So, everyone, you can see that all the basic questions are either necessary concepts that will make you remember. The rest is to make you understand why, why, why. Always answering such questions. If you listen to this class well, watch the class well, and do your homework well, I think you will definitely pass this class. No problem. Okay? I didn't hear it just now. Can the room get the material in time? I will discuss it with Mr. Tan Tian. After all, it's just the two of us. But if you really listen to the class, if you really choose it, we will try our best to get the experimental material for you. Okay? Okay, last. Oh, a few minutes left. No, no minutes left. Hurry up. Let me introduce the group we built with Mr. Tan Tian. Now, in our group, there are two PhD students, and then there are four undergraduate students. Everyone is very good. And then, if, this is the last class. There will be a special exam time. Okay? If everyone, how to say, especially the students in the third year, because the students in the fourth year will graduate soon. If you are really very interested in this class, we don't want to say it's fake. And then you are very interested in PL and static analysis. And then you think you have a strong ability to edit. After the class, you can come to our office to talk to me and Tan Tian. For example, if you have a plan to open a club or read a book, you can come to our office. This is my office. This style and this office is our own decoration. Mr. Tan Tian and I decorated it ourselves. We are in the same office. The style may be different from Mr. Tan Tian. You can come to our office at any time. And then our office is 536. Okay? This is the sub-floor of the computer building. 536 office. There is a web page at the door. Okay. This class, the first class is over. There is no time. We can't talk about money. So that's it for today. Okay? Thank you for listening. I will post the class in our group. Okay? Send it in as soon as possible. Don't worry about your homework. I'm still preparing for the class. Mr. Tan Tian is also preparing for the class. So we haven't figured out how to do the next few classes. We have to think about it. So we will postpone this experiment as much as possible. We don't want you to do the experiment in the first few classes. So we will postpone this experiment. Okay? Okay. Do you have any questions? If you have another class or you want to eat, you can go and eat. I'll leave you five minutes. See if there's anything else you want to ask. It's not hard. It's what I should do. I'm a teacher. I went back to China with Mr. Tan. I went to junior high school for the students. It's normal. Do you have any questions? You can ask. I'll leave you five minutes. Okay? Actually, there are many teachers and enterprises waiting for this opportunity. I knew a young teacher from Huake. He was wanted by Huawei for pennies. But he didn't come back to Huake. I think it depends on the situation. I thought about it the other day. I thought if our students can become very good, they can think more and look further in their lives. It doesn't have to be rich or powerful. They can live a happy life and make a choice for themselves. This is the original purpose of being a teacher. This is our value. We will be happier. So I didn't choose the enterprise. I chose the teacher. I dare not make a choice based on my own interest. It depends on your own interest. What didn't you understand? Kang Tai San's PA. If you didn't learn it, you can't understand it. Can I record a lecture in school in the future? I'm afraid I won't have the right to listen to it. I'll think about it. It's so tiring. I still prefer face-to-face. Because you don't have feedback on this thing now. Because there must be some students who don't have feedback. The first few lessons are relatively simple. I'm afraid some students don't understand the following things. So I really want to ask questions in class. This class must be lively. I think you must think about it. I won't say this thing. I'll tell you it's like this. What does that mean? You can look at Science 2. You must guide and think about it. This thing needs to be asked. But we don't have any interaction now. I can't help it. So I still focus on getting back to class as soon as possible. It must be in class. This effect will definitely be better. Will it still open later? You tell the department. If you say in the next semester, I still want to open. I still want to open. If you have more people, the department will agree. If the department agrees, I will open. Okay? What will be the industrialization opportunity of domestic research results? What kind of research results do you divide? Static analysis results. In fact, there are quite a lot of transformations. As far as I know, there are quite a lot. Especially abroad. There are a lot of foreign transformations. Domestic may be in the process. Maybe Huawei is a very big, rich, and human resources company. They are also doing it. Huawei has a lot of good cooperation with many universities in our country, including our Nanjing University. Recording in class? You can record it if you want to. You listen to it yourself. It doesn't matter. Did I miss someone's question? If I didn't answer your question just now, you can ask me again. I'm so tired. You are asking about scientific research, right? No, it's about innovation and completeness. That's what I think. Completeness and innovation from the perspective of a researcher, I think there is no contradiction. I always emphasize that the concept of scientific research is free. This thing can be useless, but it must be interesting to you. As long as you move forward a little bit on this point, innovation will come out naturally. It can't not come out, unless you don't care. If you don't find the problem, it will lead to some research problems. As for completeness, think about it. If you can really move forward on this issue, how can you have a bad completeness? Unless you say you want to be a very useful tool, I don't think it's necessary. You can do it in the industry or in the future. How is the treatment given by NANDA? NANDA is good. I am a professor who introduced the Dengfengbi project. Thank you. You're welcome. Any more questions? Comrades? Didn't your parents ask you to eat? Do you need the recording of this class? The recording of this class. I'm recording now anyway. Alright, that's all for today. Let's eat.\n"
     ]
    }
   ],
   "source": [
    "audio_file_5 = open(\"./11-Audio-Summary/audio/100m-end.m4a\", \"rb\")\n",
    "translation_5 = openai.Audio.translate(\"whisper-1\", audio_file_5)\n",
    "print(translation_5['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca4a57",
   "metadata": {},
   "source": [
    "## Lec02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f890358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's start the class. Hello, everyone. This is the second class of software analysis. Before we start the class, I'd like to tell you a few things. In the first class, we recorded the live video and put it on Bilibili. Mr. Tang also promoted it on his account. We didn't expect more than 2,000 views. Many students all over the country are very interested in static analysis. How to put it? It's our first class, so we don't have enough experience. Especially in the last class, the speech was too fast. I couldn't hear it clearly. We still have room for improvement. I think we still lack experience. But everyone was very tolerant and kind. They gave us a lot of encouragement and support. On behalf of Mr. Tang, I'd like to thank you all. Okay. We also read the comments under the Bilibili account. We organized the comments. I discussed the key issues with Mr. Tang. I'll give you the answers. First, the most important issue is whether the class will be open to everyone, including students from other universities. We didn't expect so many people are interested in static analysis. Indeed, we don't have enough resources in China. As I mentioned in the last class, only Peking University is open to students. The rest are students from Nanjing University. So, Mr. Tang and I decided to build a course website. After the pandemic, we will put all the courses on this website. The website is still under construction. When it's done, we will put all the courses on the website. Then, we will let you know through the platform. Then, you can visit the courses. This is the first thing. Second, as I mentioned, after the pandemic, we will resume the classes in Nanjing University. Then, we will put all the courses on the website. This is a very difficult task. We need to write a book, and put a PowerPoint presentation. We also need to communicate with the students. We need people and equipment to do this. We are inexperienced. This is very difficult for us. We need people and resources to do this. So, this is the first class. After the pandemic, we will not resume the classes. We will talk about this later. Third, as I mentioned, we will put all the homework on the website. As for the homework, Tan Di and I are still working on it. This is the first class. We are not sure if this is a difficult task for the students. We are not sure how to allocate time. We need to write the homework and fill in the codes. The difficulty, the workload, and the accuracy of the knowledge need to be checked by the students in the south. If they finish the first class, we will adjust the second class. If they finish the second class, we will adjust the third class. In short, if the students are not good enough, we will put the homework on the website. As for the class, as I mentioned, the class is not perfect. It is a tense class. However, we will put all the homework on the website. This is what we want to say. Let's continue. What are we going to talk about today? Intermediate Representation, or IR. What is this? Think about it. We are going to talk about static analysis. What is a static analysis? What is a static analysis? It is a program. Think about it. If you write a source code, with all the formulas, all the formulas, and then I give it to the static analyzer, is it good? If you have experience as a static analyzer, how does a static analyzer analyze a program? Does it also convert a source code into a representation? If you are a static analyzer, you may have heard of AST, Static Algebra, right? Static Algebra is the result of static analysis. Basically, it does some simple language analysis, such as type check. The subsequent optimization is done on the so-called IR. It has a series of intermediate representation formats. In fact, a static analyzer needs a form or a format to represent a program. What are the characteristics of a static analyzer? Think about it. What are the characteristics of a static analyzer? To put it simply, a static analyzer analyzes a program in a format that is simple and efficient. This is the purpose of IR. Is there a strict definition of IR for a static analyzer? No, because it is designed by humans. For example, does a language have to be a programming language? This will lead to a war. In other words, it needs a market and opportunities, including the quality of the language itself. The same goes for IR. When people use it a lot, they think it is good. When people use it a lot, they think it is good, and they will continue to use it. Therefore, the definition of IR for a static analyzer is very important. In this lecture, we will talk about what a static analyzer should look like. In other words, all the static analyzer we will talk about today is based on IR. In other words, a program used to be a source code, will be converted into an IR table in the middle. All the static analyzer we will talk about today is based on IR. Therefore, today's lecture is very important. I personally think there are a lot of details in this lecture. In order to make it less boring, I think it is good to talk about a few things in this lecture. I hope you understand what I said today. I hope you understand what I said today. And I hope you understand what I said today. I think 60% or 70% of you will understand what I said today. That means you understand what I said. You can watch the video or the lecture. I want to emphasize one thing. I realized that I was in a hurry in the second half of the lecture. I spoke fast and my voice was hoarse. If you think my speech was fast, please leave a comment and I will slow down. I don't want you to misunderstand what I said. I want you to understand what I said. I want you to understand what I said. Let's talk about today's lecture. First, I will talk about the relationship between the compiler and the static analyser. In fact, the compiler and the static analyser analyze a program called AST. What is the relationship between them? We will talk about it briefly. If you have studied the compiler, you may know that the compiler needs a middle language called AST. In fact, static analysers can also do some simple analysis on AST. For example, static analysis on 3D code. We will talk about 3D code later. We will talk about 3D code later. Why can't the static analyser do the analysis on abstract language? Why can't the compiler do the simple language analysis such as type checking on AST? What is the difference between AST and IR? What are their advantages? Why does the static analyser need IR like 3D code instead of AST? We will talk about it later. In the third part, we will talk about the theory of 3D code. In the fourth part, we will talk about the real static analyser. The real static analyser is the one in Java ecosystem called Soot. Soot can analyze Java's real program and Android system. It is the most popular static analyser in Java. Let's see what 3D code looks like in the real static analyser. Let's see how it works in the real static analyser. I will talk about the basic concepts of PL in the next part. In the fifth part, we will talk about the selection. The reason why I will talk about it is because it is also an IR format. However, some changes in the design of the static analyser are not good enough. The reason why I will talk about it is because all the courses and experiments are not related to SSA. It is a selection part. I will talk about it because it was proposed in 1980. It is a classic static analysis since it is an IR format. I will talk about it because it is a classic static analysis. I will talk about it because it is a classic static analysis. Let's talk about the basic blocks. What are the basic blocks? What are the basic blocks? Basically, the basic blocks are the control flow graph for the seventh part. The control flow graph actually faces the static analyser. In other words, the 3D code in the front is converted into the 3D code. In the static analysis, the input of the static analyser is converted into the control flow graph. It is converted into a graph. The way to analyze becomes a method of the graph. It is easier to analyze the graph. Some graphs have nodes. Each node has a command or a sentence, or a basic block. The basic block combines a series of sentences according to certain rules. It is easier to analyze. We will talk about it later. This is what we are going to talk about today. Let's start from the first part. We are not going to talk about LREM. What we are going to talk about is the basic stuff. In the lab, we are going to talk about the Java ecosystem. We are going to talk about the Java ecosystem. We are not going to talk about LREM. We are not going to talk about LREM. LREM analyzes C++. Java analyzes SCRT. Java analyzes SCRT. Compiler, we have done some research and found that some students have learned C++ before. It does not matter. If you have learned compiler, you will be able to understand. But if you have not, you will not be able to understand most of the topics. For those students, it does not matter if you do not understand. Just focus on one topic. You will see what is the relationship between static analysis and compiler. The rest of the content depends on your ability to digest. What is a compiler? It is a software that converts high-level code into a machine that the machine can understand. In the case of SCRT, we normally write high-level code. It is a software that can understand SCRT. In the case of machine code, we write code that the machine can read, load, and write. It is a translator. When translating, there is a difference between right and wrong. For example, if I tell you that I cannot understand your translation, you have to tell others that you are wrong. So, a compiler is not only a translator, but also a loader. What is the framework of a compiler? Let's take a look. First, let's take English as an example. What is the first step that a compiler needs to go through? It needs to go through a language analysis scanner to do lexicon analysis. Let me give you an example. What is language analysis? For example, if the language we can understand is English, how can we understand the letters written here? For example, the first letter is y-o-u. y-o-u is one of 26 English letters. So, y-o-u is not a problem. Next, let's take a look at the next letter. It is y-o-u. Of course, it is not one of the 26 English letters. So, it cannot be analyzed. Similarly, g-o-o-u-o-g-d-e is one of the 26 English letters. But the word does not go through lexicon analysis. If it goes through lexicon analysis, which means that every word is legal, then it will generate a token for the next step. As I mentioned earlier, there are many keywords such as English dictionary. Then, you need to judge whether the word goes through lexicon analysis or not. In this case, you need to use regular expression. If it goes through lexicon analysis, which means that every word is legal, then it will generate a token for the next step. Then, it will be called like your hair. It is a legal word. But is it correct in lexicon analysis? It is wrong in lexicon analysis. According to English lexicon rules, for example, the word goes through lexicon analysis. Therefore, it is wrong in lexicon analysis. Similarly, according to English lexicon rules, there is a formula called context-free grammar. It is a grammar that you can use without any context. I will briefly talk about context-free grammar. I don't know whether you have learned it or not. I think you have learned the four levels of context-free grammar and context-sensitive grammar. Why is it that context-free grammar is not used in syntax analysis? Why is it that context-free grammar is not used in syntax analysis? It is because context-free grammar is not sensitive to the language. Now, you can see that context-free grammar is enough to describe modern syntax. Context-sensitive grammar is used to describe more complex and modern languages. Context-sensitive grammar is used to describe more complex and modern languages. For example, you may need a few hours to understand the syntax analysis in my editor. Context-sensitive grammar is used to describe more complex and modern languages. Now, let's talk about AST. We will continue to talk about abstract syntax. Abstract syntax transforms a program into a vertical structure. We will talk about the vertical structure later. What does it do? It does semantic analysis. For example, you can see the word in the sentence. But, the sentence does not have a proper grammar. So, how can we judge the grammar? In this case, we can only do simple grammar checks. For example, a floating number cannot be given an int variable. Otherwise, the type transformation will be problematic. Another example, a string value divided by an int value is also wrong. The type does not match. So, how can we describe type checking using attribute grammar? Let's assume the syntax is correct. Type checking generates a decorated AST tree. The tree may contain some type information. You don't need to know much about it. Now, what do we do after type checking? If you want to optimize the AST tree, you need to convert it into an intermediate form. In this case, we usually refer to the 3D code. After you have optimized the 3D code, you need to continue to generate the machine code. You need to hand it over to the machine. It can be a virtual machine, a logic machine, and so on. So, what is static analysis? We mentioned that you need to optimize. In fact, optimization is an application of static analysis. In fact, I just want to check the security of the program. In fact, it is also based on the 3D code. It means that you need to pass the front end of the compiler, which is the front end before the IR, and the back end after the IR. You may ask, why do I need to pass the front end of the compiler? Can I generate the IR directly and hand it over to the static analyzer? Think about it. If you want to do a bug detection, what does it belong to? It belongs to a very advanced program. For example, if you can't pass the front end of the language, you can't pass the language in terms of language. You can't write the word for or while. The program itself is wrong. It can't even run. What does the static analyzer mainly analyze? It analyzes the non-trivial properties. It analyzes the non-trivial properties related to the real and the real-time operations whether it is a bug or a security loop. Before analyzing the non-trivial properties, you need to analyze the basic trivial properties such as the word, the language, the type, and the type check. You need to analyze the non-trivial properties first, and then analyze the non-trivial properties\n"
     ]
    }
   ],
   "source": [
    "audio_file_1 = open(\"./11-Audio-Summary/audio/lec02/lec02-0m-25m.m4a\", \"rb\")\n",
    "translation_1 = openai.Audio.translate(\"whisper-1\", audio_file_1)\n",
    "print(translation_1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adaaf5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Therefore, if you want to write a normal static analysis machine, this IR basically has to go through the pre-processing process of compilation. It has to be selected first, and after building a legal IR, the static analysis machine can continue to analyze on this IR. This is the relationship between static analysis and IR. As I mentioned before, if you want to write a normal static analysis machine on a 3D IR, you have to learn something. For example, if there was no such 3D IR in the past, and you design a static analysis machine, can you come up with a 3D IR? You can't just use a concept that everyone has been using for so many years, and then learn it. Before learning something, you have to think about why you want it, not something else. This slide is about this. AST has been around for so long, and a lot of compilers have used it. Even some simple static analysis can be done with AST. But why do we have to learn it? What I want to emphasize in this class is the 3D IR. Let's take a simple example. We have a Do-while loop here. Do-while. You've learned programming languages before, right? Do is to execute this sentence. Add is to copy. Then while is to determine the condition. If the i-th element in the a-value is less than v, we will continue the loop, right? We will continue to support i-th and i-minus-1 until the condition is met. Okay. What does AST look like? It looks like this. For example, its root node will indicate that this is a Do-while loop. Then in this loop, first of all, it has an assign. Assign is a... Of course, the left side of the assign is an i. The right side is a two-dimensional operation. It's a mathematical operation, right? It's an i plus 1. Then what is in the Do-while condition statement? It's a number visit. The second element. Then if it's greater than v... Okay. You can see from this mathematical structure that it and the grammar... Because I'm in a class right now, if some of my students have questions that are too long to answer, they might interrupt me. So I won't answer them now, okay? If we have time, I'll answer you after this class, okay? You can ask questions then. If there are some questions that I can't answer in one go, or are too long, or might interrupt me, I won't answer them now. Please understand, okay? Let's continue our class. So... Where was I? Right. The AST, the mathematical structure, is actually very close to the grammar. Right? You can see this Do-while. It's written as Do-while, right? Then the number visit is greater than v... This structure is actually a very close grammar structure. Okay? So what is 3D? We've been talking about 3D all along. What does 3D look like? I'll just give you an example. We'll go into more detail about 3D later. Let's look at what 3D looks like. First, i equals i plus 1. What does this 1 mean? What does this 2 mean? This is a label. This is the location in your program. It's a label, okay? It's a location. Then t equals a plus i, which is the number of visits. The value of the Do-while is first generated as a temporary variable, t. Then the temporary variable is used to compare with the Do-while. If t is less than 1, what does GoTo1 mean? Where is GoTo1? 1 is a label. The location of a program is here. So GoTo1 comes back here. Then this is a cycle. Because when t is less than 1, GoTo1 continues to execute the first sentence. Right? This is what 3D is. We can get this conclusion from these two examples. AST is a high-level close-to-grammar structure. We saw that just now. Right? It's very close to the grammar structure. But 3D is a low-level close-to-machine code. Why is it close-to-machine code? When you look at this, which one is closer to AST or IR? Which one is closer to machine code? Of course, this one is very close to the Do-while. Right? After some operations, after we extract it, we can go to GoTo2. GoTo2 is a label. This is closer to the Do-while. This is obviously closer to the Do-while. Right? Then, AST is Uralanguage-dependent. Think about it. It's very close to the grammar of a language. Different languages have different grammar. Right? So what is AST? It depends on different languages. And IR is Uralanguage-independent. It has nothing to do with languages. Imagine that. Right? Many languages can be translated into Do-while. This is very, very important. Because this kind of 3D code is usually language-independent. So, in general, it will be used as an intermediate form of a central interpreter of an analyzer. For example, if I remember correctly, Huawei's Fangzhou Interpreter, including not only Huawei, but also other companies, their own analyzer, this static analyzer, in fact, their IR can absorb all kinds of front-end languages. That is to say, Java, C, or other native languages. Right? Then, through their front-end languages, it will be translated into a unified IR. Why can it do this? Unified IR is used to analyze, optimize, and then generate the machine code. Why can it do this? It's because 3D code IR usually has this kind of language-independent nature. But as for Fangzhou Interpreter, I don't know the specific IR nature. I haven't seen it in detail. But in general, IR has a kind of high-level language-independent nature. It can be translated into this kind of unified intermediate form. What else is different? As I said before, AST is suitable for doing fast type checking in programming. Because it is from the structure of the tree. When you are programming this tree, you can actually get the type, and then you can compare it. What is IR? It is compact and uniform. How do you understand compact and uniform? You can see it. We say compact is compression. It's very concise. You can write it like this. It's very uniform and concise. How can it be concise? For example, there are a lot of information about uniformity. Do well, boday, and so on. It's all gone. IR is more concise. It's gone. There is no information about uniformity. What about AST? Lack of control flow information. This is obvious. You see, you know it's a loop. The reason you know AST is a loop is because it says do well. You know its English. But you look at such a language. Can you see the loop information? You can't see it, right? It just means here. You can't see the loop information, the control flow information. But 3D programming is different. You can see the control flow information from the 3D programming code. For example, if the expression is true, go to 1, then go to 1, 1 is there, 1 is here. There is a control flow information itself. So, your contents control flow information is a very important feature of 3D programming IR. In other words, when your program is able to express a real intermediate format that can express a control flow information because what? Our so-called static analysis is actually based on your control flow, a little bit of the nature of the program. If you can express this kind of control flow naturally, it is more conducive to static analysis. At the same time, we said before you are compact, you are uniform, right? Then we said you are language-independent. So, these good features conducive to static analysis make 3D programming IR far more conducive to the form of AST as a basis for static analysis. Look at this sentence, you will consider it as the basis for static analysis. All right, this is why everyone, after all, you are specializing in this course. Maybe others know 3D programming IR is for static analysis. Then you have to ask them why. Then they may not answer. But you are a professional learning this course. You need to know why 3D programming IR is conducive to static analysis. So, in this slide, I will talk about this, all right? All right, after talking so much, let's take a look at what the 3D programming IR looks like. In fact, 3D programming IR does not have a standard formal definition. No. If you want to understand it, I will use this sentence to give an example for everyone to feel its concept. You don't have to be entangled in its specific form, all right? Here, I should be missing a T2 equals here. For example, there is at most one operator on the right side of the instruction. That is to say, if you have an instruction, you have two parts on the left and right. For example, it is an assignment. All right? For example, it says T2 equals a plus b plus 3. Look at this. The right part is equal to a plus b plus 3. How many operators does it have? There are two plus numbers. What is the requirement here? At most one. There can only be one at most. You can have two. So, it's not 3D, right? If I want to convert this kind of operation to 3D, how do I do it? To convert 3D, what do we need to do? We need to introduce a temporary variable. That is to say, we give a plus b to T1. There is no problem with this. There is only one operator for a plus b, right? Then, we add T1 to 3, which equals T2. This equals T2, and this equals a plus b plus 3. In fact, we can convert this 3D format. All right? If you have a instruction on the right side, there is only one operator at most. All right? After reading this, you may know that OK, I probably understand this form. But why is it called 3D? This name is so strange. You may have such doubts. We can simply understand it this way. This address is not the kind of address we normally learn in programming languages. In fact, it is just a concept. That is to say, each 3D instruction actually contains at most three addresses. These addresses can be of the following three forms. The first form is what we said earlier, variable names. For example, A, B, and so on. What else can it be? One of the elements in it can be the element of the address. It is a constant. The constant is 3, negative 100, 796, and so on. There is also a compiler generator. This is a compiler or a static analyzer that automatically generates temporary variables for you. For example, T1, T2, and so on. This address is such a concept. It is not a traditional address. So, in general, 3D instruction is a kind of intermediate form. In this form, if you have an instruction, there is only one operation on the right side of the instruction. There will be a lot of examples later to make you familiar with it. You don't have to learn this concept. Next, let's look at some common instructions. Each instruction corresponds to 3D instruction. Let's continue to look at this. Let's look at some common instructions in the program. What does the 3D instruction look like? Let's take a look. The first one is common. x is equal to y, b, o, p, z. x, y, z are the 3D instruction. It can be a variable name, a constant, or a temporary variable. It doesn't matter. What is b, o, p? Binary operation. Binary means to operate a global bank. It can be a billery to each function in the equation or logical manipulation. It can also be machine learning in languages. The Tank will be valid for unary operations such as negative operations, inverse of operations, or type operations. It doesn't matter. x or y are non-operative functions. There is always a non-operative function. Let's go to l. It is a form of 3D code. What is go to l? It is a conditional jump. We will see when we use a conditional jump. For example, in a loop. If x go to l, it is a conditional jump. It is a conditional jump. We will see when we use a conditional jump. For example, when you do if, when you execute different branches, or when you do while, you may have this form. This is also a conditional jump. For example, if x What is ROP? It is a relational operator. For example, greater than or equal to, and so on. If this expression is x, ROP is y. If this expression is true, we will go to l. l refers to the level that we mentioned earlier. A level to represent a program location. These are some common forms of 3D code. Does it sound a bit abstract? If I finish this slide, can you still understand 3D code? You are pretty good at it. This is a bit abstract. I will give you a concept in the form of theory. In fact, the real 3D code is much more complicated than it looks. Next, let's see what the real 3D code in the real world looks like. We will learn it by combining practice. In the so-called real practice, we will introduce SUIT. SUIT is the most popular and widely used in Java analysis. If you want to do research or start a company to analyze Java, you can't escape SUIT. The homework of this class is also based on SUIT. As SUIT, a popular static analyzer, what does its 3D code look like? It is called GIMP. GIMP is a typed 3D code. It is a 3D code. It is a bit different from the previous one. It needs to be typed. Because in Java analysis, Java has a type. You need to put the type in your 3D code. It will be very helpful for the static analysis later. Because in static analysis, you often need to use the type of language. Then, based on the language type system, you can further analyze it. Okay, let's take a look. In GIMP, in the 3D code of SUIT, it is called GIMP, there are some common 3D codes. Let's see what it looks like. To give you a real feeling, I wrote some examples. For example, if your Java source code is for loop, let's take a look at what the 3D code for loop looks like. Okay, from this slide, everyone's energy needs to be focused. Follow me line by line. This is also helpful for you to understand the real situation of the 3D code. Because it may involve some basic concepts of PR. If you need an explanation, I will simplify it. You can remember as much as you can. That is to say, I will... You can take a look at it in advance. I will talk so much. The main reason is if you want to learn all the 3D codes through this class, it is impossible. I think if you can learn it, it will be great. But it is not difficult. There are indeed students like this. I have been in this field for so many years. I don't have all the skills. But I hope that through these examples, I can cultivate a feeling for everyone. For example, if you want to learn music, you need to listen to more songs to cultivate a sense of music. If you want to learn English, you need to read more English articles to cultivate a sense of English. We can use a lot of practical examples to cultivate a sense of 3D code. Alright? In the future, if you encounter a real 3D code, you won't feel empty. It will be easier for you to understand. When you see a source code, you can imagine what the source code looks like. When you see the source code, you can also imagine what the 3D code looks like. Alright? We use a lot of practical examples to look at a real 3D code. Alright. The source code is package. Package is very simple. NGU, Nanjing University, Software Analysis, has a lot of examples. This class is called 4-loop 3D code. Let's see what 4-loop 3D code looks like. First, there is a function. The function is very simple. x is equal to 0. Then there is a negative cycle. In the negative cycle, int i is equal to 0. This is initialized. i is less than 10. i++. Then we add 1 to the x in the above statement. Alright? Alright. I'm a little nervous again. Can you hear me now? If you can hear me, please type a word to reply to me. Alright? I'm afraid I'll lose connection. OK. OK. Let's continue. You sound so serious. Let's see what 4-loop 3D code looks like. Look at the right side. We don't have to rush. It's OK if we can't finish this class today. We don't have to rush. We have to look at the string. r0. What is this? Let's look at the main function. What is written in the main function? A string. args. Right? This is also a string. In fact, it marks the type of parameter. Then r0 also refers to this parameter. You can see that this is a statement parameter. You can see that r0 is equal to the symbol hidden in the form of a special symbol. In fact, you can think of it as a sub-value. But this sub-value is not real. It's just a mark. But it does mean that I want to tell you that the value of r0 is the value of the parameter that is passed in. Then the parameter followed by the cap is its type. OK? It's a special mark. If it's an ordinary sub-value, a normal program sub-value, it's directly equal to a number. It's just a special sub-value. It marks it and expresses it with a special symbol. OK? I1 is equal to 0. What is I1? It's the I in the for loop. The initialization variable. OK? It's this I. All right. Level 1. I said it earlier. Right? There are some labels in the three-digit code to mark the position of your program. Right? OK. Let's see. If I1 is greater than or equal to 10, go to level 2. If I1 is greater than or equal to 10, go to level 2. Normally, we understand the loop. Look here. If I is less than 10, let's continue the loop. If I is greater than or equal to 10, let's skip the loop. Let's see. If I is greater than or equal to 10, go to level 2. Where is level 2? It's here. Then we skip the loop. OK? Then execute I1 is equal to I1 plus 1. This is also a 3-digit code, right? No problem, right? Then, after execution, it goes directly to level 1. It's here. That is, it keeps going to level 1 until it reaches level 1. It determines that I is greater than or equal to 10. Then it ends the loop. Level 2. Then it ends. Because this is a main function, it returns directly. This is easier to understand. Right? If a parameter is go to level, we can see the 3-digit code format in front of us. This is also a 3-digit code. Unconditional go to is also a 3-digit code. Unconditional go to is also a 3-digit code. OK. It's for loop in front of us. Let's look at the do-while loop. Some students may ask, what's the difference between for loop and do-while? 3-digit code. They are all loops. Let's continue. In here, do-while is a 3-digit code. Let's see. At this time, what else is there? First of all, there is an array above. There are 10 elements in the array. It's an int type array. Then, let's continue. Let's make a variable. i equals to i plus 1. Then we determine that the second element of the array is less than 10. Then we execute the loop. OK? Then, look at this. Isn't it different between i and x? What are i and x? Oh, you asked a question. Yes. It's not the same as the students. x is optimized in SOOT. It's optimized. It's like this. When SOOT is doing ASC in the front, it will do some optimization. When it's optimizing, we will see an example later. It will optimize this thing. It will feel that if you don't do this operation, it will be optimized. This is one of the examples. Let me see. If i equals to level, then it will add i to level. Why does it optimize? Let me see. I think it depends on the option of the step. It's possible. But this x, this normal x, I think, even if some students say that after the for loop, x is not used, it may be optimized. But I feel that this normal x, because it is used here, right? An x is used here. So normally, this x should not be optimized. But it's possible that some of the optimizations in SOOT will lead to such a result. That is to say, when x is equal to x plus 1, it will find that if you add a pair of x, what will you use in the end? Will you use it in the end? It may be optimized. It depends on a normal realization in SOOT. If i equals to x, let me see. If i equals to x, I don't think so. It won't be like this. It will look at the specific value. It won't do such a check. It's not like this. As for the optimization in SOOT, what does it do? This is not what we want to focus on. The optimization form, I guess it should be optimized. Otherwise, it won't be like this. I haven't noticed this yet. The student just asked a very good question. These are some details. What we pay attention to here is the loop. I mainly use this example to pay attention to the structure of the loop. Some students may ask in SOOT, can you not let it be optimized? Yes, there is such an option. I didn't pay attention to this example. Let's continue to look at the array. Let's see if the array has this operation. We see that the array is initialized. After initialization, the new array, a new R1, and then i equals to 0. This is like initialization. You can see the i1 in the array. This i1 is this i, right? And then this i, i plus 1. It is in the loop. It is not optimized. The main reason why it is not optimized is because the i in the value has been used. This may be the reason. Because this i is this i. It has been used, so it won't be optimized. This should be the reason. Let's continue to look at Lab1. i1 equals to i1 plus 1. This is it. And then $i0 equals to R1. What is R1? Let's say it is the new array. The new array. Okay. The i1 element is this i, right? It equals to $i0. Note that $ if you look at the variable, there is $ in front of it. It is a temporary variable generated by it. It is a temporary variable generated by the number. This is the general situation. How does it judge? If the value of this array is less than 10, it constitutes Lab1. You can see that the do-while loop is executed by the new array. Then it gives a temporary variable to the data element, right? If the temporary variable is less than 10, it constitutes Lab1. It executes the first loop. This is the same as the do-while loop. Right? It is the same. This is do-while. No problem, right? Let's look at MasterCode. MasterCode is a bit more complicated now. Let's look at this example. What does MasterCode look like in 3D? Let's look at it one by one. First, let's look at the negative. What is 3D in this equation? Let's look at what is written in this equation. It is actually very simple. It returns a string. Then there are two parameters. One is parameter1 and one is parameter2. Parameter1 and parameter2 are all string types. Then it returns a string. What is this string? The first parameter plus a space plus the second parameter. Okay, let's look at so many.\n"
     ]
    }
   ],
   "source": [
    "audio_file_2 = open(\"./11-Audio-Summary/audio/lec02/lec02-25m-50m.m4a\", \"rb\")\n",
    "translation_2 = openai.Audio.translate(\"whisper-1\", audio_file_2)\n",
    "print(translation_2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66d96d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does the AR of the corresponding suit look like? There are so many. Let's take a look at them one by one. First of all, what does it say in the front? The variables and types of variables to be used later. We will not go into details. Let's take a look at the real sentence. Let's take a look at R02. What is the type of R02? It is NGOSA example-matched-coset. This is the type of R02. Why is R02 this type? It wants to... Have you learned about this before? This is an instance method. Each instance method has its own this. This refers to the current object in the array. It will be used as a receiver object. So it gave the value of this to R02. Next, let's take a look at R1 and R2. R1 and R2 each have parameters 1 and 2. Let's take a look at this. It generates a java.lang.streambuilder. Why does it generate a streambuilder? What does the suit do? It does this based on the language of Java. So what does this mean? You can think of it as a kind of syntax. It is very simple. It is a string variable plus a string constant plus a string variable. What does this syntax mean? It means that java uses a streambuilder object. You can think of it as a kind of syntax. It uses a string builder object to generate a string. Finally, it returns a streambuilder to a stream. Let's take a look at it. First, let's convert this into a real execution. Let's start with a streambuilder. Let's use a new streambuilder object. Let's call it $R3. What does it do? It generates a special invoke. What is a special invoke? It is a virtual invoke. Let's take a look at it. Let's take a look at the four main methods in JVM. It is very simple. In JVM, there are four commands. In this example, there are two commands. There are four commands. What are they called? They are called special invokes. The real JVM command is the opposite. It is special invoke special. What is this command? It calls a constructor. Why is it not called invoke constructor? It is called invoke special. Because it not only calls a constructor, it also calls a method called superclass. In Java, there is a method called excisor. It is a private method. It is also called by this command. This is a simple example. What else is there besides invoke special? There is also invoke virtual. Invoke virtual is similar to invoke interface. What is invoke virtual? It is a common method called instance method call. It is a common method called instance method call. When it is called, it will check the table and find the corresponding method. Because it is a virtual call, it will do virtual dispatch. In Chinese, it is called dispatch. Interface is similar to invoke virtual. However, invoke interface is not like invoke. Invoke interface calls the interface method. It does not call a class method. It does not do some optimization. At the same time, invoke interface also does some checking. What is checking? For example, when you implement an interface, you need to implement all the methods provided by the interface. When you implement an interface, you need to implement all the methods provided by the interface. It will check whether you have implemented it or not. It will check whether you have implemented it or not. It has more operations than invoke. In fact, it is very similar to invoke. However, it has more operations than invoke. It cannot do some optimization. It can only call the command and do some optimization. You don't need to understand the details. It does not need to do some optimization. What is another type of invoke? Think about it. If you have a common instance method, you will have static method. There is also an invoke static command. It will call the static method. In fact, after Java 7, In fact, after Java 7, there is another invoke called invoke dynamic. It has nothing to do with the programmer. It is just for... Let's understand it. We know that JVM is a good operating system. We know that JVM is a good operating system. Not only Java, but also Javascript and Python can run on JVM. but also Javascript and Python can run on JVM. What is Java? It is a static language. JVM is a natural language. JVM is a natural language. You can use some of its original commands. You can use some of its original commands. However, if you want to implement a dynamic language, However, if you want to implement a dynamic language, and let it run on JVM, and let it run on JVM, you need to do a lot of language conversion. By using invoke dynamic, you can run on JVM in a more convenient way. You can run on JVM in a more convenient way. You don't need to understand the details. I just want to give you a brief overview. I just want to give you a brief overview. We will see invoke special and invoke watcher later. Don't panic. It is the default command for JVM. It is the default command for JVM. Java has introduced a new dynamic command. Java has introduced a new dynamic command. We will go over some of the things we discussed today. Back to the topic. We talked about special and invoke in a previous video. We talked about special and invoke in a previous video. What is special and invoke? What do we do when we do something? What do we do when we do something? We can do compiler function. The Compiler function is r3 and new object. The Compiler function is r3 and new object. The Compiler function is r3 and new object. How to use the compiler function? There is a brilliant bounded nucleosale. There is a brilliant bounded nucleosale. We refer to this compiler function as method signature. We refer to this compiler function as method signature. Method signature is a new周目 a new code. It is a new content name. This is the signed motion reference. This is the signed motion reference. And the sigribtle repeats in a passing pattern. This is the method signature. This is the method signature. In the future, you will often see method signature in some English documents or foreign blogs. What does method signature include? In general, method signature includes the class name of the method. the class name of the method. It also includes the return value of the method. If there is a return value, it is the return type. If not, it is the void. In general, some method signatures include the class name. Some do not. But in this case, it includes the parameter types. it includes the parameter types. There are several types of parameters. For example, parameter1 type parameter2 type parameter2 type There are several types. There are several types. They are called method signature. What we see in this parenthesis are method signature. Javascript is a stream builder. Now parameters can only have parties that differ from one another. parameters can only have parties that differ from one another. default numbers have no name. unify indicate. default numbers have no name. Nothing happens in the file! nothing happens in the file! nothing happens in the file! nothing happens in the file! This is a definite catchphrase! Another catchphrase in JavaScript! wooshorimorg This is a a stream builder This is a a stream builder method signature method signature methods in Python JavaScript java.streambuilder append java.streambuilder re re re re re re append append append append re re re re re re re re r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r\n"
     ]
    }
   ],
   "source": [
    "audio_file_3 = open(\"./11-Audio-Summary/audio/lec02/lec02-50m-75m.m4a\", \"rb\")\n",
    "translation_3 = openai.Audio.translate(\"whisper-1\", audio_file_3)\n",
    "print(translation_3['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fa0fca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would like to show you how to convert SSA into a classic AR format. Let's take a look at what it says. It doesn't matter if you don't understand. Just listen to the general meaning. What is SSA? All assignments in SSA are to variables with distinct names. It will give each definition a fresh name. Then it will propagate this fresh name to the next assignment. For example, p equals a plus b, q equals b minus c, etc. This is a 3-digit code. What about the 3-digit code of SSA? It will give each variable a new definition. For example, p equals p1 plus a plus b. q becomes q1. This p1 is actually used as p1. But this second p is called p2. It will give each definition a fresh name. This q1 is used as q1. But this p is used as p2. The display tells you that this p2 is this p2. And this p3 is this p3. It will give each definition a new name. It is like a sub-target. It says that every variable has exact one definition. Some students may ask, does this mean that every variable has only one definition? Some students may ask, does this mean that every variable has only one definition? For example, if the variable is used here, then the left side is actually x equals 0, x equals 1. Now you have become SSA. x0 equals 0, x1 equals 0. Is this x0 or x1? Didn't you just say that x only has one definition? There is only one name, right? One definition. What should we do in this case? In this case, SSA will introduce a phi function. The phi function is a bracket. If x0, x1, x2 is x0, x1, x2. This function actually tells you to define x2 first. Then you use x2 in the back. Its meaning is that the left side is x0 and the right side is x1. As for the function, how to analyze it, there is a corresponding algorithm. We won't go into details here. So if you want to remember SSA, you need to remember two things. The first one is that each variable has its own definition. The lower bound is p1, p2, p3. Here is p1, p2, p3, q1, q2, q3. If you want to use a multi-layer function, you don't know which one to use, then it will introduce a phi function. These are the two features of SSA. Just remember these two features. It doesn't matter if you don't understand the other things. You probably know what SSA does. Now let's talk about why we use SSA. Why don't we use SSA? Because it's easy to say, but hard to do. In fact, SSA, the content of this lecture can be skipped. Let me make it simple. But I am afraid that some students or some professionals are engaged in modern analysis. If they can understand these things, maybe these things will provide some information to them. We say flow information is indirect. It can indirectly be reflected in the unique, the exact definition of a variable. In this way, we can integrate the flow information indirectly. What does it mean? It can help you design some analysis. For example, the command we see now, which is flow sensitive. A train carriage, carriage 1, carriage 2, carriage 3, carriage 4, carriage 5, carriage 1, carriage 2, carriage 3. Each carriage is coded. But if the flow is insensitive, in fact, when you analyze the program, you don't consider the order of the sentences. You imagine a train carriage as mahjong. You mix mahjong together and analyze it. It's OK. It's actually a speed and a frequency balance. If you want to be sensitive, you have to consider a procedure execution order to maintain such a information. This will be more efficient. We mentioned earlier what we are analyzing now. To ensure the speed and frequency balance, if the flow sensitive is large, the speed will be slow, but the frequency will be good. What about the flow insensitive? If you don't consider the execution order, the speed will be fast, but the frequency will be slow. But if you have SSA, for some analysis, the flow insensitive will get some frequency of flow sensitive. Why? If the flow is insensitive, you are disturbing the analysis. But each name has its own definition. When you use it, you will only use the P in front. Then you use P in the back. You know this P is that P. In fact, this variable name has a little bit of flow information. Next, define the user pairs are explicit. This is more obvious. When you want to use a variable name, you will directly go to its opponent. Then some optimization methods will be easier to do on this basis. So why don't we use SSA? Let's talk about it. As you can see in the front, it wants to disassemble this thing. Each variable has its own definition. Then it will introduce too many variables. If there are many differences, it will introduce too many functions. And when you switch to SSA, you have to switch to DirectX to execute. When you switch back, it will introduce a lot of inefficient problems. I won't talk about this example. Because this whole SSA is just to make it clear. As long as you have some concepts, it's fine. Next, let's talk about a very important concept. We talked about the 3D code earlier. What does the 3D code do? We talked about the 3D code. We said that it will eventually be converted into a control flow graph. Then static analysis is generally based on the control flow graph. Next, let's talk about control flow analysis. How do we define the 3D code of a program? How do we build the corresponding control flow graph? Let me give you an example. This example is just a form. We will continue to look at the details of this example later. Let's say that the input of this example is a 3D code. A program P is a 3D code. Let's say it looks like this. What we want to do is to convert this arrow into a form of a picture. You can see that there are edges and nodes. In fact, this is a program. This is the corresponding control flow graph. How do we do this? As I mentioned earlier, this picture is the basic structure of all static analysis. Let's take a look at the node in this picture. As you can see, this node can be a single command. It can also be like this. We can put some commands together in a certain way. We call this a basic block. Since there are a lot of static analysis, the control flow graph used is a basic block. It can be used as a node of this picture. So I think it is very necessary. Let's talk about what a basic block is. Let's use an example to understand the concept of a basic block. It may be easier. Let me put it simply. A basic block is a maximum sequence of continuous 3-digit commands with the properties. The maximum sequence of continuous 3-digit commands. What does this mean? For example, if we want to construct a basic block with these four commands, it should meet the following characteristics. It can be entered only at the beginning. What does this mean? What is beginning? It is the first command of this block. In other words, if we want to construct a basic block with these commands, this basic block has only one input. This input must be the first command of this basic block. In other words, there is no other input, no other control flow, which can be introduced from somewhere else and go to the second or third node. This is not allowed. For example, if you want to go to a label, what if you want to go to b, which is equal to xii, what should you do? This is the input. Therefore, if you want to construct a basic block with these commands, it should meet the following characteristics. First of all, it has only one input, which is the first command of this basic block. Secondly, it should meet the following characteristics. The output of this basic block should be the last command. In other words, the output should not be able to go from b, which is equal to x plus a, or the second or third command in the middle, or the first command. This is not allowed. In other words, the input is the first command, and the output is the last command. These are the characteristics of the basic block. That's it. OK. What did I say before? I said that we want to convert the 3D code into a control flow graph, right? We said that if you want to build a graph, you must build a graph node. What is this node? It is the basic block. We are talking about the example of the basic block. First of all, we need to figure out how to compile the 3D code into the corresponding basic blocks. How to build the basic blocks? I can tell you the algorithm directly. Then you can follow the algorithm. Generally speaking, you can say this. But I don't want to. Even if we don't have enough time today, you can spend some time to think about it yourself. Otherwise, how can I say this? You have to think about it yourself. Otherwise, you will always learn from others. If you change something, you will do it according to the rules. It's meaningless. You should learn to take the initiative. Now I want to change another 3D code. Let's say this is the 3D code. Tell me. If you design the algorithm to generate the 3D code, the algorithm to generate the basic blocks, for example, which few instructions can form a basic block, which few instructions can form a basic block, how will you design this algorithm? Let's think about it now. You don't have a clue. You have to catch the clue. This is how the problem is solved. You have all participated in a college entrance exam, right? In math, in the last application, the third question is usually very difficult. Everyone feels that they can't answer it. But if you want to score, what do you do? Do you collect all the conditional conditions? See if you can answer one step at a time. We can. We can also adopt this strategy when we design algorithms. What are our conditional conditions? It's a definition of base cloud. What character is it? There is only one entrance, right? The first instruction can't let others in. There is only one last instruction at the exit, right? It can't go out from other places. Okay? You can try this. Let me guide you to design this algorithm. For example, the first one, can it be used as a basic block? The instruction. But don't forget that it can only come out from here. But there is another premise of a basic block. It is a maximum sequence that meets the two characteristics of these continuous instructions. Right? It is a maximum sequence, right? Obviously, it can't be used as a basic block. But let's say if we put in 1 and 2, it can also be used as a basic block. Then we should add 2. Because it is a maximum sequence. Right? Okay, 2. Let me ask you a question. Is 1 and 2 enough? It came in. Right? There is only one entrance. There is only one exit. Is it enough? Okay, let's keep asking. If it is the maximum, can we add another instruction? No. What is the reason? It's because let's see. How many entries are there? 30. 30. In other words, let's look at it from a different perspective. There is an unconditional jump. It only jumps to 3. That is to say, if you combine these three into one basic block, there will be two entries. It can't be combined into one basic block. Right? This definition is not satisfied with this condition. So the first basic block only includes the first two rules. From the first example, we cannot get this conclusion. Let's see if we can expand this. If an instruction is a target of a jump, for example, 3, can it only be an entry of a basic block? First of all, if it is not, we can use the antithesis method. If it is not, let's say it is in a basic block and it is not an entry yet. Then, if it can enter through Go to 3, another program can enter from there, then this basic block must have an entry of one or more, right? That is not true. So, from this example, we can see that the instruction of a jump should be an entry of a basic block. In this way, we can ensure that every basic block has an entry. OK, let's continue. 3, OK, can 4 be added? Let's see, it can only enter from 3. OK. 2, it can enter from 3, right? It can enter from 3. The jump in front can only enter from 3. OK, so far, the entry is only 3. Go to 7, it can enter from 7. No problem. 4, it can enter from 5. No problem. It can only enter from 4. No problem. OK, let's see if 5 can be added. Think about it. Can 5 be added? Answer me. As a member of the 3, 4 basic block, can 5 be added? The fifth instruction, based on this instruction, can 5 be added? OK, very good. The student said no, no. The reason is that you may get this point. It's because the exit is out. Very good. Very good answer. We said this is 1, 2, 7, right? It's here. If 5 can enter, this exit is here, right? There are two exits. It doesn't work. Very good. From this example, it's not difficult to say that the second basic block can only enter from 3, 4. It's not difficult to say. In fact, if a instruction only follows a jump, it should also be a basic block entry. Why? Think about it. If a jump, as the last instruction, jumps out, if you also include 5, it means there are more than one exit. So, if you only follow a jump instruction, then you should take it out as a basic block entry, right? OK. Now, we have this information in front of us. Let's take a look. In fact, you can get the point of this boring algorithm. Let's see what the algorithm looks like. We said how to build a basic block on a 3D code. The input must be the 3D code. The output is the basic block in the program. Let's see how to do it. First, you have to decide the leader of each basic block. That is, where is the first exit, right? Of course, the first instruction in the program is an exit. A basic block is an exit. OK. Any target instruction of a conditional or unconditional jump is a leader. As I said before, the example of 3, right? This example, this 3, is it a conditional jump or unconditional jump as a target? Then it should be a leader, right? Similarly, let's continue. Any instruction that immediately follows a conditional or unconditional jump is a leader. That is, if the instruction follows a jump directly, it is also a leader. As we know, this 5 immediately follows this 4, right? A jump. Therefore, it should also be a leader. What is the purpose of this algorithm and this sentence in the front? As I said before, it is to have the only entry. This sentence is to have the only exit, right? OK. We have the entry. We have found the entry of each basic block. The basic block is easy to see. What should we do next? Each basic block has its entry and the next basic block has its exit, right? This is the process. Let's take a specific example to see. OK. Let's take a specific example to see. In fact, if I don't guide you to think, you will find this algorithm very boring. But if I guide you to think, you will find that this algorithm is very easy to remember. Let's take an example. OK. According to the algorithm of basic block, we need to determine what each basic block leader is. What is the first instruction? The first instruction should be a leader, a basic block and an entry. First, E is an entry. No problem, right? OK. Let's add E. E is an entry. What is the second rule? We say any target instruction of conditional or unconditional jump is a leader. That is, if you use this instruction as a jump no matter what it is, as a jump it is a jump target it is a leader. In this program, let's see which one on the left. Let's see. A jump target Let's see. Let's find all jumps. Go to 7. 7 is a target. OK. 12 is a target. 3 is a target. It seems we have three new entries. Right? 3, 7, 12. No problem. OK. Let's add them and go on. The third rule is any instruction that immediately follows a conditional or unconditional jump is a leader. Let's see. The next jump should be a leader. Let's see. The next jump should be 4. The next jump should be 5. The next jump should be 11. The next jump should be 12. Right? 5, 11, 12 should be a leader. 1, 3, 5, 7, 11, 12. Right? What's the second step? Build a basic block. The basic block consists of a leader and all subsequent instructions until the next leader. Let's see where the leader is. If we have these leaders, we will have these basic blocks. No problem. OK. 1. It's 2 until the next leader. Right? The entry. 3. The first one should be 5. So, 3 and 4 should be included. The same. 7. 5 is 5 and 6. 7. The next leader is 11. Right? 7, 8, 9, 10 should be included. 11. 12. No problem. OK. This is our output. We can build basic blocks with this output. We will follow these instructions to build the following basic blocks. OK. Basic blocks. So, what do we do in the end? Build control flow graph. Build control flow graph. This is just the node of the graph. What do we do next? Build the edge. You have nodes, but you have to build the edge on the graph. Right? So, let's see how to build control flow graph with basic blocks. It is relatively easy. Why? Let's take an example. If we want to build the edge between A and B, how do we build the edge? If the structure says I and I is the first instruction of A and A is the first instruction of B, how do we build the edge between A and B? If A and B is the first instruction of A and B, how do we build the edge between A and B? If the structure says A and B is the first instruction of A and B, how do we build the edge between A and B? If the structure says A and B is the first instruction of A and B, how do we build the edge between A and B? If the structure says A and B is the first instruction of A and B, how do we build the edge between A and B? If the structure says A and B is the first instruction of A and B, how do we build the edge between A and B? If the structure says A and B is the first instruction of A and B, how do we build the edge between A and B? If the structure says A is the first instruction of A and B, how do we build the edge between A and B? If the structure says A is the first instruction of A and B, how do we build the edge between A and B? If the structure says A is the first instruction of A and B, how do we build the edge between A and B? If the structure says A is the first instruction of A and B, how do we build the edge between A and B? If the structure says A is the first instruction of A and B, how do we build the edge between A and B? If the structure says A is the first instruction of A and B, how do we build the edge between A and B? If the structure says A is the first instruction of A and B, how do we build the edge between A and B? If the structure says A is the first instruction of A and B, how do we build the edge between A and B?\n"
     ]
    }
   ],
   "source": [
    "audio_file_4 = open(\"./11-Audio-Summary/audio/lec02/lec02-75m-100m.m4a\", \"rb\")\n",
    "translation_4 = openai.Audio.translate(\"whisper-1\", audio_file_4)\n",
    "print(translation_4['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82fca518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If B5 says go to B2, then B5 goes to B2 to make the change, right? This is not a problem. Then how can we make the change? B immediately follows A in the original order of instruction of A. It was A that followed B in the original order of instruction of A. But what does this mean? A does not end in an unconditional jump. Here, we only have one unconditional jump, which is go to B2. That is to say, originally, the return is a direct follow-start, but it is an unconditional jump. So except for A, the rest of them are all conditional, and can be handled uniformly. It is a direct addition. Because B2 follows B1, B3 follows B2, B4 follows B3, B5 follows B4, B6 follows B5, but B5 ends with an unconditional jump. After the addition, let's look at a simple definition. If A and B finally add up, we call it A is the forward area of B, and B is the background of A. Then you can see that a basic block can have multiple forward areas, such as B4, which has B3 and B2 forward areas. A basic block can also have multiple background areas, such as B2, which has B3 and B4 background areas. This is the concept of forward and background areas, predecessor and successor. Is this kernel-free graph over? No, we need to add two special nodes. What are these two nodes? One is called entry and the other is called exit. This is the command of the real program representative. However, entry and exit do not correspond to the real executable IR. What is the purpose of its introduction? To make it easier to design, initialize, and so on when designing algorithms. What is an entry? An edge from entry to the basic block containing the first instruction of IR. What is this example? Let's add one here. In general, there is only one entry in the MEN function. In other words, the entry is basically a single edge to the first instruction of the MEN function. But sometimes, when you go out to analyze, sometimes you need to initialize or multi-thread, different programs may have multiple edge edges like this. But our understanding of the whole course is that it is one edge. Can you understand it this way? But there may be a lot of initial edges. What are initial edges? An edge to exit a node from any basic block containing an instruction that could be the last instruction of IR. Could be. What could be? For example, in the MEN function, it says if some return, if some return, if some return. There are a lot of returns, so there can be a lot of initial edges. But in this example, there is only one return. There is only one initial edge. This is the exit. Alright. On the left, we have a complete control flow graph corresponding to this example. Let's review. In the previous part, we learned what is a 3D code, and how to build basic blocks based on the 3D code, how to add edges to basic blocks, and how to generate a control flow graph corresponding to the same 3D code. Alright. So far, we have learned the final form of IR. The static analyzer basically has to be designed on the control flow graph. Alright. To sum up, Oh, it's okay. I'm done. To sum up this course, we first talked about the relationship between a compiler and a static analyzer. This is to make it easier for everyone to understand what the position of a static analyzer is. For those of you who are not familiar with compilers, it's okay. It's okay if you don't understand it. You just need to remember that a static analyzer needs an IR. This IR is different from AST. Alright. That's it. We introduced the advantages of AST and IR. Why is 3D MRI IR the kind of IR that we generally use in static analysis? I've already talked about the second part of this course. Alright. In fact, in my first slide, I think the designer has already summarized some of the key points of a static analyzer. I think if you learn to use a static analyzer, you will need to review the things you don't understand. You should remember the slide. Why? I think this is like a compiler. You can't remember a lot of things, but the basic structure, the concept of understanding the corresponding things, and the basic flow should be understood clearly. For example, last year, I interviewed a student who came to Nanjing University for a postgraduate study. I asked him a lot of questions. Many students who have studied compilers did not answer. It's the thing in that picture. They can't answer. So you can take a closer look at that picture. Alright. After we talked about 3D MRI, what did we talk about in the fourth part? We talked about SOOT as a static analyzer. What does it look like in all kinds of 3D MRI? Let me give you a key example. I have already told you about the complex problems. I have also introduced them in detail. I have also given you some knowledge about PL and JVM. So how much can you understand? How much can you understand about PL and JVM? This is mainly to make you familiar with 3D MRI. How does the 3D MRI look like in a real 3D analyzer? In other words, what kind of ability do you need to master? It's about looking at 3D MRI for a long time. You probably know that the source code should be like this. When you look at the source code, you probably know that the 3D MRI should look like this. You don't need to know everything. I can't do it either. So as a beginner, it doesn't matter if you can't understand the fourth part now. It doesn't matter in this class. But I think if you are going to work in the field of static analysis in the future, I have given you so many examples in the fourth part. I hope I can give you a good foundation and let you go back in time to see the real code. It will also help you learn some PL knowledge. Okay, that's the fourth part. The fifth part is about learning. It doesn't matter how much you understand. It doesn't matter to our course. The sixth part is about the basic blocks. This is more important. How to build some basic blocks on the 3D MRI? Because some control flow graphs are based on the basic blocks. Then how to build control flow graphs on the basic blocks? We also talked about it. This is the content of the above course. There is no homework in today's class. So you need to remember what I said above. In fact, I also mentioned it in the summary just now. You can sort out these points by yourself. Look back at the course. Today's class is very complicated. Many algorithms are also quite boring. But I feel that if you can master these knowledge points, I don't think it will be a big problem. If you can understand about 60% of these lessons, I think it will be quite successful. Because there is a lot of information today. There are also a lot of things related to professionals. Then we can watch the second and third lessons in different ways. Or watch the video to further consolidate. Okay, thank you for your encouragement. That's all for today's class. I will continue to talk to you as usual. If you have any questions, you can ask. I will leave you 5 to 7 minutes. Oh, my throat. I'm still not experienced. It's so tiring to talk. Did I make myself clear? If you think so, that's good. Do you have any books for static analysis? Why did I start this class? I really don't have any books to recommend to you. I don't think there are any good books. Can I add a group of students? That group must be male students. As I said before, the group is just to put the courses. I will put the courses on the Internet. Everyone can visit it. What is Gimp? You just said optimization. We are talking about optimization now. There are two explanations. I think the optimization is a bit strange. If it is optimization, it should not be removed. But it may be forced optimization. There is another explanation. I just mentioned it in the middle. It may be that I posted the wrong picture. But the probability is relatively small. But this is not important for understanding our class. This is a very detailed thing in Gimp. About whether it is optimized. You have to read the article. Or you can take an example and try it yourself. You can look at it. What is the practical use of static analysis? You can see the first class. You will know. It is very useful. Because many companies have their own research and development team. They specialize in static analysis technology. To analyze the reliability and security of the company's software. If the company is not rich. But if the software needs reliability and security. It will also use the software of some static analysis companies. To pay. To analyze their code. What do you mean by Gimp? What does Gimp mean? What does Gimp mean? I don't know. Gimp. Simple. I don't know what it means. It is said that the company analyzes the reliability of the data. Different companies have different software and different analyzers. Gimp is a Java compiler? It is possible. Gimp is a Java compiler? It is possible. I don't know. I don't know. How to evaluate? I don't evaluate. Someone wants me to evaluate Wang Yin. What do you think? I remember someone said in the last class. It's too much. It's too much. If you really want me to evaluate. Wang Yin. I personally think. From the perspective of PL. In PL. In theory. I think he is much better than me. Much better. From the perspective of PL. In terms of understanding. I think they are much better than me. So if you want me to evaluate him. If you want me to evaluate him. I don't evaluate. We are talking about PL. He is much better than me. I can only say this. I think. Of course. We are talking about PL. I am not talking about pure theoretical PL. I am not talking about static analysis. I don't understand static analysis. I haven't seen any article about static analysis. Context sensitive. Context sensitive. This. Normal context sensitive. From the academic point of view. Context sensitive is used a lot. In the company. Sometimes they think context sensitive is slow. Because the speed and accuracy are balanced. Once it is sensitive. The speed will be destroyed. The company may not be able to afford it. Sometimes they use context sensitive. I don't know. Any other questions? Any other questions? Yes. The live streaming is on Wednesday. 10am. 10am. I will be online at 10am. There are many things. Sorry. Very sorry about it. Many students. Are you from Nanjing University? I think many students are from Nanjing University. Okay. Okay. The thing is. The first year. We didn't give a lecture to the students. We gave a lecture to the students. But actually. This lecture is also for the students. You can listen to the lectures. How much does static analysis care about the type? For example, Java. How to say. The type. Static analysis is very concerned about the type. We will talk about it later. I think we should talk about the part of Sardinian. I think we should talk about the part of Sardinian. How to use the type system. To analyze the Java program. There are more than 20,000 people. I don't know. Is 20,000 people high? What is 20,000 people? I don't know how to calculate it. Okay. Next time. I will make it a course for you. It doesn't matter if you read more. It doesn't matter if you read more. It doesn't matter if you read more. You are right. Any questions? Any questions? I am going to cook. I am hungry. Any questions? Any questions? That's all for today. That's all for today. Thank you. Bye. Thank you.\n"
     ]
    }
   ],
   "source": [
    "audio_file_5 = open(\"./11-Audio-Summary/audio/lec02/lec02-100m-end.m4a\", \"rb\")\n",
    "translation_5 = openai.Audio.translate(\"whisper-1\", audio_file_5)\n",
    "print(translation_5['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7bb37",
   "metadata": {},
   "source": [
    "## Lec03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a8bf9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, let's start the class. This is our third class. Hello everyone. I shouldn't say everyone. As far as I know, there are some software engineers from the IT industry and some teachers from universities in this live stream. So I'll just say hello everyone. I'm a little nervous since you are here. This is my first class. I just finished this class. I'm still under a lot of pressure. Thank you for your support. Before we start, I'd like to talk about two things. In the last class, we talked about suit. In suit, we saw an example of the three-digit code of IRJIMP. We saw that the two-digit code killed the X code. I thought it was a weird optimization. I thought it was the suit. After the class, I checked with Mr. Tan. I found out that it was the suit. It was a weird optimization. Actually, we used Java C to kill the suit. Our student, Xu Daohan, received a post on the Internet. He asked suit about the same situation. One of suit's guardians, Professor Bowden, also thought it was a weird optimization. He thought suit shouldn't be optimized like this. I'm not sure if they are still working on it. It's just a small difference from the last class. I'd like to clarify it. I'd like to clarify it. It has nothing to do with our class. It has nothing to do with our class. It's just a detail in suit's practice. I'd like to talk about another thing. I'm using a live stream with a live streamer. The left screen is for our class, which is my PDF. The right screen is for the live chat. During the live stream, some students asked questions. Some students asked questions. I was watching the class but the chat was cut off. So I couldn't answer the questions. So I couldn't answer the questions. So I couldn't help answering the questions. So as time passed, my teaching would get cut off. So, if there is an issue, please make your feedback as short as possible. If you feel okay the schools are still teaching, please make your feedback as short as possible. This is another thing I want to talk about. Today, we are going to talk about the third part. We are going to talk about Dataflow and ICS. Dataflow and ICS is a data flow analysis. I personally think it is the most basic knowledge system in static analysis. It is also a very important part. If you have studied programming, some professors may spend a few lessons to talk about data flow analysis. It is a technology in programming. I believe most of you are familiar with data flow analysis and applications. I believe most of you are familiar with data flow analysis. You may have read Long's book. It is about data flow analysis. But, if you are not familiar with data flow analysis, you may not understand what it is. I think you can understand data flow analysis from the perspective of static analysis. Data flow analysis is a technology in programming. You can understand what it is. If you study data flow analysis from the perspective of static analysis, you will understand what it is. From the perspective of static analysis, it is difficult to understand data flow analysis. For example, I have prepared three and a half to four classes for data flow analysis. I have just finished today's class. So, I have to spend two hours to explain data flow analysis. For example, it is difficult to understand some concepts in data flow analysis. For example, lattice, what is the largest and the smallest movement point? What is the relationship between mass analysis and over-approximation? What is the relationship between monotonicity and distribution? What is the relationship between MOV and MIP? When I started to study data flow analysis, I did not have good data. It was very difficult. So, I am going to explain it in detail. First, today's class and next week's class, I am going to spend one and a half to two hours to talk about application. Then, I am going to spend one and a half to two hours to talk about foundation. In my opinion, it is good for you to learn it in detail. Because, you can say that static analysis is more advanced. For example, some of you may think that your class is about static analysis. But, if you are a professional in static analysis, you need to learn it in detail. Once you understand it, you can say that you have mastered a core part of it. So, if you have a chance to work in the field of static analysis in the future, I think it will be very good for you. It is like when you are good at math, you will have a good foundation in computer science. It is a similar comparison. Actually, today's topic is dataflow analysis. If you really want to understand and master the specific algorithm and details of dataflow analysis, it is not easy. In this 1.5 to 2.0 course, I am going to talk about three classic dataflow analysis applications. Reaching Definitions, Live Variables, and Available Expressions. These three applications represent three different types of dataflow analysis. Reaching Definitions, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, Live Variables, And Actual Videos. A touch on matching patterns and using data flow analysis to understand the core of technology. After understanding this, you can fill in the knowledge in the knowledge frame. It will be easier to understand later. In the second part, we will talk about preliminaries. We will learn some basic concepts and knowledge. We will talk about some formalized mathematical symbols. You may feel that there are too many formalized things in PL. It is hard to understand. Sometimes, we don't know how to define a mathematical symbol. Of course, some of PL's work is to simplify things. But I think we should be rational. We will learn some simple formalized things. We should not reject them. In PL, and in many other courses, we use formalized things to define things. It is for simplification, and accuracy. In fact, we use simple mathematical symbols to define complex concepts. It is for communication. If you have been in this field for a long time, and you often see these symbols, it means that they are hidden in your mind. They are part of your knowledge. It is easier for you to read many articles So, don't reject the second part. In the first part, we use some mathematical symbols. In fact, the concepts they describe are simple and easy to understand. In today's class, I will talk about 1, 2, 3 parts. The first part is the simplest mathematical analysis. We don't want to talk too fast. We prefer to talk slowly. As a basic course, most of our students are undergraduate students. Some of them have never been a senior student. So, I want to take care of these students. If you know the concepts, you can review them. Or you can listen to them in more detail. Don't worry. I want to explain these concepts clearly. Let's get started. Data flow analysis is very simple. There are three English words. When we first understand these words, can we use a better and easier way to understand them? We can simply expand these three words. In fact, how data flows on CFG CFG stands for Control Flow Graph. In the last class, we talked about converting source code into 3-digit IR. In fact, most of the 3-digit IR is converted into Control Flow Graph. Most of the data analysis is done on Control Flow Graph. In other words, most of the data analysis is done on Control Flow Graph. Data flow analysis looks at how data flows on Control Flow Graph. I will continue to expand these words. I will not ask what kind of data flows on Control Flow Graph. In fact, I will talk about application-specific data. Application-specific data is a kind of data that can be easily analyzed. It is not necessary to talk about application-specific data, unless I explain it in detail. I will not talk about application-specific data. It is hard for me to answer you. Please understand me. I am not very good at talking about application-specific data. So, I will talk about application-specific data later. Application-specific data is a kind of data that can be easily analyzed. It is not the same as data-specific data. For example, we find a variable with positive, negative, or zero values. What is the data we are interested in in application-specific data? If the data is positive, the positive values are negative. What is the flow through the CFG? The flow through CFG is a statement or statement made up of basic blocks. The so-called BNs are control flows. The flow through CFG has a series cycle. This is the information of the control flow. Let's go back to the first lesson. We talked about most of static analysis sacrificing completeness to a sound but the precision cannot be guaranteed. The majority of static analysis is like this. Technically speaking, static analysis can be grasped from two aspects. One is data abstraction. The other is overall approximation. In other words, when the program is dynamically running, no matter what input is used to produce the data, the static analysis should be automated. This is called sound analysis. In this lesson, we are going to talk about a small group of analysis. They are not sacrificing completeness to a sound. Instead, they require accuracy. This is called masternization. Let's move on. As I said before, overall approximation is based on most of static analysis. We call this meganesis. What does it mean? Let's look at these two simple descriptions. After reading the concept in the black box, it doesn't matter if you don't understand it. In the following lessons, we will talk about meganesis, which is the most common static analysis. They are output information that may be true. Masternization is output information that must be true. It is easy to understand. Meganesis means the information may be correct. So, what should we do? For example, let's look at the example in the first lesson. Let's imagine a branch. The left part is x, and the right part is minus x. Is x positive or negative? You must answer it may be positive or negative. You can't ignore any possibility. Therefore, you must consider all possibilities. This is meganesis. Masternization is the output information that must be true. In other words, if the information is not true, it will be wrong. It is not like meganesis. In meganesis, you must answer all possible answers. Otherwise, it will be wrong. This is the difference between masternization and meganesis. In the first lesson, we talked about soundness and completeness. If the information must be true, it is called end-approximation. In fact, it is to ensure the accuracy of the information. For example, if the information must be true, it is called end-approximation. In meganesis, you must answer all possible answers. In masternization, you must answer all possible answers. Otherwise, it is wrong. If the information must be true, it is called end-approximation. Again, we will talk about how much you understand. If you understand it, it is the best. In fact, the over and under are to ensure the accuracy of the information. For example, in masternization, we should change over-approximation to safe-approximation. It is to ensure the accuracy of the information. Therefore, the safe-approximation can be understood as the over-approximation in meganesis. In masternization, the safe-approximation can be understood as the over-approximation in meganesis. Let's recall what we said in the first class. We said that safe-approximation is to mirror the behavior of a program. How? If a program is represented as a graph, it is just a node. If it is a node, it is a variable. If it is a statement, it is a variable. The transfer function is to design the node based on the statement. How to analyze the edge? How to deal with control flow information? These are the two key points that you should keep in mind. We also mentioned it in the first class. Let's recall the example to analyze whether each variable is positive, negative, or zero. In the first class, we talked about the application-specific data, which is positive, negative, or zero, or unknown, or undefined. In the transfer function, for example, if I pay attention to the symbols, positive, negative, or positive, positive, negative, or positive, positive, negative, or positive, negative, or negative, positive, negative, or negative, negative, positive, or positive, this is a statement. Let's recall. Let's think about the uniformless operation of the union. This is another example. now let's recall the Pablo- gel declared the abstraction and safe approximation. In fact, we can see from the previous content that different data stream analysis applications have different data abstractions. Because the application is different, the data you pay attention to is different. There is also a different safe approximation strategy. If you have a different abstraction strategy, then you will define different data stream analysis applications. Next, we will talk about the different data stream analysis applications. What are their abstractions? What are the rules for the safe approximation? In other words, what are their data stream analysis applications? Let's move on. Before that, as I said before, we need to introduce some data stream analysis applications. In fact, data stream analysis is a very basic concept. In fact, it is not very difficult. It sounds very simple, but we want to show them in more detail. First of all, we need to talk about input and output state. What does it mean? Let's look at this graph. This is the output state. What does it mean? In fact, if the statement is S1, then the input state is in S1. In other words, before the statement is executed, the state of the program is in S1. After the statement is executed, the state of the program is in S1. The output state is in S1. For example, if the statement is X equals 0, the output state is in S1. After the statement is executed, the output state is in S1. Second, the input state is associated with the program point before the statement. The output state is associated with the program point after the statement.\n"
     ]
    }
   ],
   "source": [
    "audio_file_1 = open(\"./11-Audio-Summary/audio/lec03/lec03-0m-25m.m4a\", \"rb\")\n",
    "translation_1 = openai.Audio.translate(\"whisper-1\", audio_file_1)\n",
    "print(translation_1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d765a68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the use of talking about these things? Let's move on. For example, we now have two sequentially executed sentences, S1 and S2. We just finished looking at S1, and now we ask S2, who is the input of S2? In fact, it is the output of S1. OK, this is very simple, because they are sequentially executed. Obviously, this control flow can only go from here, right? Well, this is sequentially executed, so let's see if there is a branch. In fact, if there is a branch, we have to ask, who is the input of S2 and S3? This is easier to understand. It is the output of S1, right? The output of S1 produces an output, but the same output is given to S2, and the other output is given to S3. In fact, the output is only one, because S1 only produces one output. This is about branching. What is the control flow? Sequentially executed, branching, and then what? Gathering. There is nothing else, right? Including the control flow, for example, when the outer loop returns, in fact, it is also a control flow. This branch is also either branching, or gathering with others, right? OK, let's see what the gathering looks like. Now we ask the input of S2. OK, in S2, what does it mean? Obviously, it is related to all of its front areas, such as S1 and S3, its output. How is the output related? We use a meet here. Remember this, this, this, this, this comma, comma, this comma, this is the meet operator, OK? As for why it is called meet operator, this is what people define. It is like two data meet together. Then we use a meet operator. Then it can be union, gathering bin, gathering, and it is possible that when you come, you can use other ones. For example, we will learn constant propagation later. It may be neither bin nor gathering. In a word, it needs to process two data in a certain way. The process is called meet. Different applications are different, OK? So the two outputs in the front area need to produce a result through meet as the input of the next gathering statement. So far, these three concepts I think are quite simple. Very simple. Let's move on. Here, I have given from an angle how to grasp a sentence in static analysis as a whole. It sounds a bit abstract. In fact, when we finish this lesson, we will review this sentence later. OK? How much can you understand now? We say, in each dataflow analysis application, we associate with every program point a dataflow value that represents an abstraction of the site of all possible program states that can be observed from that point. What does it mean? In fact, in static dataflow analysis, what we achieve in the end is that after the analysis, we associate a dataflow value with every program point. What is a program point? It is the front and back of a statement. Right? Program points. Then, we associate a dataflow value with every program point. What does this value represent? This value represents an abstraction of the program states. The program states represent an abstraction of all possible values that can be observed from that point. This is the result of static dataflow analysis. What does it mean? Let's take an example. OK? In the first lesson, we said that we want to show every variable whether it is positive, negative, or zero. We want to show its symbol. Then, the result of the final analysis should be to show the dataflow value of every program point associated with a dataflow value that represents an abstraction of every program point. For example, if our program point is positive, negative, or zero, we should pay attention to this point. We should show dataflow value to each of the variables in the green box. We can see if the program points y is positive, x is negative, y is positive, and y is not defined, so it is bottom. OK? The corresponding program point, y is negative 1 and x is positive y is negative 1. x is positive. x and y are equal to negative 1. Right? If x is positive, y is negative. Right? OK. These are the results of the analysis. The green box shows the dataflow value of each program point. This is the result of the analysis. I just briefly explained the process of the analysis. OK? Why is this result an abstraction of the program state? Think about it. In this analysis, we only pay attention to the symbol. In fact, you can write other things in it. For example, you can add x to the green box. x is equal to 10. Right? Or y is equal to some specific value. You can write them all. But we only write the symbol here. We only write positive, negative, bottom, and null. We only write these. Why? Because they are an abstraction of the real program state. This abstraction is what we pay attention to. There is no need. Because this analysis is based on the symbol. There is no need to abstract the state of other program states that may occur. There is no need. So we only store the dataflow value and only store the data related to this analysis. OK? Another concept is domain. What is domain? The set of possible dataflow values is the domain for this application. For example, when we talk about the dataflow value, the result of the analysis is that the value has a value. The so-called value is the domain. The value symbol is 0, positive, negative, bottom, and top. OK? These are some simple concepts. After understanding this concept, let's look at the dataflow analysis from another perspective. Let's look at it in a macro perspective. What is it for? In fact, it is to find a solution to a set of safe approximation directed constraints on the ins and outs for all statements S. OK? If it sounds a bit unreasonable now, it doesn't matter. This is a general overview. We will use specific examples later. OK? OK. We said constraints based on transfer functions and constraints based on flow of controls. At this time, we will introduce some basic concepts about the constraints of transfer functions and the constraints of control flow. First, let's look at transfer functions. Normally, they are forward analysis. What is forward analysis? It is actually an analysis based on the order of execution of a program. In other words, when you build a control flow graph, it analyzes in the order of the way you walk. Here, we see out S, F S, in S. OK? What does it mean? How do you represent a transfer function? We define a transfer function as a function. Then, we use F S F S to represent the transfer function corresponding to S statement. It means that we need to define a transfer function. What is the output of the transfer function? It is nothing but the state in S before executing S. This value is converted by transfer function F S to the state after executing the sentence S. So, out S equals F S in S. F S is a transfer function. OK? Out S is an output. OK? This is for the forward analysis. Some students have said that the forward analysis should be better translated. Forward analysis has backward analysis. What does it mean? In fact, the control flow still looks like this. But, what does it mean when I say the backward analysis? When I say the backward analysis, I mean the opposite direction of the control flow. For example, output S is the input. This time, it is the input. Then, the output of the transfer function is the input of the sentence. This is the expression. In fact, I want to mention that in some static analysis practice, sometimes the backward analysis is also the opposite direction of the control flow graph. That is to say, when you see the S-axis, it will turn the S-axis to the opposite direction. Then, the control flow graph after the S-axis does the forward analysis. In fact, the effect is the same. However, when you turn the S-axis to the opposite direction, you design the transfer function more intuitively. OK? I will mention this more. OK? Normal backward analysis refers to the opposite direction of the control flow. That's it. OK? In this slide, there are basically two definitions. First, let's use the symbol to represent the transfer function. OK. After the symbol and the definition of the transfer function, let's look at the constraints of the control flow. How do the constraints represent? What did we mention in the last class? We said that many statements can be organized into a basic block. Right? Then, the constraints of the control flow can be divided into the basic block and the basic block. Let's look at them one by one. Let's assume there is a basic block. It consists of S1 and S2. Each of them is a statement. There are N statements in total. OK. Today, I will introduce a symbol. Let's say every statement is actually only related to the output of the previous statement. This is easier to understand. For example, let's take the value of S1. Then, the input of S2 is the output of S1. Is it easy to understand? It is impossible to have any difference between the two. It is determined by the nature of the basic block. The first statement is the input of the basic block. The last statement is the output of the basic block. Therefore, the input of each statement is the output of the previous statement. This is the mathematical symbol. No problem. OK. Let's look at the control flow between the two statements. First, how do we represent a basic block? In the past, we used to use statements in and statements out. What is a basic block in? Based on the nature of the basic block, we can easily deduce that the basic block is the first sentence because it has only one input. The corresponding basic block is the output of the last sentence because it has only one input. How do we define the relation between the basic block and the control flow? First, we need to know the output of the basic block. Let's look at the first statement. Who constitutes the output of the basic block? First, the output of the basic block must have an input, right? How do we represent the transfer function of the basic block? We use the letter F to represent the basic block. How do we represent the transfer function of the basic block? In fact, the transfer function of the basic block is to execute the corresponding transfer function of each statement. First, we execute S1. The corresponding transfer function of S1 is FSE. After executing FSE, there is an out S1. As the input of S2, we apply FSR, which is the transfer function of S2, and execute the last FSN transfer function. We use the letter B to represent the transfer function of the basic block. In fact, in B, the transfer function is to execute the out of the basic block. Now, let's see how to deal with the control flow. What is the structure of B's input? It consists of all the predecessors of B. There are two predecessors, P1 and P2. The predecessors are the out of the basic block. How do we deal with the out? We use the meet operator to summarize the contribution from different paths at the confluence of the paths. How do we deal with the out of the two paths? We use the meet operator to summarize the contribution from different paths at the confluence of the two paths. How do we deal with the out? We use the meet operator to summarize the contribution from different paths at the confluence of the two paths. How do we deal with the out? We use the meet operator to summarize the contribution from different paths at the confluence of the two paths. How do we deal with the out? We use the meet operator to summarize the contribution from different paths at the confluence of the two paths. How do we deal with the out? We use the meet operator to summarize the contribution from different paths at the confluence of the two paths. How do we deal with the out? We use the meet operator to summarize the contribution from different paths at the confluence of the two paths. How do we deal with the out? We use the meet operator to summarize the contribution from different paths at the confluence of the two paths. How do we deal with the out? We use the meet operator to summarize the contribution from different paths at the confluence of the two paths. How do we deal with the out? We use the meet operator to summarize the contribution from different paths at the confluence of the two paths. How do we deal with the out? We use the meet operator to summarize the contribution from different paths at the confluence of the two paths at the confluence of the two paths. How do we deal with the out? We use the meet operator to summarize the contribution from different paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two  at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two paths at the confluence of the two  at the confluent of the two paths at the confluence of the two paths at the confluent of the two paths at the confluent of the two paths at the confluence of the two paths at the confluent of the two paths at the confluent of the two paths at the confluent of the two paths at the confluent of the two paths at the confluence of the two paths at the confluent of the two paths at the confluent of the two paths at the confluent of the two paths at the confluence of the two paths at the confluent of the two paths at the confluent of the two paths at the confluence of the two paths at the confluent of the two paths at the confluent of the two paths at the confluent of the two paths at the confluent confluence of the two paths at the confluent of the two  at the confluent of the two paths at the confluent of the two paths at the confluence of the two paths at the conflue nence of the two paths  confluence of the two paths at the conflue nence at the confluence . . . . . . . . . . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "audio_file_2 = open(\"./11-Audio-Summary/audio/lec03/lec03-25m-50m.m4a\", \"rb\")\n",
    "translation_2 = openai.Audio.translate(\"whisper-1\", audio_file_2)\n",
    "print(translation_2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c926c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In other words, you don't let go of any path. So you have to cover all of them, and you have to do it manually. Very good, everyone seems to understand it well. Okay, we're done with this basic concept introduction. Next, let's see how to understand version definition. In other words, as we said earlier, the framework we filled in earlier is still the same. We said that for an analysis, you first need to do abstraction to the data, right? Then we do what? Save approximation, to define some constraint rules for transfer function and control flow, right? Then let's take a look at how to make abstractions and rules for this version definition. Define this abstraction rule, okay? Let's take a five-minute break, okay? Let's take a five-minute break. Because we've been talking for 50 minutes now. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay, we have one minute to continue. Okay, let's continue. Those who need to go to the bathroom, please come back. Let's continue. As we said earlier, we need to do abstraction and approximation, right? We mentioned save approximation earlier. Let's take a look at what kind of abstraction we should do for the data. So for this version definition, let's imagine what kind of data we are interested in. Is the definition able to reach a certain point? Let's take a look at each program point to see what kind of definition is able to reach it. So what is the data we are interested in? It's the definition. It's the definition of all the variables in a program. Okay. So in order to introduce abstraction and approximation later on, there are some algorithms that can be realized using bit vectors, okay? We can call all the definitions bit vectors. What does that mean? Let's say we have 100 definitions in this program. Then, from the 100 definitions, from the first, second, third, fourth, to the 100th, we use 100 bits, bit weights to represent them. Then, bits i from the left, from the left, the ith bit represents the ith definition. This is easy to understand. I want to emphasize that this is a definition. Okay. This is the data we are interested in. Okay. We mentioned save approximation earlier. Let's take a look at it from two perspectives. The following analysis is the same. This is how we look at it. Transfer function. How do we give it a save approximation design? Control flow. How do we give it a save approximation design? Let's take a look at it one by one. Let's take a look. In general, we will use one sentence as an example. Here are some simple tips for everyone. Let's take a look at one sentence. Transfer function. According to the definition of this function, what should we do? Actually, let's take a look at this statement. Assign a word to v. So this is a definition. We use the capital D to represent this definition. Then x, o, p, y, z, o, p can be added or subtracted. It is a two-dimensional expression. Right? This is the operating algorithm. So, what is the meaning of this sentence? What is the meaning of this sentence? It is from the perspective of the definition. Okay. Let's say you have an input. Transfer function gives you an input. After executing this sentence, what output should it generate? Transfer function is doing this thing. Right? This statement generates a definition D of variable v. Right? There is no doubt about this. This is defining v. So, there must be a new definition of v in the output you generate. It is D. Right? Then, it also queues all the other definitions in the program that define variables v, while leaving the remaining incoming definitions unaffected. How to understand this? Think about it. You define v here. It means that after executing this sentence, this v can only be this v. Right? Then, you can delete the other v definitions. Right? But, you only delete v, because you only define v. Right? Do you delete x and y? No. It is not necessary. So, those x and y are unaffected and will continue to flow into the output. So, how do you express this sentence in the form of a symbol? This is what we saw earlier. What is out B? After executing, suppose there is only one statement in this basic block B. This statement. Okay? Let's say there are only two components. First, it generates B. Okay? This is the new definition D. Okay? And, what else? The incoming definitions need to be deleted. Delete who? Delete all the other v definitions. Okay? Then, after this execution, after deleting, the remaining definitions that are not affected will be left. And the newly generated definition will be frozen. This is out B. This is the transfer function. Okay? Let's look at an example to further understand it. Okay? This is a simple example. Let's take a look at this transfer function. Let's take a look. First, there are a few definitions in this program. Let's take a look at a few defined variables. We can see 1, 2, 3, 4, 5, 6, 7. These are all definitions in every language. So, let's label them. This is D1, D2, D3, D4, D5, D6, D7. These represent seven definitions respectively. Okay? Seven. So, let's talk about the first basic block. Okay? What are its out, its generator, and its queue? Let's say you need to know what Gen and Queue are. Let's take a look. First, what is Gen? Gen is just three new definitions. So, D1, D2, D3, D4 are three new definitions of generation to execute the basic block. No problem, right? Let's recall. To execute the basic block, we need to execute every statement of the basic block. The transfer function is actually defined for every statement. However, you need to apply them together. Do you remember the circle I talked about earlier? The transfer function is applied to the first statement of the basic block. The first statement is out, and the second one is in. Then, we use the transfer function of the second sentence to execute the basic block. Okay? So, we need to queue all the definitions of I, J, or A. Let's see. Where is I? Okay. D4 is I. D7 is I. So, D4 and D7 should be queued. Right? According to the rules we talked about. So, where is J? D5 is J. D6 is D5. So, it will queue D4, D5, D6, D7. Okay? This is the first basic block. Let's look at the second basic block. Okay? It generates two new D4 and D5. Who will it queue? It will queue the other definitions of I and J. Where are the other definitions of I and J? D1 is I. J is D2. Right? D7 is I. So, D1, D2, D7 are the queued places. Right? Let's look at B3. It's very simple. It's a statement. Right? It generates D6. Who will it queue? So, it will queue D3. So, J is D6. Q is D3. The last one is D7. Right? It will queue the other definitions of I. D1 and D4 are the definitions of I and D4. So, D1 and D4. Okay? It's easy to understand, right? It's based on the definition. Okay. Let's talk about the transfer function. It's a statement. J, U, B, Q. Let's look at the control flow. Control flow. Actually, the main issue is not to miss any path. All paths must be over approximation. Okay? The safe here is over. Over approximation. Okay? Let's look at who generates INB. In fact, it's all the preconditions. B, all the predecessors. Right? Then, timeout. Finally, let's look at the mid. Right? The mid. What does it become now? It becomes a union. That is to say, we are a main issue. We consider the mid because we want to do safe approximation over approximation. We should not miss any path. So, we consider all of them. So, the mid becomes a union. Okay? Okay. So, INB is the union of all the out preconditions. Okay? Let me emphasize it again. This union, right? Because it's because a definition reaches a point as long as there exists at least one path on which the definition reaches. Okay? We have explained it. Okay. So far, it's not hard to understand. I don't think it's hard to understand. As long as you listen carefully, it's not hard to understand. Then, let's move on to a slightly harder one, which is the algorithm. We say, everything has only one direction. We say, a dataflow is a dataflow analysis. How to analyze it? There is the algorithm. The algorithm has input and output. What is the input? It's the control flow graph. We said, you have to analyze a program. Look at all the definitions in this program. Can they reach? Right? The input is, of course, a program. The program we talked about in the second class is the control flow graph. Okay. The premise is that Q and J have been calculated. How to calculate each basic block Q and how to calculate J is what we talked about in the beginning. Okay? What are the outputs? In-B and Out-B. In-B and Out-B for each basic block. We mentioned earlier that the final output is related to the dataflow of each point in the program. The dataflow is actually the definition. Can it reach that point? Okay? So, In, Out, and B are the outputs. Method. Okay. I don't want you to design the algorithm yourself. It should be the algorithm that you design but it's hard to design. This algorithm is called a more classic data flow analysis called iterative algorithm. Okay. It's an iterative algorithm. In this algorithm, we say that we are professionals. So, the details in this algorithm must be understood. The details must be understood. Let's see what the first step of this algorithm is. Out, Entry equals Empty. Okay. So, the first question is why is it empty? Think about it. What is Entry? It's the virtual entry in front of the control flow graph. Right? So, we say that what is the Out of Entry? It's Empty. How to understand Empty? Here, you can imagine that the Empty should be understood according to the meaning of your analysis. Think about it. Before you analyze a program, what is Entry? It doesn't have a statement. It's virtual. So, what is the Out? What is the meaning of this analysis? What is the question? The question is at this point, is there a definition that can be left? Think about it. Entry doesn't have a statement. There is no definition. How can there be a definition that can leave the Out of Entry? So, there is nothing. It's just Empty. Just understand it according to the meaning. This is the first point. The second point is for each basic block B, in all the basic blocks, except for Entry, the Out of Entry is a virtual Empty. Let's see. If you are careful, you will find that the Out of Entry is a virtual Empty. Actually, the Out of Entry is a virtual Empty. And then, you specifically emphasize that a basic block must be excluded from Entry. Why? Why don't you put them together? In other words, delete this sentence and delete the sentence that excludes Entry. That is, every basic block, including Entry, is a virtual Empty. Why? You have to remember that this algorithm is a classic iterative algorithm. As a template algorithm, it should not only be applicable to reaching definitions. It should also be applicable to almost all data flow analysis. There are some data flow analysis that you have to remember. Due to the Out of Entry, which we call Boundary Condition, the Boundary Condition and all other basic blocks may be different. For example, in the next class, we will talk about Master Analysis. You will find that all Master Analysis Entry is Empty, but the Boundary Condition is Empty. However, the other basic blocks are not Empty. For example, the Boundary Condition is Empty, but the Boundary Condition is Top. In fact, the Boundary Condition is Top. This is Master Analysis. I will talk about this example in the next class. You have to remember that this is a template algorithm, so you have to remember this. Alright, what is this for? All basic blocks are Empty, but the other basic blocks are also Empty. All basic blocks are Empty, but the other basic blocks are also Empty. Alright, why is it Empty? You can understand it this way. You can also understand it in the context of an analysis. For example, let's assume that the program is not running. If you want to give a result, you think about every program point, every basic block, do you have a definition to reach it? No, right? Because there is no definition to reach it. You can understand it this way. However, if you still understand it this way, it is easier for you to understand the technique of analyzing algorithms. Boundary conditions, no matter what kind of analysis you encounter in the future, you can use what I said before, you can use the meaning of the analysis to design it. Generally, it is Empty. However, basic blocks can be explained in the same way as the previous method, but if you use the same method to explain some other analysis, it may not sound smooth. So, what should the basic block be? When we talk about theoretical framework in the next class, I will summarize a theoretical framework that is easy to understand. I will tell you clearly. I will give you a brief description of the basic framework. I will give you a brief description of the basic framework. I will give you a brief description of the basic framework. I will give you a brief description of the basic framework. I will give you a brief description of the basic framework. I will give you a brief description of the basic framework. I will give you a brief description of the basic framework. The basic framework is the basic framework. The basic framework is the basic framework. The basic framework is the basic framework. The basic framework is the basic framework.\n"
     ]
    }
   ],
   "source": [
    "audio_file_3 = open(\"./11-Audio-Summary/audio/lec03/lec03-50m-75m.m4a\", \"rb\")\n",
    "translation_3 = openai.Audio.translate(\"whisper-1\", audio_file_3)\n",
    "print(translation_3['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e0154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's go back to the algorithm, and see how we can initialize iteration 0. We can see that each of the outputs has an empty state. What is the empty state? It is 0,0,0,0,0,0. No one can reach this state. After initialization, let's continue to see what the algorithm is trying to do. What does it keep applying? Solving the constants. With the output, we can see what the INB is. We can see what the output of each basic block is through the transfer function. We can see if there is any change. After the change, we will continue to iterate. After the change, we will continue to iterate. This is the main algorithm. Let's look at the first one. Let's start over. The brainwashing has begun. Everyone, please follow what I said. Who is the input of our B1 basic block? It is 0,0,0,0,0,0. What is the output of B1? Let's look at the transfer function. What is the transfer function? It is the Q of GEN, UNION, and IN. Who is GEN? It is x,y. Let's look at Q. Who is Q? Normally, Q is the place where all other x and y are defined. But you don't need to remove Q because it is already 0. If you remove Q, it is still 0. So you don't need to pay attention to it. Who is GEN? It has two definitions. The first and the second. The position of the first and the second. Let's follow the order. The first and the second. So 0,0 will become 1,1. So after executing the basic block 1 transfer function, the output becomes 1,1,0,0,0,0. Is there any problem? OK. Let's continue to look at basic block 2. What is the IN of basic block 2? Let's look at the transfer function, the control flow. OK. What is INB? It is the union of all the predecessors' outputs. OK. Who is the predecessor of basic block B? It is B1. There is another predecessor. Let's follow the order of A to B4. OK. Who are the outputs of these two? When B4's output is initialized, it is 0,0,0,0,0,0,0. Who is the output of B1? It is 1,1,0,0,0,0,0. We just calculated it. OK. What are the two results? It is UNIN. What is the result of UNIN? Think about it. What is the union of 0,0,0,0 and 1,1,0,0? It is 1,1,0,0,0,0. 1 or 0, right? It is 1. So the final result is 1,1,0,0,0,0,0. This is the input of B2. What is the output of B2? Let's continue to look at it. Who is the output of Q? It is the output of all the places where M and Y are defined. Right? OK. M is only defined here. There is no other place. There is only one black. Where is Y defined? Find another red place. Here it is. B2. That is to say, who is the output of Q first? B2. The second 1 becomes 0. Right? 1,0,0,0,0,0,0. OK. Who is the generator? Two new generators. The third and the fourth. So it should be 1,0. The third and the fourth become 1. The second is output of Q. So it is 1,0,1,1,0,0,0,0. Right? OK. 1,0,1,1,0,0,0,0,0. As Outp2. OK. Because as Outp2 says, it will pass. So it is the same result. 1,0,0,0. 1,0,1,1,0,0,0,0. OK. Let's continue. B3. Now you tell me what is the output of B3. Now everyone write down. What is the output of B3? Now everyone write down. What is the output of B3? OK. Very good. Very good. Let's say we're going to queue up all the other places where x is defined. Where are the other blue places defined? OK. The first and the fifth. The fifth is already zero. We don't care about it. Right? The queue is also zero. The first is one. Let's make it zero. Then it becomes 0 0 1 0 0 0. But it has to form a new one. Right? Form a new seventh. Form a new seventh. So it's 0 0 1 1 0 0 1 0. The seventh position. 0 0 1 1 0 0 1 0. Very good, everyone. Then continue. After we go to B3, we go to B4 in order. B4, we said earlier that the output is 1 0 1 1 0 0 0. Right? It's B2's output. All right. B4. B4. I'll take you away. Time is limited. All right. What is B4? Let's say we queue up. Queue up x and z. The other places defined by x and z. The other places defined by x and z have blue D1 and D7. D1 is now one. One should be queued up, right? 0 0 1 1. D7 is not here. D7 is not here. All right. Queue up this place, right? That's also 0. That's D8. No need to queue up. But the output is 5 and 6. The output is 5 and 6. So D5 and D6 should become 1 1 1. Right? All right. Then it should be 0 0 1 1 1 0 0. 0 0 1 1 1 1 0 0. Why? D5. D5 also has an output. One of my classmates wrote 0 0 1 0 1 1 0. No. Take a look. It has a D5. Right? Because generally it has D5 and D6. So D5 and D6 should become 1. All right. Let's continue. We say it's time to execute. D5. What is D5's output? It's B4's out and B3's out. Then we say B4 and B3's out should be what? Union. Control flow should be handled like this. Union. Right? All right. What is the result of union? Think about it. 0 0 1 1 1 0 0 and 0 0 1 1 0 0 1 0. What is union? You change all 0s to 1s. It's 0 0 1 1 1 1 1 0. Right? The result after union is 0 0 1 1 1 1 1 0. All right. After 0 0 1 1 1 0 executes D8. OK. Let's take a look at its output. We say Q is what? All other defined places. Find the green place. D6. Is there any D6 in it? Yes. It's 1. Then it becomes 1 0 1 0. Right? There is another D8. So the eighth position becomes 1. So it's 0 0 1 1 1 1 0 1 1. OK. All right. The first iteration is over. The first iteration is over. All right. Let's review the algorithm. The first iteration is over. The next iteration depends on any out. If there is any basic block, its out changes. What is change? It's compared to the last iteration. It changes compared to the last iteration. We have to continue to iterate. OK. Continue to apply this algorithm. Let's see if it changes. It changes. Changes occur in these blocks. Almost all blocks' out changes. Think about it. What is this? The initialization is 0 0 0 0. Now it becomes 1 0 0. Of course it changes. All 0 0 0 0 becomes 1. Right? So it changes. How does it change? Let's continue. The second iteration starts. The second iteration starts. All right. What is the input and output? It's the same. Think about it. Input is 0 0 0 0 0 0 0. What is the output? It becomes 1 and 2. Right? Then continue. B2. All right. Pay attention to this. I'm going to do B2 now. What is the input of B2? The input of B2 is 0 0 0 0 0 0 0 0. And this 1 1 0 0. The red 0 0 0 0. Right? Now B2. This hasn't changed. 1 1 0 0 0 0. But B2. Right? The output of B4 has changed. Right? B4 out changes. Because the result of the last iteration changed. Why did it change? It's because when you first compile B2. B4 hasn't compiled yet. Right? But after the first round of compilation, B4 has a new result. In the second round of compilation, the new result of B4 will be added to B2. If you think about it quickly, you can feel that the iteration of this algorithm is related to the sequence of nodes you visit. I'll make it simple. You can understand it if you can. It's related to the sequence. In other words, think about it. If you mess up the sequence and compile from the bottom up, the number of iterations will increase. Because each iteration changes. Right? I'll make it simple. Let's see. This is the new input. This is the output. What else do they need? Uni. What is the result of Uni? 0 0 1 1 1 0 0 and 1 1 0 0 0 0 0. The result of Uni is 1 1 1 1 1 1 0 0. 1 1 1 1 1 1 0 0. OK. Now, let's calculate the result of 1 1 1 1 1 0 after B2. What is its out? Out B2. 1 1 1 1 1 0 0 is its input. What is the result of Out B2? Use your brain. Generate after Q. Right? What is Q? What is Generate? Let's see. Calculate. Good job. You did it. Not bad. Let's see. Q is the place where all the black M's are defined. There is only one M. Q is the second place. Right? OK. The second one. This 1 becomes 0. 1 0 1 1 1 0 0. What about Generate? 3 4 Generate. 3 4 is 1. We don't need Generate. It becomes 1 0 1 1 1 0 0. Good job. Let's continue. B3. It becomes 1 0 1 1 1 0 0. What is it? Q is the place where all the X's are defined. D1. D5. D is here. D5 is also here. It becomes 0 0 1 1 0 1 0 0. Right? Generate becomes D7. It becomes 0 0 1 1 0 1 1 0. D7 becomes 1. Right? OK. 0 0 1 1 0 1 1 0. No problem. Let's continue. B4. The input is this. Let's execute it. We say X is equal to 4. Z is equal to 5. Then, let's calculate this. What is this Out? OK. The students have given their answers. Good. Very good. What is Q? Q is the place where X and Z are defined. Right? There are two places where X and Z are defined. D1 and D7. D7 becomes 0. No problem. D1 becomes 0. 0 0 1 1 1 0 0. Right? D8 becomes 0. Q becomes Z. No problem. So, 0 0 1 1 1 1 0 0. Generate. D5 and D6 become 1. 0 0 1 1 1 1 0. OK. Now, 0 0 1 1 1 1 0 0. Let's look at B5. Let's combine B4 Out and B3 Out. What is the result? 0 0 1 1 1 1. 1 1 0 0 and 0 1 1 0 1 1 1 1 0. Right? So, the result is 0 0 1 1 1 1 1 0. OK. 0 0 1 1 1 1 1 0. Now, 0 0 1 1 1 1 1 0. Look. The first variable is also 0 0 1 1 1 1 1 0. So, the result is the same as the red one. Right? Let's check. All other places where Z is defined are D6. Right? Subtract. D6 is subtracted. OK. Subtract 0. Make 1 0. Add 1 to D8. It becomes 0 0 1 1 0 1. OK. The second variable is done. OK. Is there any... I'll ask you now. Do we need the next variable? Just answer whether you need it or not. Yes. Right? OK. Why? Because there is a change. Change. What change? Let's check the highlight. The yellow highlight. Let's check this, this, this, this, this. Is there any change in the result of the second variable and the first variable? Is there any change in red and blue? The change is highlighted in yellow. Look at B2. It used to be 0 0 1 1 0 0 0. Now, it's 0 0 1 1 1 1 0 0. B3's out has also changed. 0 0 1 1 0 0 1 0. Now, it's 0 0 1 1 0 1 1 0. It's changed. It's changed. We need to continue to add. OK? Continue to add. OK. The third variable starts. OK. 0 0 0 0 0 0 0. OK. You can take a look at this. In fact, imagine. We have already changed the third... The first time, everyone... It's like this. The second time, I can understand. The third time, it's so boring. I changed the variable again. In fact, this time, you have a feeling. This feeling. Now, I can give you some suggestions. In fact, look at this. Let's wait for a while. After changing two variables, I will ask you a question. Let's see what you feel. Let's see. 0 0 0 0 0. OK. You continue. What is the multiplication? The multiplication of X is still the first and second. Add it first. Because the other 0s don't need to change. 1 0 0. OK. Change to B2. What is the input of B2? Let's say 0 0 1. The previous B4's out and B1's out. Then, 0 0 1 1 and 1 0 0 1 1 0 0 0 0. On top of the unit, it becomes 1 1 1 1 1 1 1 0 0. Then, 1 1 1 1 1 1 0 0. Continue. Continue. We say Q out all other variables in the place of M. D3 becomes 0. Q out all other variables in the place of Y. It is another red one. Right? D2. This becomes 0. It is 1 0 0 1. Right? But D3 and D4 still need to be added. It becomes who? 1 0 1 1 1 1 1 0. Right? 1 0 1 1 1 1 1 0 0. Right. Now, I ask you. Look at this. Look at this carefully. Let's take B3 as an example. At this point, look at the second variable, the blue part, and the third variable, the green part. Are they the same? I ask you now. If the input is the same, for our reaching definition, the output is the same? Answer this question. You have made up so many definitions. You should have an intuition. Right? If the input is the same, is the output the same? It must be the same. OK. This is very important. This is the key to understanding the soul of this algorithm. I will summarize it later. OK. Think about it. What are Q and Generate? Q is always a fixed statement. Think about it. The definition of Q is always a fixed statement. Because the statement will not change. Generate is also a fixed statement. Then, based on our OUT is equal to GENERATE UNIT IN minus Q, GENERATE and Q are both fixed. If the IN is the same, just like GENERATE and Q are a constant, then we become an equation. If OUT is Y, Y is equal to a constant plus an X as an input minus a constant, Q is a constant. What is the input? What is the output? It will not change. Just think about it. Then, it will be easier. We say OK. Blue and green have not changed. Continue. The output has not changed. So it should be blue. 0 0 1 1 0 1 1. If you don't believe it, you can check it. OK. Let's check it randomly. Let's look at this one. What is blue? What is the IN? It is 1 0 1 1 1 1 0 0. So, it has not changed. Will the OUT change? Will the OUT change? Will it change to 0 0 1 1 1 1 1 0 0? Let's check if it is true. You can check it. Just now, some students said B3 is like this. It will not change. What about B4? Let's check it. Tell me, has it changed? Has it changed or not? You have to move your brain. Only when you move your brain, can you truly understand this algorithm. It will not change. OK. No problem. 0 0 1 1 1 0. OK. Let's continue. 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 0. UNION. What is the result of UNION? 0 0 1 1 1 1 1 0. 1 1 1 0. OK. 1 1 1 0. Let's see. 1 1 1 0. It has changed. Now, we know what it is. 0 0 1 1 1 1 1 1 0. Last time, the result was not kept. Let's check it again. 1 1 1 0. The result of UNION is 1 1 1 0. 0 0 1 1 1 1 1 0. Let's see. Subtract all other values. It is 6. 6. The second 1 becomes 1 0 1 0. Right? The value of 8 is 1 0 1 1. It becomes 0 0 1 1 1 0 1 1. 0 0 1 1 1 0 1 1. It has not changed. OK. The third proof is over. Do you need the next proof? Let's check the comments. OK. No need. Good. Why? Because no changes occurred in any out. Every basic block has no changes. In fact, when we study this analysis, we can only know what the algorithm is doing. But we don't know the details. When we know the details of the algorithm, we can feel when it can change and when it can't. We will find out the details later. I think it is better to have a detailed history so that everyone can understand the algorithm. Otherwise, when a beginner meets the algorithm, he may feel that the algorithm is a bit difficult to understand. But when we try it, we can feel that the algorithm is not so difficult to understand. OK. What is the result? You have not changed in the last proof. Nothing has changed. In the last proof, the result of the out is your final analysis result. How to explain this result? Let's take a look. What is this point? All the green highlights are the final result. The final result. Let's look at the out of B. 11000. What does it mean? It means that the first and second definitions can reach the end of B. Let's look at the end of B3. Its out is 0010110. It means that the third and fourth and the sixth and seventh definitions can reach the end of B3. See? At this time, let's go back to our class. At the beginning, we did a description of dataflow analysis. What did we say? We said that in every dataflow analysis application, we associate with every program point a dataflow value that represents the abstraction of the size of all possible program states that can be observed for that point. Now we can understand the meaning of this sentence. See? Every program point is associated with a dataflow value. This is 11000. This is our dataflow value. What does it mean? It is an abstraction of the size of all possible program states that can be observed for that point. What does it mean? It means that we are concerned about whether a definition can reach the end of B3. Now you can understand this sentence. Okay, let's continue to understand another sentence. In the previous class, we also made a summary of dataflow analysis from another perspective. What did it say? Do you remember what it said? It's to find a solution to a set of safe approximation-directed constraints on the ins and outs for all statements S. Now you can understand, right? What constraints? We keep using transfer functions and how to do it when the control flow merges. We keep solving these constraints until we find a solution when the algorithm stops. Right? These are all the constraints we use. What are these constraints? They are for sound, right? They are for a solution called safe approximation. In the end, the answer, the solution, is the result of these green marks. The final result, the analysis result. Now you can understand the meaning of these two sentences, right? Okay, these two sentences are very important. Because they are not just used for reaching definitions. They are used for all common dataflow analysis. So now you understand these two sentences, and you can use these two sentences to connect all other analyses. Okay? Okay, now let's review a question we asked before we did this algorithm. First, let's see if this algorithm is very friendly. It's not so cold. It feels very warm. But we still have a question. The question is, why does this algorithm stop? We just saw that it stopped. Right? It stopped once. But does it have a commonality? In other words, will all dataflow analysis eventually stop? In fact, at the end of this video, I will show you some examples. Because you can really feel it. You can feel it when the print doesn't change, and when the output doesn't change. Right? You can also feel it. Let's continue and see why. Let me summarize. Okay? This is also the soul of this algorithm. Why this algorithm? This algorithm is a loop algorithm. It keeps looping. The most important point of this algorithm is why the loop can stop in the end. Okay, let me explain it to you. In fact, some of you may already have a feeling. Let's describe the feeling of the example just now. What is the most important thing about this algorithm? It's the transfer function. As for the merge, it's the unimap. It's easier to understand. The transfer function has several components. Gen, Queue, In, Out. Right? Okay. This is the statement S corresponds to a control flow. Let's write it like this. The first thing we want to say is generate and queue remain unchanged. I just clicked on it. Can you understand? A statement, what definition does it go to? What definition is generated? It's fixed. Unless your program changes. If the program doesn't change, what do you do? You analyze it again. That's all you can do. But there are some incremental. Let's not talk about these advanced parts. Okay? Okay, what does it mean to generate and queue remain unchanged? It means that when you have a hard change, for example, we mentioned it before. Do you remember the first time when there was a change? The first time, S corresponds to these. But after the first change, the second change, there are some more effects to the flow. Right? That is to say, this hard change is the first time S corresponds to these. Right? That is to say, this hard change is the first time S corresponds to these. When more facts flow in, the more facts have what change? There are only two kinds of change. What change? It's either we queue it, right? Or what? It's not being queued. It flows to out. We call it survivors. Okay? Okay, at this time, out, more facts come in. It's either being queued or it's a survivor. The survival and the newly generated sentence are composed of newly added out content. So we say when a fact is added to out through iterative generator, or a survivor, it will stay there forever. it will stay there forever. That is to say, once these more facts come in, once they are added to out, once they are added to out, they will always stay there. they will always stay there. They will never be smaller. They will never be smaller. In other words, out never shrink. out never shrink. It's impossible to shrink. It's impossible to shrink. It means that for example, 0 will only become 1. Either 0 is 0, or 0 is 1, or 1 is 1, it's impossible for 1 to become 0. Because Q and GND are fixed. Q is fixed in there. Q is fixed in there. After the more facts come out, you already queued one thing, and then you can queue another 1. You see, 1 is changed when it comes in. It doesn't change. Right? 1 is there. 1 is there. Right? So it's impossible for 1 to be 0. So it's impossible for 1 to be 0. So it's impossible for 1 to be 0. So it's impossible for 1 to be 0. So it's impossible for 1 to be 0.\n"
     ]
    }
   ],
   "source": [
    "audio_file_4 = open(\"./11-Audio-Summary/audio/lec03/lec03-75m-100m.m4a\", \"rb\")\n",
    "translation_4 = openai.Audio.translate(\"whisper-1\", audio_file_4)\n",
    "print(translation_4['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6481afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one that should be queued has been queued. The reason why it becomes 1 is that it has never been queued before. It will not be beautiful next time, so it will not be queued next time. So 1 will always be 1. 0 becomes 1 because the generator or the survivor stays. So this out will never shrink, it will only get bigger. Okay, there must be a degree for it to get bigger. What will the degree look like? We say, as the set of the facts is finite. What does this mean? What do we mean by this analysis? It's definitions. What do 0 and 1 represent? They represent all definitions. A definition in a program must be finite. No matter how large a program is, its size doesn't matter. So definitions should be countable. What does this mean? It means that there must exist a path of iteration during which nothing is added to any out. And then the algorithm terminates. Is it like this? It means that this out will only grow from 0 to 1, and 1 is 1. In the worst case, there will always be a time when 0 can't grow to 1 because it won't change. Or in the worst case, all 0s will become 1s. Will 1s change? No, they won't. They will always stop. Of course, in this case, a real program won't exist. If all definitions can reach 1, then it means that everything is 1. But we will always find that there is an iteration that won't grow. So the algorithm will eventually stop. Do you understand now? Okay, this is why the algorithm will stop. Okay, it will stop. It's not over yet. We just said that the algorithm stopped. Then we have to ask why we use this condition. We said that when we delay, if every out doesn't change, then we think that the algorithm can stop. This result can be the final result. Is this condition safe? In fact, this sentence can be translated as if we delay, delay, delay, and after the first delay, we find that all the outs don't change, then we say that this result is the final result. Then you can try it. You can think that if all the outs don't change, you continue to loop again. You see if the result changes. If there is no change, then the result is indeed the final result. Let's take a look. Think about it. If every out doesn't change, will the final result change? Let's loop again. For example, if the change to any out occurs is false, but you insist on running it again, then the out doesn't change. As we said before, if all the outs don't change, the in won't change. So the in will not change if the out does not change. Next, let's execute this sentence. We said that if all the outs don't change, the in won't change. If the in doesn't change, and we say that the gen and q are fixed, then the out won't change. As you can see in the delay process, the out will not change if the in does not change. So the result of multiple variables will still not change. In other words, this result can be used as the final result. In fact, we can say that this algorithm has reached a point of no return. This is also related to the monotonicity of the whole analysis. We will explain them in theory in the following lessons. At this time, I just hope that you can feel it for yourself. It is equivalent to that we use the feeling to understand the theory behind it, which will be easier. All right? All right. I believe that this algorithm can be explained in this way with a certain scale. I will give you a little bit of details. I think you can say that you have mastered it. All right? That's all for today's lesson. In the next lesson, we will talk about two more difficult analyses, namely the Leave Variables Analysis and the Available Expression Analysis. Among them, the Available Expression Analysis is the Math Analysis. OK. After these two lessons, I may... After these two lessons, I may... If there is still some time left in the next lesson, I may talk about some theoretical foundations, such as Dataflow and ISAE Foundations. All right? That's all for today's lesson. Wow, it's too difficult. Why did I say that? Because this is really... When I was a student, this was my first class. And I was still in the class. I had never taken this class before. It was my first class. I had no experience. Now, many students from all over the country are coming to supervise me. They want me to... I have to ensure the quality of the class. So now, I only have the class in my head. I have nothing else. So, if my presentation is not ideal, if my presentation is not good enough, I hope you can understand. All right? I will give you five minutes. All right? If you have any questions... OK, thank you. Thank you, everyone. If you have any questions, you can ask me. All right? Yes, PPT is very difficult to do. Before I brainwash you, I have to brainwash myself, too. I think I can speak faster. I've been thinking about this for a long time. After all, this is... How should I put it? Everyone has a different foundation, right? As a teacher, especially as a course teacher, I think I have to take care of some students who may not have a good foundation and who are slow to understand. All right? So, if you can understand quickly, you will be able to understand some things easily. After all, students have different levels of education and different ways of thinking. All right? We all have to take care of them. We can't let one student go. Since I chose this course, I have to take care of all of them. Since I chose this course, I have to take care of all of them. I don't want them to lose their interest because I speak too fast and I don't understand them well. I don't want them to lose their interest because I speak too fast and I don't understand them well. As a teacher, I can provide what I can give. The rest of you, if you really feel interested, keep learning. This is what you can do. All right? It's too soft. I don't want to persuade you to quit. Persuasion is what Mr. Tan does. Mrs. Tan's course is quite hard. I will tell some parts that are harder for me. In fact, it's OK. In fact, it's OK. There aren't many parts that are hard for you. Hard parts are about so may need to adjust. Maybe next class I will talk about that. It should be OK if NSCS students do it. I think no matter you are NSCS students or not, if a new course comes out and I feel that I will take good care of it, I will take good care of it, and I don't think all people from NSCS have good basic skills.  have good basic skills and play games because this course is very important, and your generation needs to have me of course you still need to give this to your generation, ok? the people who can choose this course I think everyone has good basic skills But as I said this courses I should take care of I think this is something that we should pay attention to when we teach Let me put it this way If you look at this course and you feel very clear it's possible you feel clear it's possible some things you'd like to repeat some things you'd like to speak slowly if you speak fast you may miss some parts you may not speak clearly it's hard to say the thing is sometimes it's easy it's because you approach it in a different way For example let me be honest with you at first time I didn't think it was easy because I read the materials I felt I didn't understand the content so please understand and take care of yourself and other students The way to reach a static analysis of a brain wave we won't talk about the whole course the wave is another topic it's also quite difficult in academic how to say it's also a focus of research it has a whole set a set of a set of theory ok What is the end of the course? We haven't seen it yet we have to see it let's talk about it on the platform ok What is the relationship between sound complete and safety? ok you asked a point very good I can simply say because it's not a formal class because think about how we introduced complete master analysis master analysis we introduced in the first part that is this this what is the relationship between complete? it must be a real paper you can understand that is what master analysis says I want to report it must be real you can't have a wrong method so it must be a complete result so master analysis why is it safe? we will talk about it later in the next class we will talk about available expression if there is a misrepresentation if you use available expression to optimize it will be wrong I will give you a specific example it's not safe ok right some students say sound is safety ok this I think in academic this concept is very vague very vague it depends on how you define sound normally I suggest sound is easy to understand what is sound? you can think of sound is safety this student said it well sound is safety this is easy to understand because most static analysis it is magnet analysis what does it do? all dynamic operations it needs over approximation right so it is for safety you can close your eyes but there is a small master analysis you can't use it ok you can't use it but if you are an academic you can maybe in some articles some articles it will say a master will also say sound at this time it may have a re-definition because the definition of sound is very vague some sound I remember there is an English definition what is it? it says as long as the output is not wrong it is all sound this is the definition it is as long as the output is not wrong the output is not wrong then it is all sound from this perspective master analysis is sound but don't follow this follow the whole course because the whole course I said sound is true sound complete and true are actually the same as other universities like Pennsylvania and California so in this course we just talk master analysis so you just follow this definition sound and safety will not directly not work sometimes master analysis is complete this is the definition of sound and safety so you just follow this definition sound and safety will not directly work sometimes master analysis is complete this is the definition sound and safety will not directly work sometimes master analysis is complete this is the definition of sound and safety will not directly work sometimes master analysis is complete this is the definition of sound and safety will not directly work sometimes master analysis is complete this is the definition of sound and safety will not directly work sometimes master analysis is complete this is the definition of sound and safety will not directly work sometimes master analysis is complete this is the definition of sound and safety will not directly work sometimes master analysis is complete this is the definition of sound and safety will not directly work sometimes master analysis is complete this is the definition of sound and safety will not directly work sometimes master analysis is complete this is the definition of sound and safety will not directly work sometimes master analysis is complete this is the definition of sound and safety will not directly work sometimes master analysis is complete this is the definition of sound and safety will not directly work sometimes master analysis is complete this is the definition of sound and safety will not directly work sometimes master analysis is complete this is the dozen courses I chose for today thank you very much for listening to me today thank you very much for coming along today thank you for listening to me thank you for coming along today thank you very much for coming along today thank you very much for coming along today thank you very much for listening to me thank you very much for coming along today thank you very much for coming along today thank you very much for coming along today thank you very much for listening to me thank you very much for listening to me thank you for this I'm going to end the class now. Thank you for listening. I'm leaving now. Bye bye.\n"
     ]
    }
   ],
   "source": [
    "audio_file_5 = open(\"./11-Audio-Summary/audio/lec03/lec03-100m-end.m4a\", \"rb\")\n",
    "translation_5 = openai.Audio.translate(\"whisper-1\", audio_file_5)\n",
    "print(translation_5['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ff10c",
   "metadata": {},
   "source": [
    "## Lec04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ff70d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All right, let's start the class now. Welcome to the fourth class of software analysis. Today, we will talk about data flow analysis, the application part. In fact, I mentioned in the last class, the whole data flow analysis, because it is a very important and basic part of static analysis. So we are going to have four classes. In the first two classes, that is, the last class and this class, we will talk about the application part of data flow analysis. In the next two classes, next week and the week after next, we will talk about the theoretical basics of data flow analysis. The whole data flow analysis, the design of the four classes, first talk about the application, then talk about the theory, and then the time is basically the same. Mainly because the application part in the front, one is to let everyone learn the application, after learning these specific applications, if you encounter optimization, or some data flow analysis to check errors, to check security, you will be easier to get started. The other one, which takes a lot of time, is actually for the theoretical part of learning, which is more confusing and difficult to understand, the concept of abstract, to make a foundation. In the last class, we first gave a overview of data flow analysis, and then introduced some basic knowledge and definitions. Then we briefly introduced the Reaching Definities analysis. It is a classic and easy-to-understand Mayan analysis. Then we talked about how to design the Mayan analysis, Reaching Definities, the transfer function, the abstract of data, and the control flow. After that, we went over the algorithm again. We also emphasized the algorithm, and explained why it can stop. In fact, the point where it stops is the non-moving point. I remember that in the last class, a student asked whether there is only one non-moving point after the iterative algorithm? In fact, after learning the theory, these problems can be solved. In fact, it doesn't matter if you don't understand. In fact, in the last class, we talked about Reaching Definities, and today we talked about Live Variables and Available Expression. Today, Available Expression is still a mass analysis. In fact, most data flow analysis can be classified as lattice, and we can solve the non-moving point step by step. In fact, there are many non-moving points on a normal grid. However, in the future, we will also write work-based algorithms. In fact, the non-moving point that we want is the largest non-moving point or the smallest non-moving point. The largest non-moving point is the problem of resonance. Its density is related to MOP, MFP and basic static analysis. In fact, the relationship between density and MOP and MFP is related to the monotonicity and distributability of the data flow analysis framework. We will talk about this in the future. Now, I want to tell you something important. For example, when I talk about the data flow analysis and its application, I will give you a machine to make a mask. When you learn the application part, you will learn the theory part. However, the theory part of data flow is relatively shallow. The reason why Mr. Tan and I put the theory part in the design is that you will not only make a mask, but also learn the algorithm of data flow analysis and application. So, can you learn the data flow analysis and understand the theory part? For example, you can understand the mechanism and automation of the machine. You can make a mask, a hat, and so on. In the future, we will talk about the theory part. Today, we will talk about Live Variables Analysis and Available Expression Analysis. Finally, we will compare the data flow analysis and application. Live Variables Analysis and Available Expression Analysis are slightly harder than Rich Definition Analysis. Today, you can understand Live Variables Analysis and Available Expression Analysis. There are many students who do not have the basic knowledge of advanced programming. In other words, they have not heard the data flow analysis and application part. I will talk about it briefly, but I need to take care of the data flow analysis. Now, let's look at Live Variables Analysis. First, what kind of analysis is it? Live Variables Analysis tells whether the value of variable v at program point p could be used along some path in CFG starting at p. It sounds abstract. Let's take a look at the chart. If so, there is indeed a path that allows the starting from p to a variable v. There is a variable v at program point p. We want to know whether this v is alive at this point. First, there is a path. At the same time, there is a place for v. Now, let's look at the chart. Live Variables Analysis tells whether the value of variable v at program point p could be used along some path starting from p in CFG's control program. If so, we say v is alive at p. Otherwise, v is dead at p. Actually, this concept is abstract. In fact, there is a hidden condition that v should not be redefined before its usage. What does it mean? Let's say v is redefined at this point in the middle. In other words, v is equal to 0 at this point and is equal to 3 at this point. Therefore, v should be used before it is redefined. In other words, there is a path starting from v and there is a place for v at the same time where v is not redefined. We say v is alive at program point p. Now, this is an abstract concept. If you are not sure, you may have an impression of this concept. Next, you may ask what is the use of a variable at a program point? Actually, there are some applications. Here is a typical application. We say information of leave variables can be used for register allocations. If you have not learned the principle, it does not matter. I will briefly explain what is an information of leave variables. Let's imagine you are a machine. All of your leave variables are full. At some point, when you run a program, all of your leave variables are full. What do leave variables do? They load some data into the leave variables and add and subtract the operation. It is a simple scenario. Now, when you run a program, all of your leave variables are full. What do you want to do? You want to execute the next line and load the next operation into a leave variable. All of your leave variables are full. Do you want to replace one? Here is the question. Which leave variable do you want to replace? Actually, if you want to replace a variable, you can analyze the leave variable as a dead variable, which means it is impossible to be used in the future. If you want to replace it, you replace it with a leave variable. After you execute this line, even if you replace it, you still need to execute the next variable and load the next one. It is a waste of resources. If a variable is dead, you replace it with a dead variable. It is a waste of resources. In fact, it is a kind of programming optimization. So, what is the use of leave variables? Do you think it is helpful to design leave variables in the future? In the last class, we mentioned that data flow analysis cannot escape the classic framework of data flow analysis. First of all, we need to analyze the data and abstract it. Then, we need to analyze how the data flows and make a safe approximation. Then, we need to design the transfer function and control flow margin. First of all, we need to analyze how the data flows. In fact, we need to analyze all the variables in the program. As mentioned in the last class, what is the data abstract that Richien Definites focuses on? It is all the definitions. It is all the variables in the program. Similarly, we can convert the data abstract into bit factors. Let's say there are 100 variables in the program. Then, we can use 0, 0, 0, 1, 1, 1 to represent 100 bit weights. It represents the DIG variable. We can actually make a number. 0, all the data, 0, 0, 0, 0, are in every program point. Our data flow analysis still looks at which variables are live and which are dead. Therefore, if a variable in a program point is 0, it means it is dead. If it is 1, it is live. We will not go into details in the last class. Next, we will talk about how to design live variables analysis so that the data can be saved after the data flow analysis. Now, let's look back at the diagram. We just replaced the concept described by the natural language. Now, you already have an idea of how to handle the transfer function based on the basic framework described in the last class. Now, let's design live variables analysis. First, let's talk about data abstractions. Next, we will talk about a very important part of data flow analysis. First, you need to look at the backwards and forwards in the last class. Now, let's look at live variables. Do you think live variables is forward analysis or backward analysis? Which one do you think is more intuitive? Let's think about it. Think about it. Is it backward or forward? Think about it. Some people say forward. Some people say backward. In fact, in data flow analysis, there is no forward or backward analysis. In fact, we design forward and backward because it is more convenient to design algorithms. Let's not say it is backward. Let's say it is forward. How to say forward? It is equivalent to if the variable v in program.p is alive. Let's say there is only one path in the program. Let's say from program.p to program.x there are 100 statements. Let's look at the simplest case. If you go down, one statement goes down. The second statement goes down. Finally, at the 99th sentence, the variable v in program.p is used. You need to connect the information at every point. Then you can know whether v is alive or not. Let's think about it. If we go up from x, the variable v is used. Then you can move the used information forward automatically. You can move forward every sentence. At this point, v, p, q, and m are used. If you go up a little bit, they are not used. In fact, backward is more convenient and intuitive. Let's go on. Let's recall the characteristics of backward analysis. Let's take an example. Let's say v is equal to 3 in basic block p. Then in basic block b, there is a sentence. We don't know what the sentence is. Then in the two sequences b, s1 and s2, one of the nodes uses v. On the right side of the assignment, it means it is used. Let's recall the characteristics of backward. What is backward? Let's look at block b. It gives out b through a transfer function. Then you get in b. This is backward. Forward is the opposite. Forward gives in b through a transfer function. The first question is what is out b? In the last class, out b is actually the merge of in s1 and in s2. It is a merge. It is a merge. It is a merge of the two data. How to deal with it? We should deal with the control flow. It is a safe approximation. Take a look at the formula. You should be familiar with it. It deals with out and in during the merge. It is a transfer between out and in. There is such a formula. Let me remind you of it. I will delete it now. Think about it. There is a problem. We should deal with how to give it a safe approximation during the merge. You think may and ss is related to mass and ss. Do you think it is may and ss or mass and ss? Let me answer this question. May and ss generally deal with the union. It is a merge. If it is mass and ss, it deals with the intersection. Of course, the union and intersection will be discussed later. Think about forward and backward analysis. We talked about forward and may and ss. We talked about backward. Is it may and ss or mass and ss? In fact, all the information is based on its definition. It is based on its meaning. Good, we all say it is may. Why? Think about it. If a path is used, I think it is lived. As long as there is a path, it may be used in the future. I think it may be lived. It is may and ss. Let's look at backward analysis again. It deals with the union between the two backgrounds May and ss. As long as there is a path, it may be used. You should not miss any path. Good, this is may and ss. Next, we will deal with control flow margin. We will deal with transfer function, which is the core. In the future, we will deal with transfer function as a basic block. Let's look at backward analysis. What is its meaning? v is used here. No matter what b is, it is used from p. In principle, what is out b? It is written here. At least, it tells us that v is lived at out b. We design the transfer function backward to give a transfer function to find out what is out b Now, let's design the transfer function of live variables analysis. Is out v Then, it is possible that this language is any language in the program. You have to design a transfer function for every language in the program. So, it may be any language. You have to figure out how to design a transfer function for safe approximation. You have to think about it. I found that the comments are not very active. This is a long story. You can think about it on paper. But don't think about it because I don't supervise you. You have to think about it. The teacher is chatting with you. You have to think about it. It is a very important training for students. You have to think about it. Don't think that your classmates are fast. When I teach, after the teacher asks me something, I always get the correct answer. I think the teacher's answer is correct. Then you feel that it makes sense. It is true. You don't participate in this thinking. You don't get the answer. So, you lose a lot of the training of active thinking. In fact, it is a training about the subjectivity of a person. You don't just work in the computer field. You also work in other fields. You say that I am not innovative. You say that I am not innovative. You want me to develop a project. I can't think of anything. The main reason is that you don't have a critical thinking. The main reason is that you don't have a critical thinking. You don't have a strong subjectivity. You passively accept all the knowledge. If someone has something, you think about it. You never think about what it is. Now, active thinking gives you time to think. It is to train your subjectivity. It is good for your future development. It is good for your future development. It is good for your future development. Now, everyone, no matter if you are lazy or not, I don't ask questions now. I don't ask questions now. You just think. Now, you set out a transfer function to get its in. Think about it. Give me a minute. What should this transfer function look like? What should this transfer function look like? What should this transfer function look like? If you really don't have any thinking, I can give you a hint. When you design dataflow analysis, When you design dataflow analysis, imagine an application scenario. Imagine an application scenario. It is more intuitive. For example, let's say you decide what the value of the coin is. What does it want to say? It wants to say that the value of the coin is the distribution of the memory. Let's say the value of the coin is the distribution of the memory. If it is an integer, it should stay in the memory. If it is a DAG, the value of the coin should be deleted. If it is a DAG, the value of the coin should be deleted. If it is a DAG, the value of the coin should be deleted. If the value of the coin is an integer, the value of the coin should be deleted. Although it is a backward analysis, you can think about it from a positive perspective. Let's think about the coin. It is like solving an application. Let's say the coin is an unknown, and the student says there must be many different sentences. How can I get all of them?\n"
     ]
    }
   ],
   "source": [
    "audio_file_1 = open(\"./11-Audio-Summary/audio/lec04/lec04-0m-25m.m4a\", \"rb\")\n",
    "translation_1 = openai.Audio.translate(\"whisper-1\", audio_file_1)\n",
    "print(translation_1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "774d2a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do we really care about in this analysis? You can design dataflow in the same way in the future. In fact, we only care about whether a variable is a leave. We defined that if it is a leave, it has a use, and it is not redefined in the middle. Think about how many scenarios there can be for a variable v. You can figure it out even if you are not good at it. For example, we have an assignment here. The first scenario is written in K language. It has nothing to do with v. Now I ask you if out is b, out b is v, and the statement is k equals n. It has nothing to do with v. I ask you what is in b. Think about the scenario. At this point, is v equal to 3 a leave? Will it be used in the future? Answer. If k equals n, what do you think is in b? Is v a leave at this point? If it is a leave, it is v. If it is not a leave, what do you have to do? Q it, it is not v. Is it a leave? Yes, it is. Why? Because it is used. Let's move on. Let's say v is used. k equals v. It is easier to understand. Think about it. It is used at this point. v equals 3 is a leave. At this point, v will be used immediately. It is used immediately. What should it be? It should be a leave. We say v is on the right. We say v is on the left. What is v on the left? It is defined as v. Alright. Let's see. If v is equal to 2, what do you think is in b? Answer. Everyone, answer. Someone said the formula on the left should be in s. You will know later. I said it is backward s. I want to know what is out b. It is a combination of two backwards in. We said it is a union. What is out b? You will know when you see the expression. Someone said it is empty. Why? Good answer. Because at this point, v is redefined. Think about it. After v is equal to 3, there is a v value 13 in the memory. Next, v is equal to 2. 3 is no longer a leave. It is no longer a leave from this point. So it should be dead. Of course, you can kill the memory value. Next, let's make it more complicated. In a sentence, v is used and written. Alright. If this sentence is this sentence, what do you think is out b? Think about it. What is out b? What is out b? Good. v. Although the assignment is used the same variable, but you should know the meaning of the assignment. It is to show the new v value, and then to define it. Think about the scenario. What does it mean? Although v is redefined, it is used before it is redefined. But it is used before it is redefined. So v is equal to 3. When v is minus 1, v is still v is equal to 3. So it is still a leave. So it is good. Next, let's change another scenario. This is not a sentence. It is two sentences. v is defined first, and then v is used. What is out b? Think about it. Think about the scenario. Think about it. v is equal to 3, and then v is equal to 2. What is v equal to 3? It is dead. What does it mean? v is defined first, and then v is used. Let's draw a number. k is equal to v. v is used first, and then defined. What is this? It is still a leave. So far, we have covered all the cases. We can get a transfer function formula. As we said, transfer function gives out to get in. Out is input to get in. Out is input to get in. What is out? It is the backward of all in. It is a meganizer. Let's take a look at this formula. It is similar to what we talked about in the last class. In fact, it is also out minus q, and then a generation on union. But q is defined. Is the variable redefined? It is all about transfer function, gen and q. Generally, there is a pattern on minus q union. What is define? It is a leave. The variable is defined in out B. Should it be in in B? If the variable is redefined, like 3, 4, 5, 6, it should not be in in B. It means that out B minus def B are leave. Coming out of B, and it is not redefined in B. But all the variables should not be in in B. If all the variables are redefined in B, is it not leave? It is not. For example, if the variable is used as leave, it is used before redefinition in B. We should add these variables. In fact, this is the transfer function. Let's take this transfer function as an example. What is the transfer function? Define the variable first. But if it is used before define, we should add it. Transfer function. With transfer function and control flow, let's look at the whole algorithm. The algorithm is very similar to what we talked about in the last class. Let's go through it quickly. Input is still CFG. We still assume define and use, which is what we talked about before, gen, generation and queue. Output is still every point of the base problem. Is it 0, 0, 0, 0, 1? It is a variable. It is dead. The first sentence of this method must be a boundary condition. What is a boundary condition? It is a backward analysis. It starts from the last point in the process and goes up. What did we say before? It is getting out to in. In the end, we see that the initialization is all in B. Let's look at the exit, which is virtual. What is in? It is empty. In the last class, we talked about what the boundary condition is. It is determined by the meaning of the analysis. Let's imagine what the last point of in should be. It is a program point. Is the variable lived? Will this variable be used in the future? It is impossible. It must be empty. The initialization should be fine. After the initialization of the special node boundary, let's look at the initialization of other nodes. The initialization of other nodes should be in and out. The initialization of central function should be in. What is in? We talked about it in the last class. In theory, the initialization of dataflow analysis should be empty or not. What is not empty? In the next class, we will talk about the initialization of mass analysis. The initialization of mass analysis is 0, 0, 0, 0, 1, 1, 1. Why? We will talk about the initialization of the main analysis is empty. The initialization of mass analysis is all. If we draw a lattice, the initialization of the main analysis is bottom. How do we define bottom? The complete lattice has bottom and top. The initialization of mass analysis is top. The initialization is empty. The initialization is all. The initialization is empty. The initialization is all. The initialization is all. The initialization is all. We will talk about the initialization of mass analysis. The initialization of mass analysis is pattern. The handling of control flow and control function is pattern. The pattern is backward can't in. In, all the in have no change. End of iteration. Next, we will talk about in, not out. After this, we can give a specific example. Next, we have another program. This program is data abstraction. What is data? It is a list of variables. What are the variables in this program? X, Y, Z, Q, P, M, K. K is here. There are 7 variables. There are 7 variables in this program. Then, we have 7 zeros, a big vector. What do we do now? Initialization. The initialization is empty. After the initialization, we have the first iteration. The first iteration, let's start from the beginning. What is in B5? It is Z equals 2P. Now, the statement of B5 is Z equals 2P. What is out B5? It is 0, 0, 0, 0, 0, initialization. Now, according to the transfer function, what is the in of B5? Let's take a look. First of all, who is Q? Who is defined? It is Z. But where is Z? It is in the upper left corner. It is 0. Who is generated? It is used. Who is used? It is P. What is P? It is the fourth one. Let's define the out of B5. The in of B5 is 0, 0, 0, 1, 0, 0. Let's look at B3. The out is 0, 0, 0, 1, 0, 0. Let's take a look. It is similar. V equals V. X equals X. Now, let's see who is defined. X is redefined. X should be Q. X is 0. Who is Q? It is used. Is it used before it is redefined? Yes, it is used before it is defined. So, X should be added. X is 0, the first element. The first element becomes 1. So, it becomes 1, 0, 0, 1, 0, 0, 0. OK. Let's look at B4. It is the third statement. We have calculated B4. The out is the in of B5. 0, 0, 0, 1, 0, 0. However, B4 is special. What does it have? Let's take a look. It has two out. Control flow is merged. How does it work? It is a base block. How does B4 get its out? It is the union of all the in of the successor of its out. Let's say it is a main. How many out does it have? It has one. What about the other successor? It is B2. What are the in of B5 and B2? The in of B5 is this. What is the in of B2? It is 0, 0, 0, 0, 0. What is the union of 0, 0, 0, 1, 0, 0 and 0, 0, 0, 0, 0? It is still 0, 0, 1, 0, 0. OK. The out of B4 is 1, 0, 0, 0. OK. Let me show you what is the in of B4. Let's do it. What is the in of B4? What is the in of B4? It is 0, 1, 0, 1, 0, 0. OK. Let's see if it is correct. It is correct. What is Q? It is X, Q. Right? Yes. It is correct. X is 0. Q is also 0. We don't need to worry about it. U is Y. U is Y. Y is 0. It is 0, 1, 0, 1, 0, 0. Very good. OK. What is B2? It is B4 and B3. What is the union of B4 and B3? It is 0, 1, 0, 1, 0, 0. What is the union of 0, 1, 0, 1, 0, 0? It is 1, 1, 0, 1, 0, 0. 1, 1, 0, 1, 0, 0. It is the out of B2. OK. What is the union of B2? Note that M is defined. M is defined. Note that out of B2 is 1, 1, 0, 1, 0, 0. It is the out of B2. What is the union of B2? Start to calculate. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "audio_file_2 = open(\"./11-Audio-Summary/audio/lec04/lec04-25m-50m.m4a\", \"rb\")\n",
    "translation_2 = openai.Audio.translate(\"whisper-1\", audio_file_2)\n",
    "print(translation_2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b8210f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we can't put it in. So what does it become? What is the result? 100. Remove 100. 100, 100, 100. Alright. Let's continue. 100, 100, 100. Look here. The red and the blue haven't changed. The last time the variable and this time the variable result haven't changed. The output won't change either. Alright. Do we need to stack? We've thought about it last time. Of course we need to stack. Why? Because there is... The second time the variable is over, we need to stack. It's because of B4. Pay attention. The result of B4 has changed. B4's print has changed. B4's print has changed from 010100 to 0101001. So we have to continue with the third time. Alright. Starting. Finally. 0000. The output hasn't changed. Backward. The print hasn't changed. Continue. Has the output changed? Have the blue and green changed? No. The print hasn't changed. Continue. Has the B4 output changed? No. What is the print? Doesn't change. Has the output changed? We will know after a while. Look. Has the blue and green changed? No. So what? The print doesn't change. Has the B4 output changed? No. Has the blue and green changed? No. Has it changed? No. Alright. The third time. End. All the prints. We will go through this quickly. Because we are actually very clear about this. All the prints haven't changed. This is the end of the algorithm. Alright. Let's go through the algorithm again. The final analysis result is the 010111 that you get at the end of the iteration. For example, at this point, what does it mean? This point, 1001001, means that X, the first one, and the fourth one, which is P, and the last one, K. X, P, K. These three variables are leave. The rest are dead. Alright. This is the result. Although it is a backward analysis. Alright. This is the final analysis result. We have finished the explanation of leave variables analysis. Next, we will talk about available expression. Let's take a break for 3 to 5 minutes. Alright. We will be back in a minute. Alright. Let's take a break for 3 to 5 minutes. Has the school notified you about the return to school? Has the school asked you to be ready? For example, the school starts in April. Have you prepared in advance? No. The teacher has notified me. The teacher notified me on the 15th that I will return to school. That is, I will not return to Nanjing. After returning to Nanjing, I will be quarantined for 14 days. I will be quarantined for 14 days. If everything goes well, I guess the school will start in April. But I don't know when it will start in April. Alright. Let's move on to the next topic. Available expressions. First, I want to tell you that this is a must-know analysis. OK. Let's start with a sentence to summarize the concept of analysis. OK. Expression. X, O, P, Y. You should be familiar with the expression. You can think of X, O, P, O, P as a mathematical algebra, addition, subtraction, or a logical algebra. You can even say that it is more... Some students say that X, Y, subtract 6, divide by 8, multiply by 1, what should I do? We talked about this in the second class. The 3-digit code will be divided into 3-digit numbers. The expression will appear in the form of X, O, P, Y. What is the expression? We said that the available expression is actually in the program point P. It depends on whether the expression is available. It's that simple. Alright. I won't talk about the start of school. I don't know when it will start. The school hasn't notified me. I guess I have to listen to the government's arrangement. Let's wait patiently. If the expression is available in the program P, it's easy to understand. What does it say? First, all paths from the entry to P start from the entry. Entry is the virtual entry in CFC. The entry of the whole program. From that point, all paths to P must pass through the evaluation of X, O, P, Y. What does it mean? It means that there is an expression X, O, P, Y in the program X, O, P, Y. For example, X plus Y. Then, from the entry to P, let's say there are 100 paths. In these 100 paths, they all have to evaluate the value of X, O, P, Y. The dynamic search has to evaluate the value of X, O, P, Y. Then, we say that this is the first condition. Must pass through the evaluation. All the paths. The second condition is after the last evaluation of X, O, P, Y. Let's say there are 100 paths. Let's say there are two paths. Each of them has to evaluate X, O, P, Y. At the same time, the last evaluation is the last evaluation of each path. After that, we should not redefine X or Y. These are the two conditions. The two conditions are available expression. So, what do we want to do with the available expression? The definition of available expression means that at program P, we can replace the expression X, O, P, Y by the result of its last evaluation. First, each path has to evaluate the value of X, O, P, Y. At the same time, after the last evaluation of each path, if we don't redefine X or Y, which are the two operands, then we can calculate and less evaluate the expression X, O, P, Y. We can replace the expression X, O, P, Y with the last one. In fact, this information can be used to optimize global common sub-expressions. We will talk about this in the next lecture. Of course, I won't talk about this. OK, let's move on. As you are familiar with it, let's move on. The data of the available expression should be abstract. What is the data? What are we paying attention to? It is the expression. Of course, the data is the expression of all programs. It can also be expressed as big vectors. If there are 100 expressions in the program, then we use 0 and 1 to express them. The second 0 and 1 represent the second expression. 0 means that this expression is available. No, it is not available. 1 means it is available. OK, this is related to data. Next. OK, what are we going to design? Control data flow analysis. How does it flow? We need to design a safe approximation rule. Design a transfer function for each node. Design a control flow for nodes. Especially for the gathering point. Design a margin for it. OK. Obviously, we don't need to think about the available expression. It is a forward analysis. Because from the entry point to this point, some information before this point needs to be collected. It is a forward analysis. OK, let's look at it in the simplest way. For example, there is an already known available expression before we implement this language. Let's say we implement it in the front. It is a plus b. This is an available expression at this point. Now, I will ask you. After a equals x, o, p, y, what should its out be? Well, I will let you think about it. Actually, it is easy to think about. We have already followed the concept in the front. I will tell you directly. What is it? First of all, let's see. What is out? It is the forward that I mentioned before. First of all, x, o, p, y, it just evaluated. Let's say it only has one path. So, it just evaluated this expression. So, it should be out. We still have a gen and q problem. I mentioned it before. Most of the dataflow analysis are gen and q problems. It is still our central function. What is it usually? Out. What is forward? Out is equal to gen on union. Then, what is in? Then, subtract q. Gen is the newly generated expression. It must be available. Right? After the execution of this sentence, at this point, o, x, y, x times y, o, a, x, o, p, y, it must be available. So, we put it in gen. Then, delete from in any expression evolving variables a. Why? a is redefined. That is to say, when you want to queue the print output, all the expressions with a as the expression and the number of operations. Because it is defined according to the definition. On the last path, the last evaluation, right? There should not be any redefined a after that. In the expression, a or b cannot be redefined. What is in it? It is redefined. Right? Redefined. So, delete from in any expression evolving variable a. There is only a in it. So, we remove a. Then, what is its out? a plus b has been removed. It is deleted. It will only leave the newly generated x, y, p, y. So, its transfer function is more intuitive. This is the rule. Let's go back to the rule. This is forward. So, it is for the print output. Then, who is it queued? What is it queued? Delete from in any expression evolving variable a. This is to delete all. In this, redefine it. Define it. If it is in the front, as an expression, one of the operations, you can queue it. Then, there is generation. Generation is the newly generated expression. Alright? Alright. After looking at the transfer function, what do we look at? An example. This example, let's make a judgment. Now, a is equal to e multiplied by 16 multiplied by x. Now, the expression we are concerned with is only this one. e multiplied by 16 multiplied by x. Alright. Here, redefine x. Then, b gives this value. Then, c is equal to this expression. Now, I ask you. Do you think that before c is equal to the compound sentence, which is the compound sentence before the compound sentence, the expression e multiplied by 16 multiplied by x is available? Think about it according to our definition. Is it available? Think about it. Think about its definition. Think about it again. Is it available? Don't try to understand it according to your own understanding. Available expression is a bit annoying. Let me remind you. It's not that you want to analyze it. It's just like this. It's just like this. It tells you whether its name is available. Think about it. Is it? You have to think about its definition. Do you hear me? Think about its definition. Some students say yes. Some students say no. Let's take a look at it. Let's think about its definition. Alright. Let's assume that when we do this, when we say after the end, of course, the available expression is e multiplied by 16 multiplied by x. After the end, it is available. When we do this, it is available.  Let's look at this sentence. We said that the event is a base block. In fact, it is for each statement. Apply its transfer function. Alright. We said that the transfer function is here. Then, x is equal to Oh, x has been replicated. Right? Let's assume that this is not an expression. We don't need to generate a new one. Then, when we queue it, we queue it, right? We print the above and invoke an expression like x. Alright. queue it. It's empty, right? Alright. It's empty. After it's empty, x is equal to expression available. It's not. Let's move on. Now, it's empty. b is equal to the print of the replicated sentence. Then, what is its out? First, we need to generate an expression. e is equal to 16 multiplied by x. Then, we need to remove the expression with b in the print. Then, is it available? No. The print is empty. So, its out is expression. Alright. This division on the right, its out is also expression. It is directly passed down. Because we will talk about how to combine the two expressions later. I am asking you if it is available. Both are available. Of course, it is available. Available expression. This is the definition. We say this is an available expression. Then, some students will say that the value has changed. x is the value. Let's see how to use it. Let's follow its definition. If it is an available expression, we can have many options to optimize it. One way is to divide each value. Since it is available, we can use a temporary variable to calculate the value directly. Have you calculated the value directly? Then, we give t. The temporary variable is t. Then, we change a, b, c to t. Because it is an available expression. Then, when it is running, think about it. First, we need to do a transformation to the program. Some people will do a transformation. The program will look like this. It will either follow this path or this path. No matter which path, the value of t will follow the distributed value. The distributed value may be different, but it will only follow one path. t will follow one value. Since t follows the same value, it will calculate e to the power of 60 times x. We don't need to calculate this one, or this path. We use the last evaluation of this expression. We don't need to calculate this one, or this one. We only need to calculate the available expression. OK? OK. We mentioned the control of merging. I said this is mass analysis. What does mass analysis mean? All the paths must meet this condition. Let's define it. Let's define the merge of all the paths. Why? Because all the paths must evaluate this expression. Let's say there is only one path. Can all the other paths evaluate this expression? No. All the other paths must evaluate this expression. OK. So this is the merge of all the paths. Let's emphasize that in the last class, no, in the second class, we said mass analysis is under approximation. OK? So under or over is also safe approximation. What is safe? Safe is when the analysis is under approximation. My analysis is safe if it is under approximation. For safety analysis, it may report an expression that is truly available. Even if it is truly available. OK? Now we will say it is safe. What does that mean? It is under approximation. Under is false positive. It is true if it is true. But it is safe. The main analysis is the opposite. It is over. Under is safe. It is true if it is true. Under is true if it is true. It is true if it is true. Under is true if it is true. OK? This is the result. It is not available. In real world, X is redefined. Redefined X is different. It is not available. But X is true if it is true. In real world, X is true if it is true. Under is true if it is true. When you look at the result, it is a redefined function. This is true if it is true. When you look at the result, it is true if it is true. When you look at the result, it is true if it is true. When you look at the result, it is true if it is true. When you look at the result, it is true if it is true. When you look at the result, it is true if it is true. When you look at the result, it is true if it is true. When you look at the result, it is true if it is true. When you look at the result, it is true if it is true. When you look at the result, it is true if it is true. When you look at the result, it is true if it is true. When you look at the result, it is true if it is true. When you look at the result, it\n"
     ]
    }
   ],
   "source": [
    "audio_file_3 = open(\"./11-Audio-Summary/audio/lec04/lec04-50m-75m.m4a\", \"rb\")\n",
    "translation_3 = openai.Audio.translate(\"whisper-1\", audio_file_3)\n",
    "print(translation_3['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50f6675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We'll talk about that later. But here, you can imagine. Think about it. In our mass analysis, look at this. When the control flow is gathered, what does it do? It does intersection. Imagine that the initialization is zero. So, let's say you start to vary, and then you get a result. Then, if you suddenly gather a little bit, the first time there is a zero, it will come and intersect with your result. Zero intersects with any other zero. It's all zero, zero, zero, zero, zero, zero. Right? Your analysis is in vain. In fact, you can know from this point that it can't be zero. We'll talk about why it's one later. A little bit later. In fact, it's equivalent to a lattice. From its top, and then down. The top is the biggest. Let's say the lattice we designed is the biggest. It's a little bit down, but it can't find the point. We'll talk about that later. But remember, it's really one. In this case, it's all one, it's all out. So, it's still forward-neutral. So, let's look at how out varies. The rules in it, we just talked about it in the last slide. It's also a gen-q problem. At the same time, each meeting point should make an intersection. With such an algorithm, we are familiar with it. At this time, we can see if out varies. If out varies, we will continue to delay. Let's take this algorithm to give an example. Okay, let's look at the program. You may be familiar with control flow. The thing inside has changed. It's changed again. What has it become? It has become a set of expressions. Let's see how many expressions there are. There are five expressions in it. p-1, z-5, right? z-5, e to the power of 7 times x, what? 2 times y, where is 2 times y? 2 times y is here. Then, y plus 3, y plus 3, these are the expressions. How many are there in total? Five. Simply put, five. Okay, let's start the algorithm. Let's say this is forward. The initialization, all initialization, let's see. The boundary condition for initialization is 0. The other basic block initialization is 1. Right? Unit, not unit, that symbol represents 2. Okay, after initialization, let's start the algorithm. The initialization starts. Okay. Int is 0, 0, 0, 0. Let me ask you, what is out B? Let me show you. We said before, what is its out? Let's see. Who is Q and who is Gen? Who is Gen? Gen is p-1. Then p-1 becomes 1. This inversion is over, right? Then, who is Q? Q has evolved y in the front, but y doesn't. What does it become? Very simple, 1, 0, 0, 0, 0. Okay, let's continue. B2. B2 is interesting. It has a pattern. Who is B2's forward? Let's see. B2's forward is p-1. Who is B2's other forward? It's p-4. Okay, what is the out of the forward? Gen. Okay, the out of the forward, Gen is the input of B2, right? Let's see. Who is Gen? I mentioned it before. The initialization is 1, 1, 1. If the initialization is 0, 0, 0, 0, 0, 0, 0, 0 plus 1, 0, 0, 0, isn't it 0, 0, 0, 0? This 1, 0, 0 is useless. Why is the initialization 1, 1? This is another explanation, okay? Okay, initialization 1. 1 plus 1, 0, 0, 0 is still 1, 0, 0, 0. 1, 0, 0 is the input of B2. Okay, B2's input. Now let's calculate what B2's output is. What is B2's output? You just write this, this, this, this. No, we use 0, 1 to represent it. You can write it. What is B2's output? Who is Q? Who is Gen? Who is Gen? Who is Q, right? This is quite simple. Think about it. How many expressions do you need to generate? How many expressions do you need to Q? Think about it. What is the result? Good. Let's go again. Who is Q? Who is Q? Who is Q, right? Who is Q, right? Who is Q, right? Who is Q, right? 1, 0, 0, 0 is the default expression. Okay? Who is Q, right? Who is Q, right? 1, 0, 0, 0 is the default expression. How many expressions do you need to give? How many expressions do you need to give to B2? One. 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 16, 18. Okay, good. Let's go again. Who is Q? Q is the second one of the octagon, right? Q is the second one of the octagon, right? After that, E is the fourth one from the rectangle, right? After that, E is the fourth one from the rectangle, right? 1, 1, 0, 1, 0. What is Q? Do we use Q, K? Do we use Q, K? Do we use Q, K? Q is the second one of the octagon. The second one is 0. The second one is 0. 0 100 110 110. 0 100 110 110. 0 100 110 110. The semi-second box and the first one. the second one is the first one of the octagon, what is the octagon's out? Note that there is only one box in the second one of the octagon, it is the out of the second one, i.e. 010010. Ok. Let's continue. 2 times 1 is 3 times 1, 1 multiplied by 720x is 1 anyway. Qilang has x, which has x? 1 70 times x. Oh, I've a question. This one you need to think about. All right. Let's start by saying that This box is it, we'll take one Q on the left 5 times 1 70 times x. Its evaluation is the last one, 1 70 times x, it uses it again. Q times x, 1 70 times x, it uses it again. In other words, it evaluates this expression again. According to our definition, behind this expression, there is no re-definition of x, so it has to be generated. There are students who ask, this order, I'll ask you about the order of Gen and Q. You can think about this. Gen and Q, Gen and Q, can you cover this situation? Think about it yourself. All right. We say this 1 70 times x, Gen comes out, right? Q, Q is Q times x. First, 1 70 times x is Q, but Gen comes out here. If you Q another one with Q, there is no Q below. So what is the result? 011, 01110, 01110, right? Because we have generated a 2 times y, and then we say, is it necessary to use the involved x, this 1 to, for example, the fourth 1 70 times x, to Q. We say no, because although x is Q at this point, just like the example we talked about last time, Q at this point, but this point is re-evaluated, right? Everyone pay attention to this order, okay? According to our definition, you won't make a mistake. All right. After that, let's continue to look. It has two procedures. What do you want? Intersection. Intersection, not union. What is that? The first three are 0, then this must be 0. The back is 11, the front is 10, then what is it? The first three are 0, 000010, right? 000010, 000010, then what do we do? What do we do first? Generate 1 70 times x, 1 70 times x, then this is 5, this is 5, the second, the second is the fourth, the second becomes 1. At the same time, the involved m is not there, the involved y is there, the involved y has two, one is the third, one is the fifth. The fifth itself is 0, right? The third, the third was originally 0, 1 70 times x is 5, the second, the third itself is not 0, then it becomes 01010, right? No problem. No problem, the fourth iteration is over. Obviously, we continue to go down, I won't ask you anymore, we should go down, because what? All the outs have changed, because it is forward, look at the outs, right? They have changed, from the original 1 to 0. Ok, continue, the second iteration. If the in does not change, the out does not change. I mentioned this idea. So, does it change? No, the blue and red do not change, the result of the last iteration is red. Ok, continue, the second, pay attention, the second, whose forward area is it? B4 and B1, ok, B4 has changed, 1 becomes 01110, although B1's out has not changed, but B4's out has changed, but B4's out, after B1's out, does it change? Or what? Or, it has changed, it has changed, it has changed to 000000, pay attention to this result, it has changed to 000000, 01110 and above, 10000, what has changed? Because the first one is 0, this is 1, it has changed to 0000000, 000000, ok, continue, look, the result, I will calculate it myself, look at the result, I have calculated it for you, Z divided by 5, Z divided by 5, what? It has changed to 1, right? E square times X, it has changed to 1, is there a Kp in front? No, there is no Kp in front, so add two 1s, 01010, ok, continue, 01010, look at B3, B3, B3, Y plus 3, Y plus 3, the fifth one has changed to 1, there is an emoji in front, there is the second one, 1 has changed to 0, right? Ok, 000000, continue, look at B4, B4, 01010, ok, what is B4's out? B4's out is 2 times Y, right? Actually, look at 01010, this is also 01010, if this has not changed, its out will not change, red and blue are the same, so this blue and red out will not change, ok? It is also 01110, then continue, look at B5, what is the emoji? 01110, 0001, what is it? 0, after 0, you will find that it is 00010, 00010, B5's emoji does not seem to have changed, then B5's out will not change, right? B5's out is 01010, ok, now I ask you a question, do you think that the second iteration is over, do you still need the next iteration? Let's see if all the outs have changed, right? Do you need the next iteration? Let's see. Take a closer look. Very good, there is no need. The result of the red and blue iterations are the same, so the algorithm is over, then the blue result is the final analysis result. What does it mean? At this point, for example, this 100, only the first iteration is available. No wonder, because there is only one evaluation, right? Next, we can interpret this result. This is available expression analysis. Ok, so far, dataflow analysis, we have finished the application part. We have introduced three very typical dataflow analysis applications. Now, we will make a comparison of different applications. If you can compare these three applications, if you can master these three dataflow analysis applications, you will be able to understand each of them. Moreover, I think you will be very familiar with the algorithm. So, I think you should use this application. In the future, when you meet dataflow analysis, you will not panic. You will design one and it will be easier for you to understand. So, I believe through these three specific analysis, you should master dataflow analysis. Now, let's test this application. You must fill this form. As I said, you must fill this form. So, I am not telling you to memorize it. You have to understand the meaning of this form. Ok, let's fill this form. Now, all of you can take a piece of paper. You don't have to write on the left side. There is no time. You can fill on the right side. Let me ask you what is domain? All of you start to fill. Domain, I want to tell you what is domain. It is your dataflow analysis. What is your data? What is abstraction data? It is a bunch of what? Don't tell me that domain is a bunch of numbers. It is just a form. In reality, you can't make it a bit vector. It is not like compressing data and then operating through the operations between positions. You can't make it like that. It is just a form. Now, let me ask you what is domain? After you finish writing, type 1 on the screen. If you don't finish writing, use a pen. Everyone uses a pen. Everyone uses a pen now. Are you done? As soon as I see 3 of you type 1 wrongly, I will start to tell you the answer. 5 of you, OK? If you don't have a pen, go get one. Or, write a note on your notebook. Don't be lazy. I will test you in class. OK. It is easy, right? OK. Next, direction. Every analysis, every data flow analysis, it has to be sure that it is forward or backward. These three, you can't look forward to science 2. If science 2 is put in the group in advance, you can't look forward to science 2 and answer. What is original damage? What is livable? It is when your brain is running at high speed. Once you understand this part, your homework today will be fine. This part of the test is also clear. OK? It will save you time. So, move your brain quickly. Use your own understanding. Don't refer to anything. Direction. Are you done? If you are done, type 1. If you are not done, type 0. Good. See if I am right. Rich in definition is a forward. Think about it. Let me summarize for you. What is rich in definition? A definition will be rich in this part, right? A definition, the front definition, will be rich in this part. So, you need to have a front definition. What did I say about backward and livable? I said that future and livable will be used. Is it lived? Future. Then, available expression starts from the entry. All paths may evaluate your expression. It starts from the entry. Forward, backward, forward. Next. Rich in definition is livable and available expression. Which one is meganesis? I'll show you. OK. May is the last one. You may think I always say you can remember, but you have to understand what May is. What is reaching definition? As long as there is a definition that can reach this point, we say you are May. What does May do? It's over-approximation. In other words, there is no reach in that path. It doesn't matter. As long as there is a path, it's fine. I want to consider all the paths. Similarly, leave variables in. Although it is a backward ss, but what is it? As long as there is a path behind, from this program point, there is a path behind the variable, and I use it, I think you are lived. It's based on definition. Available expression is different. All the paths from entry to my must be evaluated. You can't do without one. So we do under-approximation. What you report should be right. It's all right. It's all true. It shouldn't be false. OK. Boundary. What is the rest of the boundary? Algebra. Algebra, we say, remember, it's easy to be ignored by everyone. Everyone basically remembers what the transfer function is. You don't have to remember this algorithm. This boundary. What is the boundary? Write it yourself. Including, it is in or out, it is exit in, or entry in, or entry out, or exit out. Give you more time, OK? OK. OK. Recall the algorithm. Think about it. The algorithm, it is related to forward and backward. Forward is to see who. It is to see entry as exit. To see entry, I said earlier, mail access. It is to see out, in, right? To be honest, it is in, right? It is to see if it is backward or forward. OK. Look at the result. It is a forward analysis. Right? It is out. If it is forward, it should be entry. We say, it is empty. The new variable is backward. It is in. It is exit. It is going up. Right? Then, the same way, it is a forward analysis. So, it is out. The entry node is out. OK. Initialization. OK. It is easy to ignore. If you really know the transfer function, before you do it again and again, initialization, it is to say, initialization of all nodes, 0000 or 1111. OK. What is initialization? Let me give you a hint. I said earlier, it is related to mail access and mass access. Let you remember it. Right? Know it first. Then, I will talk about it in the theory class. Let's continue to discuss it. OK. OK. Let's see the answer. OK. Transfer function. Transfer function. Actually, we all have seen it. You can write these three into one form. As I said earlier, what are these three forms? We have a special term, Gen-Q problem. They are all Gen-Q problems. Once you write it, the basic form of the transfer function is OK. Out is equal to who? In is equal to who? Actually, I just show you a template. You may think, hey, the backward and forward lines are different. I just want to show you a template. Sometimes, we give in to out. Sometimes, we give out to in. Right? Give out to in. You just need to write the template roughly. You don't need to talk about it. This is the general form. Then, let's swap out and in. This is forward and backward. This is Gen-Q problem. It looks like this. Let's look at the algorithm side by side. We won't talk about this part. Meet. Meet. Why is it called Meet? This is equivalent to how you deal with the information in the control flow margin. Union, intersection, and others. Actually, using Meet is the general way. When we talk about lattice, we have different names for it. We call it Meet. Sometimes, when you have a complete lattice, it has both Meet and Joined. Meet. Meet. How do you deal with the control flow margin? Press 1. We are almost done. Be patient. We are almost done. Two more students. Meet. Union. Mass. Intersection. Of course, not only Union and Intersection. Actually, this is equivalent to how you gather the information in the control flow margin.\n"
     ]
    }
   ],
   "source": [
    "audio_file_4 = open(\"./11-Audio-Summary/audio/lec04/lec04-75m-100m.m4a\", \"rb\")\n",
    "translation_4 = openai.Audio.translate(\"whisper-1\", audio_file_4)\n",
    "print(translation_4['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cb9d23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to combine these information. For example, in the future, we will talk about constant propagation. You can see that it is not a pure union or intersection. OK, let's summarize this table. Among them, there are only three examples of main-master boundary. But it has a universal property. When you design other data flow analysis algorithms, you need to consider the meaning of these two elements. For example, when you look at the definition of rich definition, you need to look at whether the definition is rich or not. If the definition is not rich, then the definition is empty. You need to look at the definition in this way. In fact, the definition of main and master can also be inferred from the Korean language. The other two points are more important. When we talk about initialization, sometimes it is empty, sometimes it is all, sometimes it is union, sometimes it is intersection. In fact, we will build a theoretical framework for everyone in the future. We will give you a systematic explanation through the theory of Ge. When is main-master, when is master, when is initialization, what is initialization, and what is meet. OK, let's say that other people do not use static analysis as a major or minor course. They may remember how to use Alt, Gen, Int, and Q. They may also remember Forward and Backward. But you are a person who has chosen this course. I require you to remember this form. You have to remember it, and you have to remember it with understanding. I think I have told you every detail of each corner of this form. And I have repeated it. So you have to think about it yourself. I require you to remember this form. If you can remember it all, I think you have mastered it. You have mastered this aspect. This form, in order to force you to remember it, we will test you if it is possible to remember it. OK? To sum up, what did we talk about in the last class? I spent a lot of time to go through all the details. In order to make it clear in terms of application, we will also build the theory in the future. We talked about the basic framework of data flow and assets. Asset abstraction and safe approximation. Among them, Maze is over-explanation. Master analysis is under-approximation. Then, we briefly introduced some basic concepts of data flow and analysis. In, out, and the order of execution. Who is in? Backward, forward. Who is in? Who is out? And so on. These are the basic concepts. Including the basic process. What is its transfer function? In fact, it applies the transfer function of each statement in it. And so on. We have talked about these. After that, we listed three very typical analysis. One is Maze analysis, which is forward. The other is Backward analysis, which is the variable analysis. And then, there is Master analysis. Master is forward, available expressions. After that, I will give you a summary. In the third part of the lecture, we talked about the final algorithm. Why does the algorithm stop? Why does it reach a point? We also talked about it. We will talk about it in the next part. The above is the main content of this lecture. The main content of these two parts. About the application of Dataflow and Essence. OK. In these two parts, about the application, data flow analysis application, what do we need to remember? That is to say, you can't remember many details, but you have to remember and understand these points. I think you can master it. First of all, these three, Dataflow and Essence, if you can't remember all the details exactly, you should know the meaning of these three. You should understand the meaning. Once you understand the definition, I will tell you the details of each definition. How to understand it? How to understand it with a scene and an example? As long as you understand something, it will be easier to design a Dataflow algorithm in the future. In fact, we are all like this now. Everyone has a demand. For example, everyone wants to check this error. Everyone wants to check this security loop. I want to optimize this thing. If you have such a demand in the future, what is everyone? Describe it in natural language. You have to understand what it says. If it is converted into an algorithm, how do you understand it? How do you put the scene into it and design the algorithm? This requires us to have such an ability to understand the scene described by people. Then design according to the scene. I have taught you this before. Then you can also say the similarities and differences of these three analyses. In fact, it is the table we saw earlier. You have to remember this table. Finally, you have to understand why the stack algorithm can eventually stop and eventually reach a non-moving point. Let's review it again. In fact, when more facts come out, come in, the whole out is a little bit... Because Gen and Q are fixed, so when more Dataflow comes in from the in, your out will not shrink. It will only grow. In fact, as we will talk about in the next class, this involves a monotonicity. This is our Dataflow analysis. It is monotonic. For example, what is monotonicity on Lattice? We will talk about it. This monotonicity is related to whether your analysis can stop or not. All right. This is all the content of the whole Dataflow analysis of this class. So, I will be very nervous in the next class. To be honest, I am not confident that I will still upload videos and live broadcast next week. I will talk about this in detail in the group. Because I think I still want to present the theoretical part of the next class to you. So, I can't be in a hurry. I can't finish the PPT in a hurry. The next class is very important. So, I am also trying to understand how to present the next class to you. So, at least I have to be satisfied with what I want to present. So, I hope that we can still have classes on time in the next class. All right. That's all for today. I will leave you with five minutes. All right. If you have any questions, feel free to ask. If you don't have any questions, you can leave now. All right. If you are not ready, you can change to the weekend class. Don't scold me. Sorry for the delay. I will try my best to be on time next Wednesday. All right. We will discuss this in the group later. That's all for today's class. When you watch the first video, you will be very emotional. I will tell you more about it. You will be very emotional. You will be very impatient. You are college students. You must remember that you will be very impatient in the future. I have written a letter like this before. The answer is like this. What do you feel? Learn something. When you see a lot of good resources in there, you will be very impatient. Of course, you will think that when you see something like this, such a good resource, or a good book written by Professor Niu in a foreign church, you will feel that you have bought this book. When you buy it, you will feel that you can learn this knowledge. You will be very capable in the future. But after you buy this book, most people will put it aside. Some people will read a few pages, but they won't read it again. Or some people can read it, but they can't read it because of various reasons. Then this knowledge will be wasted. When you see something and you feel that it is useful to you, you will feel that you have bought it. How to say it? You will feel that you have bought a lot. You will feel that you will be successful in the future. What do I want to say when I come back? What do I want to say when I come back? Persistence. You must persist. Learn something. Look at our class. How many people listen to the first class? How many people listen to the second class? How many people listen to the third class? Of course, it is possible that what I say is not good. Some people don't want to listen to it, or some people don't want to listen to it. But look at this. It is like this. You can't persist. For example, I want to learn financial analysis in the future. I want to give myself a better chance in the future. There may be more choices. But if you keep learning, you won't be able to keep learning. Why? Why can't you persist in one thing? If you are such a student, I hope you reflect on it. Some students say that we are studying for a doctorate, right? There are many doctoral students here. Why can a doctor persist? If you don't really want to get a doctorate in the future, if you are really pushed, it is difficult to publish your thesis. Can you persist? So you still have to persist subjectively. Do what you want to do. You have to mobilize your subjective mobility. Then you will know that you are willing to do this. For example, you are willing to kick the ball. You say, who is going to kick the ball? If others don't kick the ball, you are willing to call someone to kick the ball on a rainy day. Because you have this hobby. You are willing to take the initiative to do it. What about learning? Who is willing to learn? It's all for the sake of having a good foundation. But you will gradually improve in the process of learning. Because you know more and more. After you persist, you will know more and more. You are a positive feedback. It is a positive feedback. It will push you forward. This hobby is slowly cultivated. Whether you have a hobby for this course or not, I hope you can persist in learning. If you don't choose this course, it doesn't matter. I can be irresponsible to you. But for those who choose this course, there are nearly 40 students in Nanjing University. You must persist in this course. Scores are not important. If I see that each of you learn very well, I can give you a very good score. I can design the exam questions well. But this course is for you to learn. This is the first course of Nanjing University. This is the first time to talk about software analysis. You have to persist. You have to persist. In fact, I mentioned in the first class that things are expensive in detail. In fact, you will have an advantage. I can tell you for sure that your market is really big. Whether you are a undergraduate, a master's student or a doctor, you will do static analysis. At least at the beginning, the domestic market is in a very short supply. You have a great advantage. I also want to tell you that you can see that the people who listen to this course actually have Alibaba and Huawei, and the top IT companies in China and their employees are also listening. They are all doctors and master's students. They have read it. In fact, they have learned a lot. They are also listening to this course. Why? In order to let themselves learn and be in a state of learning. I hope that this will improve their ability in the future and help them develop in the future. It is not that learning is never a straight-forward thing. So all the students here should learn from them. You have to keep learning and push yourself forward. At least in this course, I hope you can learn something and be responsible for your life. Why do you want to go to this university? You have worked so hard for more than ten years. Okay? Okay. If you don't have any questions, let's stop here today. Okay? Let's meet again at 10 o'clock next Wednesday to fight for the meeting. Okay? No more questions, right? Can I close the class now? I am leaving. I am leaving. Okay. Bye bye. Bye bye.\n"
     ]
    }
   ],
   "source": [
    "audio_file_5 = open(\"./11-Audio-Summary/audio/lec04/lec04-100m-end.m4a\", \"rb\")\n",
    "translation_5 = openai.Audio.translate(\"whisper-1\", audio_file_5)\n",
    "print(translation_5['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8858e9f9",
   "metadata": {},
   "source": [
    "## Lec05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6070fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's officially start the class now. This is our data flow analysis. Today we will talk about the basic part of data flow analysis, the foundations. This is the fifth class of software analysis, and also the third class of data flow analysis. In the last two weeks, we talked about the application part of data flow analysis. Today and next week, we will spend two more classes on the foundations. As I mentioned before, the foundations are abstract, gray, and difficult to understand. So if you don't understand what you hear in today's class, it's okay. Based on my experience, even a PhD in software analysis doesn't know much about the foundations of data flow analysis. So it's okay if you don't understand what you hear. I think the main reason is that the foundations are abstract, gray, and difficult to understand. Another reason is that according to my research, there is little good information about the foundations. There are only two types of data. There are also some materials that are not systematically deep enough. But those materials are too difficult to read and understand. So I spent a lot of time preparing for this class on data flow analysis foundations. During this time, I also discussed a lot of details with Mr. Tan Tian. In the end, I will present these two classes to you this week and next week. Because my personal ability is limited, I will try to explain this part of the content as systematically as possible. At the same time, I will try to make it easier for everyone to understand. This is the outline of this part of the content. If you have read Longshu, you will notice that this part of the content has a lot to do with Longshu. I personally think that Longshu's foundation is not well written. The main reason is that Longshu uses half-branches. If you don't understand what I'm saying, it's okay. I'm just explaining why I don't use half-branches for Longshu. Longshu uses MIT and UNIT for half-branches. This is understandable, but a lot of things are very complicated. It doesn't look very intuitive. Especially when you combine it with MAP analysis and mass analysis, a lot of people are confused. Is this analysis accurate or not? Is the largest or smallest point accurate? At this time, you will intuitively make a lot of mistakes. And Longshu itself is not systematic enough. So please understand what I'm saying today. After listening to my lecture today, I think it will be easier for you to understand Longshu. Okay, let's get started. Let's see what we will talk about today and next week. First, we will talk about Iterative Algorithm. In fact, Iterative Algorithm is another view. We will look at Iterative Algorithm from a different perspective. We talked about Iterative Algorithm in the last two lessons. In fact, we encountered Reaching Definitions, Leap Variables, and Available Expressions. In these three analyses, Iterative Algorithm was used. It is the continuous iteration, transfer function, out, in, control flow margin, and so on. After processing these two formulas, until all the out, the main license depends on all the out, it does not change. Then the algorithm stops. The master license depends on all the in, it does not change. Then the algorithm stops. Backward depends on all the in, it does not change. This is Iterative Algorithm. Today, I will first look at Iterative Algorithm from a different perspective, so that you can better digest and absorb Iterative Algorithm. The purpose of this lecture is to focus on this algorithm, because it is a general algorithm. Most of the data flow analysis can be obtained with Iterative Algorithm. We will focus on a general algorithm, a universal algorithm, and ask a lot of fundamental questions. The content of our course is to answer these questions as much as possible, which is equivalent to providing you with a motivation to learn it, a motivation to learn the foundation. In fact, some people have asked this question in the last class, or in the last class, in the last class I mentioned what Iterative Algorithm is about. Iterative Algorithm is about non-moving points. Some students asked, is there only one non-moving point? Will there be many non-moving points? And so on. In fact, after learning the first part, we asked some general questions. In fact, to answer these questions, what do we need in the end? We need the content of the sixth part, which is a non-moving point theorem. It is actually related to lattice. It is a non-moving point theorem that defines the function on the lattice. In fact, the most important mathematical concept we will talk about today is lattice. Because we want to divide the data flow analysis into five parts. It is expressed through lattice. After the expression, some properties of the data flow analysis can be expressed through some properties of lattice. Such properties can be easily proven. But before talking about lattice, if I talk about it now, it will be more... Because it depends on some already existing concepts. For example, what we talked about in part 2, 3, and 4. For example, we will talk about partial order first. Then partial order poset. After that, we will continue to talk about the upper and lower bounds. After talking about these, we will start defining lattice in part 2, 3, and 4. For lattice, we will talk about lattice, complete lattice, and product lattice. These three are what we will use today. Why do we talk about semi-lattice? Because it is also mentioned in many materials, including concentration. I will briefly explain it to you. After explaining it, the fifth part of understanding lattice, we know that dataflow is still a framework. How can we express it with lattice? After expressing it, we can use a monotonous non-moving point theorem on the lattice function to help us solve some fundamental problems mentioned earlier. As a non-moving point theorem, it can be used as a theoretical tool. But before using this theoretical tool, to prove some problems in our iterative algorithm, for example, how many non-moving points are there, which is the largest non-moving point, which is the smallest non-moving point, and so on. Before solving these problems, because the fixed point theorem is a non-moving point theorem defined on a lattice based on pure mathematics. If you really want to apply this property to the iterative algorithm, first of all, we need to convert the iterative algorithm analyzed by the data stream into a consistent condition for the non-moving point theorem. How to convert it? We will talk about it in the seventh part. After converting it, you can use some properties in the theorem to prove the dataflow and some important properties of the iterative algorithm. That is to say, to answer the fundamental questions we just mentioned. Okay. The first to the seventh part, the whole part above, is very complicated and complicated. The concept is abstract. Because most of them are mathematical concepts, I will have a lot of proofs. I can tell you now that when you listen to this class, I don't ask you to fully master all the proofs. Okay? Because sometimes, when you introduce a concept, it is the first time to introduce it to you, and you have to use the concept and the nature to prove something. It is very difficult for you to fully master it. But I have to tell you, it is a bit like when we talk about books, we first read it thickly and then read it thinly. Let's say I give you a theorem. I don't tell you how to prove it. You don't know much about it. When you use this theorem in your heart, you will be a little weak. You don't know what situation you can use it in. Is it right? After I tell you, although you can't fully master it, at least you can follow it as much as possible. Then you will know what it is like. I think at least you have to achieve such an effect in the process of proving the theorem. In this way, when you use this theorem in the future, you will be more flexible. Okay? So, because the content of this class is really confusing, even if I designed it carefully, I think most of you don't understand it. So, I want you to really master it. You can't come back every time and take the first grade, take the seventh grade. You have other classes. You have to do other things. People at work may have to work. It's hard for you to have so much time to master this part. So, for these students, if you don't have enough time, put all your energy into the eighth part of the next class. I will put the first to the seventh part of the content, all the core, the most important things in the eighth part to summarize in a visual way, the most intuitive way, to make it easier for you to understand to combine with you. So, in the future, even if you finish this class, you can't even remember the foundation, if you don't understand it, you can use the eighth part as a reference in the future. Okay? This will at least save you time. In the future, what did we talk about in the eighth part? In fact, we talked about how to put the lattice on the lattice and how to combine with the iterative in the eighth class and the next class, how to combine with the iterative algorithm, especially how to combine with mail analysis and mass analysis. Do you remember in the last class, we talked about how to initialize the mail analysis and how to initialize the iterative algorithm? We talked about how to initialize the mass analysis and how to initialize the iterative algorithm. Why? What's the difference between the biggest and the smallest point of the lattice and the accuracy of the analysis and what does it have to do with the summaries? We will summarize all of these in the eighth class. Okay? But, if you want to understand the eighth class, you must understand the first to the sixth parts of this class and the seventh to the eighth parts of this class. Okay? After talking about the eighth part, we will explain the data flow analysis from another perspective. We will explain the data flow analysis from another perspective. We will explain the data flow analysis from another perspective. We will explain the concept of meet-over-process, or MOP. We will talk about the gen, the queue, and the problem that we encountered earlier. These can represent the distributability of the lattice function. After talking about the MOP, we will compare the progress of the analysis. After talking about the MOP, we will talk about the gen, the queue, the definition, the variables, and the variable expression. These are all distributable. But, there are also non-distributable ones. In the tenth part, we will talk about a very common and important non-distributable constant propagation data flow analysis application. After talking about this part, we will talk about the worklist algorithm. In the first to tenth part, we will talk about the iterative algorithm. If you understand the iterative algorithm, it will be very easy to understand the worklist algorithm. In fact, the worklist algorithm is an optimization of the iterative algorithm. The worklist algorithm has some features that the iterative algorithm does not have. OK, this is what we need to learn about the foundations. I will try my best to finish the first to the sixth part in this class. OK, I will try my best to make it easier for you to understand in advance. If you can understand 40% to 50% in this part, it is already very good. OK, we have learned part 1 to 3 of the iterative algorithm. If you have learned it, it will be easier for you to understand. However, I suspect that if you have learned it, you will be able to remember and understand all of them. This is another matter. OK, let's start this class. First, let's talk about the first part. Let's talk about the first part. The first part First, let's review the iterative algorithm we talked about in the first part. The iterative algorithm of data flow analysis is actually a data flow analysis solution. Don't forget the result of the final analysis. For example, the main analysis versus the definition analysis. What is the result? All the out nodes have an out 0,0,0,1,1. That is the result. It is actually a data flow analysis solution. Right? OK, let's take a look at the above OK, let's take a look at the above. You should be familiar with this algorithm. I talked about it in great detail in the last two classes. It is already very slow. Let's take a look at the main forward analysis. Just imagine that this is a rich definition. OK, it is a main and forward analysis. Let's take a look at the method. The first part is the initialization. The initialization is empty. Right? Then, the value cycle starts iterating one iteration after another. Right? This is called the control flow. How do you deal with it during the merge? And what is this? It is the transfer function. Right? How do you get an out when it flows in? This is a GenQ problem. We talked about it before. The cycle goes on and on until any changes to out do not occur. That is, all nodes and all nodes do not change during the next cycle or iteration. The algorithm stops. This is the result of data flow analysis. Right? Let's review the algorithm. Next, we will understand the iterative algorithm from another perspective. Let's listen to the following content and follow my thoughts. Right? Let's say given a CFG, CFG stands for a program or a program control flow graph. Let's say there are k nodes in this graph. Right? Let's say there are statements in this graph, not basic blocks. What are k nodes? What does the iterative algorithm actually do? It actually updates the out information of each node during each iteration. Right? We use out n which stands for each node. Let's represent the out information of each update. This should be easy to understand. Let's assume the domain of the values in data flow analysis is v. What is the domain? Do you remember the definition in data flow analysis? The domain of the values in data flow analysis is v. The values in data flow analysis are not definitions. What is the domain? What is v? It is the definition in all programs. Right? The domain of variables in data flow analysis is the variable in all programs. You can think of it as a branch of analysis. After that, we can define a k-tuple. A tuple consists of k elements. Why k elements? Let's assume there are k nodes in CFG. So each node consists of each node's out value as a k-tuple element. Right? What is the value of this k-tuple? It is a... Because each out value is a... Right? The corresponding value is v. So what is the corresponding value of this k-tuple? It is a product of v. Right? A product. Let's use the k-quad of v to represent such a product. OK? Generally, this is how it is represented. It represents a predictor. It represents a statement. The k-quad of v represents such a value. OK. Let's say this value represents each specific value. Actually, it holds the value of analysis after each iteration. Let's say each iteration updates each node's out value. OK. Now you understand. This k-tuple stores each node's out value after each iteration. This is the temporary result. OK. Let's move on. Actually, each iteration can be considered as taking an action to map an element of vk. What is vk? It is the value of each iteration. Right? The new element of vk through applying the transfer function and control flow handling abstracted as a function Fvk.vk What does this mean? It means that each iteration represents an action. What is this action? It is a function defined as a large-scale function F. What does it do? It applies the transfer function to the two equations. For example, if E is a union or intersection composed of out, then all the previous and subsequent union or intersection and the transfer function is given to in, how to get out, and so on. In fact, the large-scale function F contains these two equations. How to handle the transfer function F? Each time F is handled as a function. F is the input and output of the function. Just like the input is the input and the output is the output of the function, the output is vk. vk is a k-tuple. The input is the output of all nodes. The output is the output of all nodes after the next iteration using F. Can you understand this? OK. Then, after the algorithm has the above expressions, it outputs a series of k-tuples iteratively until a k-tuple is the same as the last one in two consecutive iterations. This corresponds to the previous algorithm. We say this algorithm can be seen as outputting a k-tuple every iteration. When does it stop? Until the output of the k-tuple is the same as the output of the previous k-tuple. That is, this algorithm stops. OK. Let's look at this iterative algorithm from another perspective. This is a text expression. Text is just a notation. You don't hear it very clearly. You just know the general meaning. Next, we will use a specific image example to help you digest and understand. In the upper left corner, this is the general iterative algorithm for k-tuples. The green part indicates what you can do every time you iterate. We defined it as a large-scale function f. When does it stop? The yellow part says that if any out does not change, the algorithm stops. OK. Let's look at the image example of this algorithm. Given that each iteration updates every node out, what does the red part indicate? Every out is empty. It is empty compared to the bottom part. We will talk about the bottom part later. After the bottom part, the initialization is over. What do we do next? We look at the top part. The top part indicates the first out. The bottom part indicates the first node. The first out is the first node. The second node is the second node. The first node is the second node. The second node is the second node. The next node is the next node. What do we do until we discover that the out is exactly the same as the first node? We use vi to represent the first node. This is the last node. Let's look at the next node. We use a variable to represent the next node. We use a variable to represent the next node. So X0 represents the initialized configuration. X0 represents the initialized configuration. X1 represents the initialized configuration. X2 represents the out of the node. You can imagine that X0 represents the function f of iteration 1. X1 represents the out of the node. X2 represents the out of the node. X2 represents the out of the node. X3 represents the  operator of iteration 1. X4 represents the x e function of the last iteration. X5 represents the x i function of the last iteration. X is the fixed point of function f if x is fx. X is the fixed point of function fx. X is the fixed point of function fx. If you still don't understand, you can digest and absorb it. It will be better if you understand. Now, we have seen the framework described above. We can continue to discuss some interesting questions. As I said before, the iterative algorithm can also be called the in-out equation system. It is a system that constantly asks for in and out of nodes. It is a system that asks for in and out of main message and for forward and out. You can understand it this way. In the end, it produces a data flow message solution. Now, we have some interesting questions to ask. The first question is whether the algorithm can be guaranteed to stop. As I said before, the algorithm must reach the non-moving point.\n"
     ]
    }
   ],
   "source": [
    "audio_file_1 = open(\"./11-Audio-Summary/audio/lec05/lec05-0m-25m.m4a\", \"rb\")\n",
    "translation_1 = openai.Audio.translate(\"whisper-1\", audio_file_1)\n",
    "print(translation_1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cedc392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In other words, this algorithm will always provide a solution to the data flow analysis, right? Some students say, teacher, didn't you talk about it in the last two lectures? Recent definitions, available expressions, and new variables, they all stopped. But what I'm asking here is, as a general iterative algorithm, can it use this algorithm for all data flow analysis? Can all data flow analysis be guaranteed to stop? We only met three of them at the top of the iceberg. There may be hundreds of data flow analysis, which can be used for error detection, security optimization, etc. So can it stop? We don't know, right? So I'm going to ask, this is called a fundamental problem. It's a very basic problem, a very abstract basic problem. Okay, now that we have this question, we can continue to ask. Okay, let's say it can reach a non-moving point. Is there only one solution or only one feasible? Is there only one non-moving point? Some students asked before, is there only one non-moving point? We're going to ask, if there is only one non-moving point, can we use an iterative algorithm to solve it to generate the best solution? In other words, if there are many non-moving points, and we get this non-moving point, which is the non-moving point we got from the iteration algorithm, and finally stopped the non-moving point, what is its quality? Is it good in all the non-moving points? We will talk about this good in a later analysis. From the point of view of analysis, it depends on whether it is accurate. Is it the most accurate? Is it the most accurate of all non-moving points? Okay, we can ask this question. Today, we can also ask some general questions, fundamental questions. We can ask, okay, let's say it can stop. It has a non-moving point. Then I want to know when it can reach that non-moving point. Or when can we get a solution? Because the algorithm must have a boundary, right? There is a complexity. So in the worst case, how many steps can we take to reach this feasible? This can explain to us. In fact, you can see that this is a very abstract question. It doesn't mean that you can solve it by satisfying one or two dataflow analysis. Because it is an abstract question, we have to solve it in an abstract way. So before we answer these questions formally, we must first learn some math, abstract things, okay? Okay, let's first look at a partial order. I didn't drop the line, did I? Give me a feedback. Okay. Did I cut the line? No, okay. Okay. So... I suggest that some of you have learned Lissan math. I believe you all have learned Lissan math. But I think I have to be more detailed in this regard. Because do you think you understand Lissan math? If you don't understand it very well, you must listen carefully to this aspect. Because every detail in here will be used when we prove later. In other words, I won't tell you useless things here. All the mathematical knowledge will be used later. One mathematical knowledge is equivalent to another mathematical knowledge. In the end, we will all use it. So you have to listen carefully. I suggest that now everyone, whether you are using a cell phone or a computer, or a tablet, everyone takes out a piece of paper, a piece of paper, a piece of paper, a piece of paper, a piece of paper, a piece of paper, a piece of paper, a piece of paper, a piece of paper, a piece of paper, a piece of paper, a piece of paper, a piece of paper, a piece of paper, a piece of paper, a piece of paper and a piece of paper. How can a part of it be a part of robots? I personally don't care if it is a part of both the robot and the robot. But the robot, can't even stop its robot from dronking a previous round thing. When the robot can stop drinking a vehicle can that robot be able to control itself? It is because it is a vehicle, Okay, let's get started. There are a lot of comments. Are you lagging? I'll start. Partial order. What did we say? Partial order. Let's speed up a bit. We define a partial order. What is a partial order? It is called a partial order. A partial order is actually a model. It just has a partial relationship on it. We use p for the model. The partial relationship is this symbol. It represents a partial relationship. What is a partial relationship? Define a partial order over p. If it meets the following three characteristics, it forms a partial relationship. The entire pair forms a partial order. Let's see what kind of relationship it forms. The first one is called a self-reversal relationship. For each element in the model, if the symbol x is partial to x, from now on, if it meets a partial relationship, I can't just say that x is partial to x. There is a front-and-back relationship. Therefore, I use a small equal sign. But you have to remember that the small equal sign is actually the integer of the small equal sign. I just want to make it easier for you to see. So, I just want to make it easier for you to see. I just want to make it easier for you to see. I just want to make it easier for you to see. I just want to make it easier for you to see. As for what it is called, each application has a different partial relationship. For convenience, I say it is a small equal sign. I will use it in the future. I don't want to mislead you. This is for convenience. This is a self-reversal relationship. The second one is an antisymmetry relationship. For any two elements in this set, For any two elements in this set, if x is less than or equal to y, and y is less than or equal to x, then we will say x must be equal to y. If we satisfy these two relations, x must be equal to y. If you don't understand, we will use an example later. The third one is a bit easier. It is a transfer. For any three elements in this set, if x is less than or equal to y, and y is less than or equal to z, if we satisfy these three relations, if we satisfy these three relations, we will say it is an antisymmetry set. Let's look at the first example. Let's say we have a pair. Let's say we have a pair. There is an antisymmetry relationship. Is this a poset? Is this an antisymmetry set? What is s? The s in s is an integer set. The antisymmetry relationship means that x is less than or equal to z. Now, I will show you the first example. Let's try again. Is x a antisymmetry set? Let's try again. Is x a antisymmetry set? We will see whether it is a antisymmetry set. We will see whether it is an antisymmetry set. Let's see whether it is an antisymmetry set. Let's see if 1 is less than or equal to 1. Because the antisymmetry relationship was tried on all the biting describingees it. x is less than or equal to 1. x is less than or equal to 2. x is less than or equal to 3. x is less than or equal to... x is less than or equal to 2 is zero. x is less than or equal to 1 is zero. That is why we have antisymmetry. If it's written as antisymmetry, then we can see this is equal to 1. and this is less than or equal to 2. So, Antisymmetry is the same as antisymmetry. It must be equal to one element in X. It's very simple. 1 is less than or equal to 2. 2 is less than or equal to 3. 1 is less than or equal to 3. So, it's satisfied. It's a antisymmetry. It's simple, right? Let's look at the second example. It's the same as before. What's the change? It was less than or equal to. It's less than. The antisymmetry is less than. Is the pair still an antisymmetry? Is the pair still an antisymmetry? Let's be realistic. We only have 10 seconds. If I ask you a question, you have to wait 10 seconds. Today's lecture is a bit long. So, I'll just give you some simple examples. First, let's see if Antisymmetry is satisfied. 1 is less than or equal to 2. 1 is less than or equal to 1. 2 is less than or equal to 2. 1 can't be less than 1. Antisymmetry is not satisfied. So, it's not an antisymmetry. Now, let's look at the third example. Now, let's look at the third example. The pair S has a bunch of English words. The pair S has a bunch of English words. Let's assume these are the English words. What does antisymmetry mean? It's a substring relation. What does it mean? If the pair S has an antisymmetry, it means that S1 is a substring of S2. In fact, this arrow represents such an antisymmetry relation. Let me ask you a question. Does this mean that S1 is an antisymmetry? that S1 is an antisymmetry? that S1 is an antisymmetry? Let me show you. First, antisymmetry. First, antisymmetry. Does each string represent a substring of its own? Of course, it does. Next, antisymmetry. What does antisymmetry mean? If a string is a substring of another string, and vice versa, then these two strings must be the same. So, antisymmetry is also correct. So, antisymmetry is also correct. Third, antisymmetry. If a string is a substring of another string, and vice versa, does this mean that S1 is a substring of S2? Yes, it is. So, antisymmetry is also correct. This is a postset. Now, we have three examples. Now, we have three examples. Now, we are trying to understand the meaning of partial. In fact, why is partial called partial? Why is partial called partial? You can understand it like this. It means that any of the two elements cannot be compared. What does it mean? It means that any of the two elements cannot be compared. It is incomparable. It does not require any of the two elements to satisfy this partial relationship. For example, P and C. There are P and C, and there are C and D. But, any of the two elements cannot satisfy the partial relationship. This is a partial. You can understand it like this. Let's look at the last example. Let's look at the fourth example. I am asking you if my set is a power set of ABC. What is a power set? This is a mathematical concept. It is a set. ABC is a power set. ABC, AB, AC, all of them cannot satisfy the partial relationship. All of the elements can be a power set. Now, what is a partial relationship? It is a subset. It is a subset. It is a subset. It is a subset. It is a subset. It is a subset. Now, is it a partial relationship? Some people know it well. Let's take a look. In fact, we often think about this picture. Sometimes, when we draw a concept, there is an object. Do you remember our original definitions? Right? It is very similar to this picture. Every 0, 0, 0, 1, 1, every 1, 2, 3, are very similar to this picture. It is a partial relationship. Let's see if it is a subset. Is every set a power set? Yes, it is. Is it a partial relationship? It is a power set. It is a power set. It is a power set. It is a power set. It is a very typical power set. It is a very typical power set. Now, let's talk about A and B. Partial is incomparable. A and B do not satisfy a partial relationship. A and B do not satisfy a partial relationship. Incomparable is another example. Incomparable is another example. Before talking about lattice, we need to talk about the concept of upper bound and lower bound. the concept of upper bound and lower bound. This concept is relatively easy to understand. This concept is relatively easy to understand. But you need to remember some mathematical symbols. Sometimes, it is like this. You need to follow the rules. You need to follow the rules. When you follow the rules, you will get a intuitive explanation. you will get a intuitive explanation. What is the combination of upper bound and lower bound? We have talked about partial, so we define it as partial. There is a partial set P. What is the partial set? It is the subset of s, the positional value of s. note that  note that when I write the partial set P, it shows a partial set P. it shows a partial set P. If this picture does not show P, it represents a partial set. In plot, it represents a partial set joining a total of P. To be more specific, it has a subset s. What do we define? For all the elements in P, it is an upper bound of s. it is an upper bound of s. What is the condition? All the elements in s are less than or equal to u in P. It is easy to understand. If u is an upper bound of s, it means that all the elements in s are less than or equal to u. This is the partial set. The upper bound is the corresponding lower bound. Similarly, the element l in P is a lower bound of s. It means that all the elements in P are greater than the lower bound. are greater than the lower bound. Let's look at an example. Let's look at an example. There is a partial set P. There is a partial set P. What is its subset? It is s. The partial set P is the density. The arrow represents the subset. the subset. Let's say the partial set P is like this. Let's say the element s is an upper bound of s. What is its upper bound? What is its upper bound? What is its lower bound? It is s. What is its lower bound? It is s. It is s. It is greater than or equal to s. It is greater than or equal to s. It is greater than or equal to s. Let's look at two very important concepts. They are ListUpBound and GreatestLowerBound. They are the smallest upper bound and the largest lower bound. They are the smallest upper bound and the largest lower bound. Lattice will be defined by the smallest upper bound and the largest lower bound. You need to remember some of the names. We define the ListUpBound. It is also called LUB. It is the abbreviation of the first three letters of the ListUpperBound. It is LUB. The first letter abbreviation. We may use LUB in the future. We may use another acronym. It is called John. John means meet. What is ListUpBound? We use this acronym. Remember that the combined upper bound is ListUpperBound. It is the smallest upper bound. If for every upper bound of s, say u, if it is the smallest upper bound, it must be less than all upper bounds. Similarly, we can define the GreatestLowerBound. Remember that it is GLB. GreatestGlowerL BGLB It is also called meet. The largest lower bound of a combined upper bound is this acronym. If for every lower bound of s, say L, if the lower bound is less than the largest lower bound, it is the largest, it is less than the lowest bound. We call it the GreatestLowerBound. We call it the GreatestLowerBound. Let's change to another example. The combined s is this. Let's think about the lower bound, the upper bound, the GreatestLowerBound, and the ListUpperBound. Let's think about it. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "audio_file_2 = open(\"./11-Audio-Summary/audio/lec05/lec05-25m-50m.m4a\", \"rb\")\n",
    "translation_2 = openai.Audio.translate(\"whisper-1\", audio_file_2)\n",
    "print(translation_2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e7c4bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next, let's look at the remaining three examples one by one to see if it is a lattice. The first example is that the total number is small and equal. Is it a lattice? Answer? Is it a lattice? If you ask for the largest number, 1 and 2, the largest number is 2, then 2 must be the smallest upper limit. If you ask for min, 1 and 2, then 1 must be the smallest lower limit of 1 and 2. So there is a minimum upper limit and a maximum lower limit. There is a min, a joint, and a min. Let's look at the second example. We said that it is also a lattice, right? Let me ask you, is this lattice, the substring, a lattice? Answer? Very good. The third example, we ask you, is it a lattice, are you sure? It is a post-site, a very common one. Is it? The middle one is a sub-site. Is it a lattice? Very good. We are talking about the join and meet. What is join? Join is actually a unit. After you join, you get a joint of A and B. If the join of A and B is AB, then AB must be the top of A and B. The top of A and B must not be ABC. How can the join of A and B be C? What is the meet of A and B? It is the biggest sub-site. What is the meet of AB and AC? It is A. It is not a join. A join is also a sub-site. But it is the biggest sub-site. For this example, if you can't remember it clearly, you can go back and watch the movie. Then you can follow the sequence. This is the easiest and easiest way to remember. You can follow the sequence. Let me give you an example. It is a lattice. Let's define a sub-lattice. In many materials, it is called a sub-lattice. What is a partition? When you know the partition, you will know the partition very clearly. What does it mean? It means that there is a smallest upper level and a largest lower level. A partition means that there is only one existence. If there is only a smallest upper level, a join, then it is a join semi-lattice. If there is a largest lower level, then it is a meet semi-lattice. This is a meet semi-lattice. This is the only semi-lattice that can be defined. The next one is a complete lattice. We will use this a lot later. This is very important. First of all, a complete lattice is stricter than a lattice. It is a lattice, but for arbitrary subsets S of P. What does it mean? It means that for any sub-lattice in the partition, if any sub-lattice has, as we said before, if the smallest upper level and the largest lower level of this sub-lattice exist, because it is not a lattice where there are only two pairs, it is a sub-lattice where there are more than two elements. If the smallest upper level and the largest lower level of this sub-lattice exist, then this lattice is called a complete lattice. There is no other way. This is the definition. This is the concept of mathematical definition. This is the nature of our concept. This is the basic abstract concept used in everyday life. If you are satisfied with this concept, then this concept and nature will be established. There is no other way. The abstract concept is like this. Let's use a word to explain what a complete lattice is. All sub-sets of a lattice have a smallest upper level and a largest lower level. What is the difference between a complete lattice and a lattice? The smallest upper level and the largest lower level. A complete lattice is a sub-set of any sub-set. Any sub-set will have a join and a meet. Let's continue. We have two sub-lattices here. One of the three sub-lattices is not a lattice. There are two left. Is this lattice a complete lattice? Let's think about what a complete lattice is. All sub-sets must have a smallest upper level and a largest lower level. Let's see if it is. This is a bit confusing. Let me explain. For example, let's take a sub-set. This sub-set contains all positive integers. If the positive integer does not include 0 or 1, then it has the largest lower level. But does it have the smallest upper level? No. Why? Because it is infinite. There is no boundary. Unless you define a boundary value. If you use positive infinity, then it is infinite. There is no boundary. Unless you define a boundary value. This is a bit complicated. I hope you can understand. Let's look at the first sub-set. There is only one lattice left. Let's look at this lattice. Is it a complete lattice? Please answer. Yes, it is. All sub-sets will have a smallest upper level and a largest lower level. Let me give you a hint. As mentioned, the definition of bounds implies that the bounds are not necessary in the sub-set. For example, if the sub-set is AB, it does not necessarily include the lower level. It does not mean that all outside lattices must be in the sub-set. For example, if the sub-set is AB, it does not necessarily include the lower level. Now, let's talk about complete lattice. As mentioned earlier, there are two elements in a complete lattice. As long as there is a complete lattice, there must be two elements. What are these two elements? The largest element is called top. What is the largest element? It is the whole P, not any sub-set. P is the sub-set itself. What is the combination of P and the complete lattice? The largest element is the smallest upper level. That is the largest element of the complete lattice. The smallest element is called bottom. In this case, the red ABC is the top. Let's review the definition of every finite lattice. Let's start from the bottom. The bottom is this symbol. We have mentioned mass lattice before. We will talk about top and bottom later. These are two important concepts. Now, let's talk about every finite lattice. Every finite lattice is a complete lattice. In other words, as long as every finite lattice is a complete lattice, every finite lattice is a finite lattice. Let me ask you a simple question. If a finite lattice is a complete lattice, is a complete lattice a finite lattice? Answer me. Yes. Not necessarily. For example, you can hear it. Between 0 and 1, there is a bound. It is a complete lattice. Let's say all real numbers are less than or equal to 0. 0 and 1 have a bound. It is a complete lattice. But every subset also has a bound. Although real numbers are infinite, subsets also have a bound. But a real lattice is a finite lattice. Real numbers can be infinite, but it is not a finite lattice. We can use it later. I will not talk about things that are not useful to you. We have talked about so many mathematical concepts. What are we really concerned about? In fact, most of the dataflow lattices are complete and finite lattices. Why are they finite? In general, all dataflow lattices are finite. You can draw a line and draw a line. So most of the dataflow lattices are complete lattices. Of course, there are also infinite lattices. But in general, a complete lattice is fine. Let's talk about a concept called product lattice. We will use it later. For example, the K-tuple for each K-tuple, it is easier for you to understand. What is a product lattice? There are several lattices. There are n lattices. Each lattice has an expression. There are n lattices, from L1 to L2 to Ln. For each lattice, if it has a minimum upper limit and a maximum lower limit, we can get a product lattice. What is a K-tuple? It is a dense expression. The upper limit represents the product of n lattices. What is the domain? It is a conjugate. It is the domain of each lattice. It is a conjugate. A lattice is also a conjugate. It has a conjugate relationship. What is the conjugate relationship? For example, X1i to Xn is a product of one element. It is a K-tuple. Here is a n-tuple. Two elements are contiguous. These two elements are conjugate related. Every lattice has two elements, which is also conguage related. After they have been established, which is a conjugate relationship, the produced product lattice will satisfy two elements. If we say conjugate and conjugation what else? We said there must be the upper bound and the lower bound. What are the upper bound? The upper bound of two elements of the produced product lattice is actually the upper bound of the two elements of each lattice. The corresponding lowest bound of each product lattice is the lowest bound of the two elements of each lattice. OK Then it has two properties. Please remember. A product lattice is actually a lattice. We have proved it. It must be a lattice. It has the lowest bound and the lowest bound of the two elements. A product lattice L is a product of complete lattices. Then L is also complete. It is easier to understand. Please remember. If each lattice of the two elements of each lattice is complete, then the product lattice is also complete. OK Now we can express the dataflow lattice with a lattice. As I said, we want to express the dataflow lattice framework with a lattice. I have been talking for an hour. There is a lot of content today. Let's take a break for two minutes. Let's go to the bathroom. Let's go to the bathroom. One minute left. I am hungry. 10 seconds left. 10 seconds left. OK Let's move on. OK Let's talk about dataflow lattice. Let's recall what we talked about in the last two lessons. It is not for nothing. It is just a specific example. Now we want to use a general expression to express the dataflow lattice framework. How do we express it? Let's use three elements. The first element is D. The second element is L. The third element is F. What does D mean? It is the direction of the dataflow lattice. Let's recall what we said before. The origin definition is a forward lattice. The leave variables is a backwards lattice. A backwards lattice. The second one is L. Let's use lattice to express the framework. The L in lattice is the pigeonhole to which is a collection of dominant values. Let's use V to represent the dominant values. Let's use V to represent all the definitions in the program. What else? A lattice must have the smallest upper level and the largest lower level. It must have a drum and a mid. Let's use data flow analysis as a reference. Lattice must have the smallest upper level and the largest lower level. However, when we use the real data flow analysis, we either use the mid or the drum. Let's imagine the intersection. When we talk about mass analysis and available expression, we use the control flow and the intersection. However, we use the drum and the unit to define the drum. Why do we use a lattice instead of a semi-lattice? It is because in the second half of the lecture, when we talk about the theory, we will find that using a lattice instead of a semi-lattice is more intuitive and easier to understand. Let's talk about F's transfer function. F's transfer function is because each node has its own transfer function. Normally, each node has its own transfer function. However, each node has its own transfer function. A function has input and output. Let's say F is int to int. The input is int, and the output is 1. What is V? It is the domain value. The output is 0.0.0.0. 0.0.0.0.1. It is the domain value. These three elements make up the basic framework of the General Framework. Let's take a specific example. On the left, let's take a simple example. Let's take a look at the data flow analysis. On the right, let's talk about how to build a relationship between S1 and S2. Let's assume that S1 and S3's outputs are A, B, C. If A is 0.0.0.0, then S1 is 1. S2 is 1.0.1. S3 is 1.1.0. S4 is 1.0.0. S5 is 0.1.0. This is 0.0.0. Let's compare the two. Let's talk about control flow merge. We are talking about the definition of the function. The two functions are a and b. A and b are the in-units of S2. S2 is A and B. A and B are on the lattice. The two are moving up. See? Let's talk about S2. S2 has a central function f. Let's change it. The central function is q. Let's assume that the function is A, B, C. Let me give you an example. Let's assume that the function is going up from the bottom. It starts from the bottom. The bottom is empty. See? It moves up little by little. Let me give you an example. The main line is going up from the bottom. Alright? Now we can use a sentence to express the dataflow analysis. Dataflow analysis can be seen as iteratively applying transfer function and meet or join operations. Let me give you some motivation. I asked some general questions. Alright. We already have some simple math knowledge. Next, let's take a look at and try to answer the first two questions. Alright? The first question. The first question. Can the general iterative algorithm stop? Or can it reach the non-moving point? In fact, in the third class, when I was talking about rich definitions, I talked very slowly. Do you remember what I said? Can the general iterative algorithm stop? I said that all nodes' out never shrinks. Do you remember? In other words, 0 only becomes 1, but 1 does not become 0. Because of this, I explained that it will stop eventually. Now, we want to use any dataflow analysis in a more general way. Can it reach the non-moving point? In fact, out never shrinks is a monotonous question about the lattice function. In other words, to answer this question, the dataflow analysis can be expressed on the lattice. Let's see what is the monotony of the lattice function. The answer is monotony. Let's see the second question. The second question is that the algorithm has only one non-moving point. How many non-moving points does it have? In the first class, we introduced the concept of non-moving point. x is equal to fx. Right? f is equal to fx. What is f is equal to fx? It is the non-moving point of a function. Let me put it this way. How many non-moving points does a function have? Think about it. Answer me. Think about it. The non-moving point is very simple. x is equal to fx. x is the non-moving point of f. Right? How many non-moving points does it have? In the last class, we introduced the concept of non-moving point. How many non-moving points does it have? It is very straightforward. We can draw a graph. This function is red. It is monotonous. Can this function have non-moving points? The red circle is the non-moving point. s is equal to fx. fx is equal to s. How many non-moving points does it have? We already know how many non-moving points it has. But the question is how many non-moving points does it have? Is it the best of all the non-moving points? From the analysis point of view, we will discuss later whether it is the most accurate. We will answer this question later. To answer this question, we will talk about the monotonicity of the function on the lattice and the non-moving point definition. This is very important. The thing we are going to discuss is the mathematical thing. The monotonicity of the function on the lattice and the non-moving point definition on the lattice.\n"
     ]
    }
   ],
   "source": [
    "audio_file_3 = open(\"./11-Audio-Summary/audio/lec05/lec05-50m-75m.m4a\", \"rb\")\n",
    "translation_3 = openai.Audio.translate(\"whisper-1\", audio_file_3)\n",
    "print(translation_3['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbe08777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After talking about these mathematical things, let's move on to the iterative algorithm. We said that the iterative algorithm has to solve the problem of the function on the lattice. After connecting them, we can use the non-linear theory on the lattice function to explain the two general problems of the iterative algorithm. So what is the non-linear theory on the lattice? First, let's look at the monotonicity of the function on the lattice. What is the monotonicity of a function? What is this function? f. This is a general expression. This is a basic expression rule, especially in PR. What is a function? It is a function from U to U. What is the input? What is the output? f is the function. What is the output? What is the U? It is a function on the lattice. If the lattice is an int, then it is from int to int. It is a lattice. The whole expression is a lattice. If the function on the lattice is f, then it is monotonic. It is the two elements on any lattice, x and y. If x is less than or equal to y, then it is a partial relation. If f is less than or equal to x, then it is less than or equal to y. This is monotonicity. It is quite straightforward to understand. Remember that it is a function on the lattice. With this monotonicity, we can look at a very important non-moving point theorem. What is a non-moving point theorem? First, give a complete lattice. Because we are dealing with data flows, it is basically a complete lattice. If the function on this lattice and the function on this lattice meet the following two conditions, then we can come up with some non-moving point theorems. What are these two conditions? First, the function on this lattice, f, is monotonic. It was just defined before. Let's see what is monotonic. x is less than or equal to y, and f is less than or equal to x. Second, l is finite. This lattice must also be finite. It is finite. We just talked about this. A finite lattice must be a complete lattice. But a complete lattice does not necessarily have to be a finite lattice. This is why we need to add a condition here. I didn't talk about it in vain. We need to add a condition. This is why we need to add a condition here. What conclusion can we draw from this? Let's take a look at the function on this lattice. I will talk a little slower here. We can get the smallest non-moving point of the function, f. What rule do we follow? First, we get a value for the button as an input. Then, we use this value as an input for the next f. f, f. It is like a loop. We keep applying this function f. Until what? Until we reach k. When k is a variable, until a fixed point is reached. Do you remember the example I gave you at the beginning? It is also expressed in a similar way. It is like a loop from bottom to top. Let's say you are looping from bottom to top. What is the function you are looping? It is monotonic. At the same time, your lattice is also finite. You must reach the non-moving point. At the moment you reach the non-moving point, what is the smallest non-moving point? I will talk about the smallest non-moving point later. Now, I just want you to remember the principle. We will match you later. We will connect. Now, we will apply the largest non-moving point. What is the largest non-moving point? It is the same rule, but we start from the top of the lattice. Then, we apply f little by little. At this time, you will say that when you reach the non-moving point, you will definitely reach the largest non-moving point. Now, we want to prove why Fitts' Pond satisfies these two conditions. We can get the smallest non-moving point by looping like this. We can get the largest non-moving point by looping like this. Now, some of you may already have a feeling. Although I haven't connected it to the iterative algorithm yet, but you already have a feeling. In fact, we are also iterative. Now, let's start. We will prove how to get the least Fitts' Pond. Why do we get the least non-moving point? In fact, this definition has two meanings. The first meaning is that this non-moving point exists. It exists. The second meaning is that it exists, and we get the smallest non-moving point. Basically, we asked two questions earlier. In fact, they are all related. We said that the non-moving point exists. We said that the non-moving point is the best non-moving point. If there is one more non-moving point, it is the best non-moving point. We will talk about what is the best non-moving point later. But if we want to prove that it is the least non-moving point, we say that it is the least Fitts' Pond. Why do we need to prove it? Next, we need to prove that it doesn't matter if you don't fully understand it. As long as you can follow me. Try to follow me step by step. This is equivalent to the mathematical knowledge we used earlier. We used it flexibly. We brought it in. I believe that after you follow me this time, when you use the non-moving point principle again to connect something, to connect our data flow analysis information, it will be very easy. But if you don't follow this trick, if you don't try to follow it, you will be weak when you use it in the future. It won't be so easy. Let's prove it. First, let's prove what? Let's say that this Fitts' Pond exists. It exists. Now, everyone, everyone of you, give me some feedback. I have proved it now. Give me some feedback. What are the conditionalities of the non-moving point principle? You can't just listen to whatever I say. You can't just feel that it makes sense. You have to think about it. I told you about the non-moving point principle. You have to write it down on your notebook. This actually helps you to practice your ability to prove. In the future, your ability to study, your ability to prove is very important. You have to practice if you have a chance. Because I see that we have no time to talk about the rest of the content. So we can be a little slower now. Okay? Everyone, think about it. I'll give you 30 seconds. Think about it, okay? After thinking about the conditionalities, what do you think our conclusion is? According to the conditionalities, like solving the application of the college entrance exam, what is the conditionality and what is the conclusion? It's actually very simple. Just follow the conditionalities step by step. Use all your mathematical knowledge to help you. Okay. Okay. Let me see. You should have thought about it. Because you can't see the textbook. I've already sent the textbook to you. Mr. Tang has already sent it to you. First of all, complete lattice. Then what about lattice? The function defined by lattice must be monotonous. Then, this lattice is finite. Then what do we want to prove? We want to prove that first of all, you have to be able to hit something. Then what do we have to prove? We have to prove that the maximum number of non-moving points is the same as the minimum number of non-moving points. Okay. Let's start. The definition of this bottom. Do you remember what bottom is? We said that every completed lattice must have a top and bottom. The definition of bottom. What are the functions? Lattice to lattice function. The value obtained from bottom is also the value obtained from lattice, right? The output value obtained from F-bottom is also the value obtained from lattice. As long as the value obtained from lattice is based on the definition of bottom, we say that we are the smallest element in lattice. Then I must be less than or equal to the value obtained from F-bottom. Because I am the smallest element. So it is based on the definition of F-bottom. Okay. The second step. We said that the function is monotonous. What does monotonous mean? Monotonous means if I define F-bottom as the input of this function, it corresponds to this function, then I define F-bottom as the input of this function. F-bottom is a function of F. Then it corresponds to this function. Do you see it? Okay. Because the left side is x, the right side is y. If x is less than or equal to y, then Fx is less than or equal to Fy. This is a monotonous definition. The two above are monotonous. We use F2 to represent this. Because we use F twice. We use F2 to represent. Then we get F-bottom is less than or equal to F2-bottom. This is a monotonous definition. It is a monotonous relationship in lattice. Okay. Then we can keep using F. Because F is monotonous, we can get this conclusion. F-bottom is less than or equal to F2-bottom. F-bottom is less than or equal to F2-bottom. F-bottom is less than or equal to Fy-bottom. It doesn't matter how many times it is denoted. At the same time, F-bottom is less than or equal to F-bottom. Okay. What do we do next? There is a key condition we use. We say L is finite. What does finite mean? For some k, there must be a k value. When it comes to k, why does it stop? Like what we said before, 0, 0, 0, 0, 0, becomes 1, 1, 1, 1, 1. Like what we said in the interview. Because there is a boundary, there must be 1, 1, 1, 1, 1. You will definitely go to the end. Because there is a finite boundary. So when it comes to k, it will stop. When k and k plus 1 are the same value, we reach the fixed point. We use this symbol to represent F-fixed. We will use it in the next lecture. We will use it in the next lecture. Because it is finite, we have a mathematical term. I don't write it here. I don't want to confuse you. It is ascending chain. It is not infinite. It is finite. It is ascending chain. It is finite. The lattice itself is finite. The ascending chain is finite. The descending chain is also finite. The descending chain is also finite. It limits two dimensions. It is easier to understand. We don't use other mathematical concepts. Let's just say R is finite. Fixed points exist. What do we do next? You get a list of fixed points by iterating from the bottom. You get a list of fixed points by iterating from the bottom. Why? It is still very straightforward. When you say the smallest and unique fixed point, we have said that already. We have a number of fixed points. You say it is the smallest. Let's assume we have another fixed point. The other fixed point is x. We define it by fixed points. The fixed point of a function is x equals f of x. Then we call x the fixed point of f. This is defined by fixed points. Let's come back to the definition of x. Let's come back to the definition of x. Of course, x is also an element on the lattice. The bottom is the smallest element on the lattice. The bottom exists in the complete lattice. Therefore, we are satisfied with this deviation. This is not a problem. Next, we will use a commonly used mathematical method to prove it. It is the mathematical induction. It is the mathematical induction. What do we want to do with the mathematical induction? We will see the conclusion later. Let's talk about the mathematical induction first. Let's go through the steps. Let's go through the steps. Let's recall the mathematical induction. What do I get first? I get the initial condition. For example, x is equal to 0 and x is equal to 1. Then, I assume the condition is true. Then, I get the initial condition. Then, I get the initial condition. Is this the mathematical induction? Is it lagging? Induction. What is the initial condition? The initial condition is this. What is f? It is monotonous. So, what do we get? x is equal to y. Then, fx is equal to fy. It is monotonous. It is easy to understand. This is the initial condition. What is ds? Let's assume that ds is equal to x. Let's assume that ds is equal to x. It is easy to understand. Because f is monotonous. Think about it. monotonous is equal to x, monotonous is equal to y. If you add another f, it becomes fy plus 1. If you add another f, it becomes fy plus 1x. If ds is equal to x, it becomes fy plus 1x. So, we can conclude that fy is equal to fx. So, we can conclude that fy is equal to fx. What do we want to conclude? In fact, in the case of monotonous points, x is equal to fx. So, in the case of monotonous points, x is equal to x. So, what do we have? Let's assume that the case is over. Let's assume that we move up a little bit from the bottom. I am also a monotonous point. Let's assume that x is also a monotonous point. But, according to this, my monotony must be smaller than yours. Although we are all monotonous points. So, this is why we move up a little bit from the bottom and apply f. This is the smallest monotony. In fact, there is another conclusion that I haven't said. But we have used it before. I can ask you directly. Is the smallest monotony the only monotony? Is it the only monotony? Answer me. Is it unique? Did I lose connection? No, right? Is it the only monotony? Think about it. We mentioned the case of the smallest monotony and the biggest monotony in the previous lecture. The proof is the same. The proof is the same. The proof is the same. The proof is the same. Is it familiar to you? We know how it was established. We know how it was established. Remember this monotony. Right? Let's review the two questions before. We want to know if the algorithm can reach the monotony. If there is a monotony. If there is more than one monotony, we want to know the quality of the monotony. We want to know if it is greatest or least fixed point. If it is best, we want to know if it is greatest or least. We will talk about it later. What did we see just now? It was purely a mathematical proof. It was purely a mathematical proof. The fixed point theorem was defined on a lattice and its monotony. The lattice is finite. We said that this f is fixed. There must be a monotony. And this monotony must be the smallest monotony. It was purely a mathematical proof. We want to know if the iterative algorithm can reach the monotony. We want to know if the iterative algorithm can reach the monotony. At the same time, if the iterative algorithm can reach the monotony, the dataflow lattice algorithm is the greatest or least fixed point. What we saw just now was a monotony on a lattice. We cannot say that our iterative algorithm also has that property. Unless we can relate the algorithm to the fixed point theorem, if possible. What are we thinking now? We want to know if the iterative algorithm can reach the monotony. We want to know if the iterative algorithm can reach the monotony. The premise is that we have to relate the iterative algorithm to the fixed point theorem. After that, we have the monotony. How do we relate the iterative algorithm? Actually, I can tell you that we can relate it. Because we can reach the monotony. Later, we will talk about what the function means. What is our function? What is the function of the iterative dataflow lattice? What is the function of the iterative algorithm? Once we relate it, we can use the fixed point theorem to explain the two questions. This is the best way to explain such a complicated thing. I have tried my best. I think this is the easiest way for you to understand. Let's move on to the next class. In the next class, we will talk about how to relate the iterative algorithm to the fixed point theorem. In the next class, we will talk about the core concepts. We will summarize the core concepts. You can take away the core concepts and use them later. For example, you want to use the 8th class to design the chart. You can use it as a tool to search. You need to understand the first part of the algorithm. You need to understand the algorithm from the side. It is easier to understand the fixed point theorem. I will give you specific examples to train you and give you an intuitive impression. If you understand what I just said, it means that you have reached my design goal. Let's move on to the next class. This class is a bit fast. Some students asked me to speak faster. I want to tell you in advance. If you don't understand later, it doesn't matter. I want to tell you that Mr. Tan Tian and I have re-examined our course settings. We will talk about IFDS and soundness. However, we can't avoid fingerprint analysis. So, I want Mr. Tan Tian to talk about fingerprint analysis first. Then I will talk about soundness. I want to compare IFDS and fingerprint analysis. As far as I know, there is no material to talk about this. You need to know fingerprint analysis in advance. As for soundness, we also need to talk about some examples. After Mr. Tan Tian's fingerprint analysis, I can talk about IFDS and soundness. I also want to talk about inter-procedural analysis. I found that inter-procedural analysis is related to contact sensitivity. So, I want Mr. Tan Tian to talk about this. I will talk about this after Mr. Tan Tian's lecture. In short, the next lecture will be the last lecture during the pandemic. I will finish the rest of the lecture. After the next lecture, Mr. Tan Tian, who is very young and cute, will talk about inter-procedural analysis and fingerprint analysis. As for Mr. Tan Tian, this is also his first lecture. Unlike me, when I was abroad, I was a tutor. I didn't have a formal lecture, but I was a tutor. I had the same experience as foreigners. However, Mr. Tan Tian has little experience in this area. I hope you can give him enough support. Alright. Mr. Tan Tian is also a tutor now. That's all I want to talk about. See you next time. Sigh... Finally finished. I have been reciting this lecture until 3 a.m. It's almost 3 a.m. Sigh... It's hard to sell a lesson. What I want to say is...\n"
     ]
    }
   ],
   "source": [
    "audio_file_4 = open(\"./11-Audio-Summary/audio/lec05/lec05-75m-100m.m4a\", \"rb\")\n",
    "translation_4 = openai.Audio.translate(\"whisper-1\", audio_file_4)\n",
    "print(translation_4['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a2769de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have you guys looked up the lyrics? I said Zhang Xuyong, Man Man, and what's the other one called? Man Man, Man Man, I forgot. Have you guys looked up the other two lyrics? What is it? Who are you to make me... I forgot. Who are you to make me haggard? You don't give me a little bit of comfort, right? I said I don't want to be late for class. You guys only have a few classmates to comfort me. I'm just kidding, I'm just kidding. About my homework, it's like this. Because my first homework is about concept propagation. You guys can see it here, right? This, this, this. We will talk about the concept propagation workload. After I finish talking about it, I will leave my homework. I will leave my homework after class. Mr. Tang is in his own dorm. We don't live together. Do you guys understand? Actually, this is a bit hard to understand. I feel like this is the best way I can come up with. It's easy for you guys to understand. Who is that background? Who can tell me who he is? He has so many words. His reaction is pretty fast. Every time he answers, it means he has good technical knowledge. Can I reverse the complete lattice? Why do I have to reverse it? His bottom and top are all defined, right? Can I reverse the complete lattice? Why do I have to reverse it? His bottom and top are all defined, right? Interesting? His reaction is so fast. But it's not intuitive. You can't really say it's one and the same thing. Actually, when you reverse it, subtop is defined using the same logic. based on Wong's book. But whenever it reaches the largest, smallest, and petite has a analytical conclude, you will find it strange. So I don't really recommend this. It can't be one and the same thing. One has the largest difference, while the other has the smallest difference. It's not the same. But it's good that you can think of it this way. The wind rises from the ground. It's good that you can think of it this way. But it's not the same thing. Are there any questions? I'm going to eat. I'm going to cook. I'm going to make dumplings every day. I'm going to make steamed buns. I'm going to make people fat, and make them hungry. If there are no questions, I'm leaving. Okay. Bye bye. Bye bye, everyone. I'm hanging up. Bye bye.\n"
     ]
    }
   ],
   "source": [
    "audio_file_5 = open(\"./11-Audio-Summary/audio/lec05/lec05-100m-end.m4a\", \"rb\")\n",
    "translation_5 = openai.Audio.translate(\"whisper-1\", audio_file_5)\n",
    "print(translation_5['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55093324",
   "metadata": {},
   "source": [
    "## Lec06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "494d0a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will tell you about the experiment, homework, and the next course arrangement at the end of this class. Now let's start the 6th class of software analysis. It is also the last class of data flow analysis. It is also the 4th class of data flow analysis. It is also the 2nd class of data flow analysis foundations. We will talk about the last class in this class. If you are not familiar with the last class, I hope you can watch the video of the last class first, especially the second half, and then listen to the content of this class with the knowledge of the second half. Let's review briefly. What did we talk about at the end of the last class? This is a slide we left at the end of the last class. We talked about the reviewed question we have seen before. Do you remember that at the beginning of the last class, we only presented the iterative algorithm in another way. That is to say, we imagined the basic algorithm of the data flow analysis iterative algorithm. We have a k-tuple, and there are k nodes in the cfg. This k-tuple is equivalent to updating the out of each node for each iteration. Then we keep iterating this out, until all the out of the k-tuple are exactly the same, which is the so-called fixed out. At this time, the algorithm stops. After introducing this form of iterative algorithm, we raised three very general questions. Then we introduced a lot of mathematical knowledge concepts, such as deviation, up-down, complete lattice, product lattice. Then we defined functions on the lattice. What we talked about in the last class is the function we defined on the lattice, and then we presented the fixed point theorem. In fact, the last class is to answer these three questions. Especially the first two questions, we haven't answered yet. The first question is, can our iterative algorithm stop? That is to say, can it reach the fixed point? Is there only one solution? The second question is, if there are multiple fixed points and multiple solutions, can our iterative algorithm reach the fixed point? In the last class, we talked about this. Now, what we have just seen is the property. That is to say, the fixed point theorem is filled with functions on a lattice. We cannot say our iterative algorithm also has that property, unless we can relate the algorithm to the fixed point theorem, if possible. What do I mean by that? I will talk about this in the last class. Now, let's focus on the class. We have just seen the fixed point theorem. I will review it for you later. This fixed point theorem is a property of a function on a lattice. Let's say a function is monotonous, and the lattice is finite, and it is a complete lattice. If you apply this function from the bottom, if it can reach the fixed point, it will be the smallest fixed point. If it starts from the bottom, it will be the smallest fixed point. If it starts from the top, it will be the largest fixed point. This property cannot be directly applied to our iterative algorithm. When can we use it? Unless we can relate the algorithm to the fixed point theorem. If we can relate it, which means if our algorithm meets the fixed point theorem, then of course the result will be applicable to our iterative algorithm. I will give you the conclusion in advance. Of course, our algorithm can reach the fixed point. What is the fixed point? It is the smallest or largest fixed point. Now, let's see how we can relate the algorithm to the fixed point theorem. What is the next part? It is also an intuitive way to prove. It is not very strict, but it is still a whole process of proof. As I said in the previous lecture, I don't require you to fully understand the theorem, but you can understand as much as you can understand. If you understand a little more, I think you will have a clearer understanding of the theory behind it. It is definitely good for you, although you don't have to fully understand it. Next, let's talk about a simple intuitive proof. Let's see how we can relate the iterative algorithm to the fixed point theorem. Let's review the iterative algorithm. As I said before, it is a K-tuple, a K node, right? Our iterative algorithm applies a function every time it deviates. What is this function? It changes all the nodes' outs. Then it applies the function once, until it reaches the fixed point, which is ds and ds plus 1. The result is the same, all are vi. This is the iterative algorithm. Let's look at the fixed point theorem. Given a complete lattice, and satisfy two conditions on the lattice. The first condition is that the lattice is finite. The second condition is that the function defined on the lattice is monotonic. If this is the case, both conditions are met. So if we start from the bottom, and apply the function a little bit upwards, we will reach the monotonic point. And this monotonic point is the smallest monotonic point. If we start from the top, and apply the function a little bit, we will reach the monotonic point. And this monotonic point is the largest monotonic point. How do we relate them? You can think about it. You can think about how the iterative algorithm relates to the fixed point theorem. Let's look at the second condition. First, the iterative algorithm has to have a lattice. Only if the iterative algorithm has a lattice, and the lattice is finite, can we relate this condition to the fixed point theorem. We talked about this last time. The iterative algorithm has a few slides. We will talk about how to express data flow analysis through a lattice. You can recall that the meaning of iterative algorithm is a lattice. We can express data flow analysis in terms of data values. In this graph, each node has an output. The output represents the data flow value. As I said before, each node has a value. For example, each node has a definition. Let's think of it as a lattice. The bottom is empty. Let's say there are three definitions. The first, second, and third. The lattice is empty. The first, second, the first, third, the second, third, and the top is the first, second, and third. This is a lattice. Each node has a lattice. The k-tab is the entire control flow graph. What is the meaning of k-tab? We talked about it last time. It is a product of a lattice. Each node has an output. Each node has a value. Each node has an output. Each node has an output. This is a product lattice. We know that the iterative algorithm is also a lattice. It is a product lattice. We talked about it last time. A product lattice is also a lattice. Let's see if a product lattice is finite. We talked about it last time. We talked about product lattice. If a product lattice, because there are k nodes, is a product lattice of complete and finite lattice, then the entire allocated product lattice is also complete and finite. The second condition is that it is easy to connect. The product lattice is a lattice. At the same time, the lattice is finite. If each lattice is finite, then the product lattice is finite. The second condition is related. Let's look at the first condition. First, we need to define a function. We need to define a function on the lattice. At the same time, we need to prove that the function is monotonic. This is related to the first condition. What is the function of the iterative algorithm? I mentioned it last time. In each iteration, it is equivalent to think.reapply function which consists of two parts. In each iteration, it is equivalent to think.reapply function which consists of two parts. In each iteration, it is equivalent to f input x. In iteration one, f x is the output. In iteration two, f x is the output. In iteration two, f x is the output. In other words, the function applies its own transfer functions to each node. to each node. In each iteration, each node applies its own transfer functions to each node. In each iteration, each node applies its own transfer functions to each node. For instance, to the node with the maximum size on the map, it uses the function to apply a transfer function. To the node with the maximum size on the map, it uses the function to apply a transfer function. As we see, each node has a transfer function. The output value of each node is the output of the L-Lattice function. For all nodes, the L-Lattice function is the output of the L-Lattice function. In other words, the green part of the range is the L-Lattice function. The L-Lattice function is also a finite. At the same time, each iteration of the iterative algorithm defines its behavior as a larger function. The L-Lattice function only needs to prove that the function is monotonic. Then we can connect the iterative algorithm to the Fixed Point Theorem. Let's see if the function f is monotonic. Let's think about it. There are two parts of the function f. One part is the transfer function, and the other part is the join-meet operation. The first part is the transfer function. In fact, we have talked about it when we talked about the original definition. In fact, the output value of the jQ problem is never-shrink. In other words, no matter how the int comes in, the q is always fixed, and the gen is also fixed. If we use the big vector from 0,0,0, 0 can only become 1, and 1 cannot become 0. So we have been emphasizing the transfer function. In fact, all the transfer functions are monotonic. The join and q functions are monotonic. In other words, if all the transfer functions are monotonic, then the whole transfer function is monotonic. So we have known the monotonic part. Now let's talk about the green part, the join and meet. Let's think of it as a function. Is this function monotonic? If it is, then the whole function is monotonic. I heard that the join and meet function is a combination of all the paths and dataflow values. Why are there only two values and one lattice? Because each dataflow value is a lattice. In fact, it is just a simple base case. If you have more than one, for example, you have three paths, then merge the first two paths into one lattice. In other words, the base case, the join function, is monotonic. Let's use join and meet to prove that the join and meet function is monotonic. Let's prove it. In fact, when you think of a binary relationship as a function, a monotonic function on a lattice, you can imagine that we want to take any three elements on the lattice, x, y, and z. Let's say that we want to give any two x and y to satisfy the binary relationship. Let's say that we want to give any two x and y to satisfy the binary relationship. Just imagine that we want to give any two x and y to satisfy the binary relationship. Let's say that we want to give any two z and z to satisfy the binary relationship. Consider that this is a monotonic relationship, which has the same element, z. Then we think that the John function is monotonic. Think about the monotonic function we talked about in the last class. x is less than or equal to y, while f of x is less than or equal to f of y. As a function defined by the lattice, we can get this result. If we can get this result, then it is monotonic, right? What is John? In the lattice, it is the least upper bound of any two elements, right? First of all, it is also an upper bound. Therefore, the John function of y must be the upper bound of y and also the upper bound of z. Because it is an upper bound, we can say that y is less than or equal to the John function of y, right? In addition, the John function of z is also a transfer function. What is the transfer function? As I said before, x is less than or equal to y, while y is less than or equal to the John function of z. Of course, x is less than or equal to the John function of z. This is the transfer function of the lattice. Do you remember? Therefore, the John function of y is the upper bound of y and also the upper bound of z. Now the John function of y is also the upper bound of x, right? Therefore, y and z are both the upper bound of x and also the upper bound of z. At the same time, what is the John function of x? According to John's definition, it is the least upper bound of x and z. Therefore, the John function of x is the least upper bound of x and z. Therefore, the John function of x is also less than or equal to the John function of z. Therefore, the John function of x is less than or equal to the John function of z. After proving the formal definition, we know that the John function of x is monotonic, and the John function of z is also monotonic. Therefore, we know that f is monotonic. We have already converted the iterative algorithm into the fixed-point theorem. The conclusion of the fixed-point theorem is of course applicable to the iterative algorithm. Now we can answer these two questions. Now we can delete these two questions. We can relate the iterative algorithm to the fixed-point theorem. Therefore, we can conclude that the iterative algorithm can reach the fixed-point theorem based on the fixed-point theorem. At the same time, the iterative algorithm can reach either the biggest fixed-point or the smallest fixed-point. Later on, we will systematically understand the meaning of best. Sometimes it is greatest, sometimes it is least. The so-called best is related to the accuracy from the perspective of analysis. The so-called greatest and least are the most accurate Now we have answered these two questions. The premise is that we need to have monotonic functions in order to have these two conclusions. We cannot guarantee that the iterative algorithm can reach the fixed-point. Now let's look at the third general question. When will the algorithm reach the fixed-point? We already know that the iterative algorithm can reach the fixed-point either the biggest fixed-point or the smallest fixed-point. When will the algorithm reach the fixed-point? This is actually a question about the complexity of the algorithm. We can ask how many iterations can the algorithm reach the fixed-point? Before answering this question, I would like to introduce another theorem about lattice. This theorem is quite intuitive. It is called the height of a lattice. In other words, a lattice has a height. Every lattice has a height. What is the value of this height? We call it the length of the longest path from top to bottom in a lattice. From top to bottom is the length of the longest path. The length of the path is the height of the lattice. Now I ask you what is the height of this lattice? The answer is 3. You can remember this concept. Then we can use it as a condition to calculate when the algorithm can reach the fixed-point. Let's look at the algorithm again. What do we want to ask? After so many iterations, what is the result of the lattice? What is the result of k-tuple? It is the same. The maximum iteration can reach what value? It can reach the fixed-point. To answer this question, we can make a prediction. We imagine the worst case complexity. Let's imagine every iteration, let's say as I mentioned before, when we were talking about how to express beta-prognosis through lattice, after every iteration, the value is the same as going up or down in a lattice. If it is the main, it will go up a little bit. For example, let's focus on this lattice. Let's say this is a lattice. Let's imagine ABC is the definition. Bottom represents 000, A represents 100, B represents 010, C is 001, AB is 110, AC is 101, ABC is 111. Let's imagine this lattice. After every iteration, we assume only one step in the lattice. Either go up or down. Let's say in a normal iteration, there are many nodes that have changed. For example, from 000 to 001. But in the worst case, after every iteration, we make the smallest change. The smallest change is one zero in a node becomes one. In a normal case, you can go up two steps. For example, you can go from 000 to 110. But in the worst case, we assume only one zero becomes one. Either A or B becomes C. So we assume only one node changes and only one zero becomes one. In other words, only one zero becomes one, which is equivalent to one step forward in the lattice. In the worst case, none of the nodes changes. Therefore, in the worst case, we assume that for every iteration, only one zero becomes one. Let's say the height of the lattice is h, and there are k nodes in the CFC. Let's say in the worst case, we need iteration, and in the worst case, what is the value? You can calculate it yourself. Let's use a 10-second delay. Let me ask you, in the worst case, how many times do we need iteration? Very good. I hope you understand. In the worst case, at most, we need h times k. Why? Think about it. Every time we climb up, one zero becomes one. When can we stop? In the worst case, every time we climb up, one zero becomes one. And we only change one node. In the worst case, all the nodes become one. At this time, every node climbs up from the bottom to the top. Let's say every time we climb up, one node becomes one lattice. In the worst case, we need iteration, and in the worst case, we need iteration.\n"
     ]
    }
   ],
   "source": [
    "audio_file_1 = open(\"./11-Audio-Summary/audio/lec06/lec06-0m-25m.m4a\", \"rb\")\n",
    "translation_1 = openai.Audio.translate(\"whisper-1\", audio_file_1)\n",
    "print(translation_1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d8253fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When many people learn this method, they feel that it is not very intuitive. So they memorize the h times k, that is, hat times the whole node. After you understand it, it is actually quite intuitive. Of course, this is the worst case. Because we know that if all zeros become 1, this method can stop. That means all the definitions don't reach. This is not possible in normal programming. This is just a so-called complexity, and we want the worst case. OK, we can answer the third question. When can the algorithm reach the fixed point? How many times does the worst case need to be replaced? It needs the number of nodes in the lattice hat times cfg. OK, so far we have answered the three general and fundamental problems of data flow analysis. The mathematical principles behind it, including the proof process, and how to understand them. We have covered these three questions with a large piece of paper. I think you have understood it quite deeply. OK, next we will talk about a very important part of the data flow analysis. Do you remember that we have been talking about this for the past few lessons? We have been talking about how to learn the rich and definite instances, and what are the available expressions. Some of them are main analysis, and some of them are master analysis. In general, master analysis is the top, and main analysis is the bottom. In the previous lessons, I have explained the theoretical framework of the data flow analysis. I have explained the theoretical framework of the data flow analysis. What is the theoretical framework of the data flow analysis? I know that you are all students, and you have other courses to learn. You are all working people, and you have other things to do. It is impossible for you to use the relevant knowledge in the future. You will have to re-learn our course, and re-learn the whole data flow analysis. You don't have the time and the experience. So there will be this part of the content. As a summary, I want to give you an example of the data flow analysis. First of all, I want to let you know what the data flow analysis looks like if you use the lattice expression. What is the main analysis like? What is the master analysis like? And what does it have to do with the intersection point on the lattice? Why is the main analysis intersecting the smallest point? Why is the master analysis intersecting the largest point? And what does the intersection point have to do with the sunniness and the accuracy of the analysis? We will present it to you in the future. The following content is very important. You must listen carefully. Ok? Let me give you an example. This is a power site, right? This is a power site, right? This is a density. This is a density. Lattice is roughly like this. Let's change the lattice to a elliptical shape. Like bottom top. Bottom top is the only one, right? It is equivalent to the lattice of the entire site. Let's put a definition for complete lattice. According to the definition, complete lattice must have bottom and top. General data flow analysis has bottom and top. It is a complete lattice. Imagine using a elliptical lattice. Let's imagine again. This is just an intuitive representation. What are we talking about? We are talking about the lattice is a result of the product lattice we introduced before. If you can relate to it, then you can relate to it. Let's imagine. Do you remember that our data flow analysis is like a program. It is just a program. For example, we buy a node in the KTable program. Because I K a node. Then your KTable goes up a little bit. A little change. In fact, the real lattice is a product lattice. Because every node is related to a lattice. They are a lattice, a product. A product lattice is also a lattice. The lattice we show is a product lattice from the point of view of the entire analysis. You can imagine every element in this product. If I click on it, it is a lattice. This lattice element should be a product. It is 00001. But it is every node 001. The second node is 010. The third node is a KTable. It is a product lattice element. But the entire product lattice is a lattice. If we imagine, there is only one lattice. You can not think of it as a product lattice. But it is really a product lattice. Because we want to update every node's data value. After we have such an imagination, we say there is a lattice. Let's talk about meganesis. As we said before, what is meganesis? It is from the bottom to the top. Why? In general, what does bottom mean? The bottom of a lattice from the point of view of the main, it represents an unsafe result. In conclusion, whether it is meganesis or mass analysis, it is from an unsafe result to a safe result. Why is meganesis a safe result and unsafe result a bottom? Let's imagine, what is the most intuitive meganesis? It is reaching definitions. What does reaching definitions mean? It means we use it to detect whether a variable has been initialized. How do we detect it? Because meganesis is a forward analysis. When we say entry, it is before the start of the program. Before the start of the program, we give a special definition to all the variables. This special definition tells us that you are undefined, you have not been initialized. Meganesis means there is a path you can reach. Let's say you reach this point. But if we say all the initialized definitions are undefined, it means all the variables have not been initialized. It means all the variables have not been initialized. No definitions can reach. This definition is undefined. It means all the variables have been initialized. It is a wrong application. All the variables have been initialized, which means no definitions can reach. It means all the variables have been initialized, because no variables have been defined. It means all the variables have been defined. It means all the variables have been initialized. There is no definition of undefined or initialized. There is no definition of unsaved. It is unsummed. We need to understand all the definitions. This is unsaved. What is top? We start from unsaved and move to saved. The dataflow method is like a ladder. We move up step by step. How do we move? What is top? It is a saved result. It is simple and intuitive. Undefined is marriage. If you define it, it is possible. It means all the variables have been initialized. Is it saved? Yes, it is. For example, there are 100 variables. It is saved. It is saved. But it is a nonsense. If you don't analyze it, you know all the variables are possible. It is unsummed. It is saved, but useless result. Ok? Someone says we move from unsaved to saved. Right? It must be a value in the middle. The most unsaved is the most useless. Which value do we define? If we want to know where the real analysis stops, we have to introduce another concept, which is truth. In the first class, we talked about the relation between something's truth and completeness. We talked about it collectively. At this time, you can imagine the process and the analysis. At this point, you can imagine the truth. For example, let's take the definition as an example. Let's assume A and C, the first and third definitions can reach. This is the truth. Then we have the truth as a boundary. If it is main, A and C are included. This part is saved. This part is unsaved. The above part is saved. This is the sound. The sound contains the truth. This part is complete. This part is not complete. This part is not completely contained in the truth. Remember, this is saved and unsaved. It is just a table. It is not completely contained. We know the above part is saved, and the below part is unsaved. My classmate said, does the main analysis start from the bottom? From the bottom, a little bit of applyable function. My classmate said, how do I know if I go beyond the truth? How do I know if I go beyond the saved part? How do we decide? Answer me now. How do you know if your analysis is saved? How do you decide? How do you decide? How do you decide? How do you decide? How do you decide? There are two elements in static analysis. One is data abstraction. The other is safe approximation. That is, when you design control flow merge, you have to design according to safe approximation. That is to say, you design control flow merge according to your safe approximation to ensure your analysis is safe. That is your design. It is not like if we give you an analysis, it must be safe. It is your design. So, in this case, why do we use union? Merge. It is a way to ensure safe. When do we stop the algorithm? First, there are many non-moving points. But, as we said before, our mainline is moving up from the bottom a little bit. And if it is monotonous, and the lattice is finite, the compute is finite, and the bottom is moving up a little bit, the function is monotonous. Although there are many non-moving points, our mainline is the smallest non-moving point among all fixed points. Why do we say mainline is the smallest non-moving point? Let's take a look. This is 1, 1, 1. This is 0, 0, 0, 0. Is the upper element bigger than the lower element? Look at all the fixed points. Right? Right? All the fixed points are here. The fixed point you want must be the smallest one. The fixed point you want must be the smallest one. The fixed point you want must be the smallest one. Right? Let's continue. I don't know how precise it is. First of all, it is already moving up. It is already moving up. In addition to moving up, what about precision? What about precision? No matter make or mask, what is the basis? It is from precise to non-precise. It is from precise to non-precise. It is from precise to non-precise. Normally, when we want to analyze if it is safe or not, the more precise the better. The more precise the better. Why do we say precision to non-precise? It is the least accurate. All the definitions can be achieved by a single analysis. So, we need to analyze the non-precise in this way. The higher the non-precise, the less accurate the value. Because we achieve the least of these points, the higher the non-precise, the more accurate the final result. That is why in the first question, we said the smallest non-precise must be the best. If there are more non-precise, the higher the non-precise, the higher the accuracy. The higher the non-precise, the higher the accuracy. This is why the least of these points is the most precise. The most precise is the most accurate. The most precise is the most accurate. This is the reason. Do you understand? This graph shows the main analysis about the smallest non-precise, accuracy, soundness, etc. What does it have to do with the bottom and top? What does it have to do with the main analysis? The bottom is empty. The main analysis is empty. Let's look at the must analysis. The must analysis is the opposite of the main analysis. Let's say the lattice is the same, but lean forward from the top. We've talked earlier that the main analysis is the opposite of the main analysis. The must analysis is the opposite of the main analysis. What about the top? The top is the same as the main analysis. For example, available expressions are the same as the main analysis. Why is it an unsafe result? It's because the top is the same as the main analysis. Therefore, all the expressions must be available. Let's say all the expressions are available at a certain point. All the expressions are available. If you want to optimize a wrong result, you can optimize the previous value. But now all the expressions can be reused. How is it possible? Therefore, it's an unsafe result. Let's talk about how unsafe it is. No expressions are available. Let's say you want to optimize the available expression. The conclusion is no expressions are available. No expressions can be reused. Therefore, you can't optimize a single value. However, you can't optimize a single value. This is a safe result. You just can't optimize a value. It doesn't mean that the program can be wrong. If the previous value is wrong, all the expressions can be optimized. Then you switch the program and replace all the values with the original values. This is unsafe and safe. However, this safe is useless if you don't optimize a single value. If you don't optimize a single value, you can't optimize a single value. If you don't optimize a single value, you can't optimize a single value. This is also unsafe and safe. The corresponding mask also has a truth. Let's understand this. There must be a corresponding unsafe and safe process. This is a bit tricky. Some students may say what does unsafe mean? What does safe mean? What does unsafe mean? What does unsafe mean? We talked about this before. What does unsafe mean? There are many expressions. The first one is big. The second one is small. The first one means more expressions are available. We talked about this before. If one of them is false, the analysis will be wrong. The first one may be false. It means you are unsafe. The second one is truth. The first one is false. The second one is true. The third one is complete. You can think of safe as complete. In short, the result I get must be correct. But when we talked about the mask analysis, the requirement for safe approximation is complete. This is an under-approximation. But some people say their analysis is solved. This is the opposite. The main reason I mentioned is that they will redefine the soundness. If it is safe, it is solved. From this perspective, safe is solved. But when we talk about soundness, complete and truth, this is an under-approximation. This is complete. This is not complete. There is a miscommunication here. If you don't understand what I said, it doesn't matter. You need to learn by yourself. This is the difference between different literature and expressions. This is our understanding. It goes from unsafe to safe. Why is it unsafe? There is no miscommunication. This expression is not available. If you say it is available, what do you mean? It is a miscommunication. For the mask analysis, you can't say it is. If you say it is, it is unsafe. If you want to optimize it, you are wrong. The above is unsafe, the below is safe. It goes from top to bottom. There are many fixed points. Some people say if the function is standout, and the lattice is finite, what is the result we are looking for? It is the greatest fixed point. Why? The mask analysis is the greatest fixed point. From the perspective of the lattice, this is the greatest fixed point. The greatest fixed point is at the top. From all the lattices, this is the smallest. It is empty. From all the lattices, it is the largest. So it is the greatest fixed point. What about the fixed point? It goes from safe to unsafe. It is useless. For the mask, the greatest fixed point is at the top. The reason is the below is unsafe, and the above is safe. The greatest fixed point is at the top. Many people say the least fixed point is the best, and the greatest fixed point is the best. It depends on the analysis. The picture is quite intuitive. In the future, the main analysis is to go from the bottom to the top. The top is big, and the bottom is small. It must be the least fixed point. The more you go up, the less accurate it is. The same goes for the mask. It goes from the top to the bottom. The more you go down, the less accurate it is. The more you go down, the less accurate it is. OK? Do you understand the picture? Answer me. Do you understand? Why is the greatest fixed point always safe? Imagine what we want to write. You want to achieve the greatest fixed point. Let's define the function. Let's say the function is monotonic, and the lattice is finite. First of all, you reach the greatest fixed point. But think about it. In addition to the fact that the function is monotonic, it is also safe. In other words, if the function is not safe, it can also reach the greatest fixed point, but the greatest fixed point does not go up. This is because first of all, you have to define the function using the central function and the control flow margin. Then you have to make it a safe approximation. This is the most basic. Then you say it is monotonic. In other words, safe is a condition that we are satisfied with. The greatest fixed point is a condition that we are not satisfied with. Do you understand? Actually, this is a good question. The size depends on the safe approximation. It does not depend on the fixed point theorem. After hearing this, I want to tell you more. We used to use strict math to prove the principle of fixed point. Right? To prove the principle of fixed point, we said that the greatest fixed point is the greatest fixed point. Now I want to show you from another perspective. I want to show you why the smallest fixed point is the greatest fixed point. Let's take the main axis. Now you know what the main axis is. It is the smallest fixed point. Let's take the main axis and see why it is the smallest fixed point. From another perspective, let's imagine that I apply functions one by one. If you don't understand, you can understand by adding a side, a circle. Let's imagine that we apply a function one by one. We take a step on the lattice. What is the rule we take? We take a step on the large function. There are two rules. One is the transfer function, the other is the control from merging. The transfer function is actually written dead. The gen and q are fixed. The q and gen are fixed. The rule is like this.\n"
     ]
    }
   ],
   "source": [
    "audio_file_2 = open(\"./11-Audio-Summary/audio/lec06/lec06-25m-50m.m4a\", \"rb\")\n",
    "translation_2 = openai.Audio.translate(\"whisper-1\", audio_file_2)\n",
    "print(translation_2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa99ec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fact, each node has a transfer function, and each step of the transfer function is fixed. Next, let's talk about control flow moduling, which is the main lattice, or the drum. What is the drum from the lattice point of view? It is the smallest upper limit of any two elements, right? Remember that two elements can have many upper limits, but it is the smallest upper limit. In other words, from 0.0.0, 0.0.0 and 0.0.1, you modulate the value, and then find their upper limit, you can change it to 1.1.1, but what do you change? You change it to UNION. What is UNION? It is the smallest upper limit. In fact, you can reach 1.1.1, but you can't. From 0.0.0 and 0.0.1, UNION can only become 0.0.1. What you want is the smallest upper limit of the two elements. In other words, if you want to modulate the transfer function, you need to look at the control flow moduling, or the drum modulation. In this way, you can reach the smallest upper limit of the two elements. There are many machines that you can't reach the smallest upper limit of the two elements, because you are using the least upper limit of the two elements. The least upper limit of the two elements is the smallest upper limit of the two elements. Therefore, every time you modify, it is a minimal step. Every time you modify, it is the smallest step. For example, if you stop at the smallest step, of course, you will get the smallest fixed point. You can also modify to the maximum, and you will get the fixed point. But if you modify to the maximum, you will get the smallest. This is another way to explain how to reach the smallest and largest fixed point. I believe that some of you have understood it. But it depends on whether you are familiar with it or not. If you are familiar with it, you can listen to it again and wear it again. You will be more and more familiar with this picture. And I just explained the view, you can probably get the idea. It doesn't matter if you don't understand it. Ok, this picture has a camera. What does the camera mean? It is very simple. If you have a tablet or a mobile phone, you can take a screenshot. I spent a lot of time to design this picture. And I have been discussing with Mr. Tan Tian how to make this picture intuitive, concise, and rich. Mr. Tan also gave me a lot of good ideas. So this is one of the most essential pictures in the whole course. So, you can take this picture and make a screenshot. If you have any questions, don't waste your time to learn the PPT, and watch the video again. Then you can use this picture as a reference. It can be a reference material. If you want to design a mail-in or SMS, you can take a look at it and wear it. You can't find this picture anywhere else in the world. So, if you can remember it, just remember it. Ok, let's move on to the next part. We have been learning for almost an hour. Let's take a break for about 8 minutes. I'm so sleepy. I slept less than usual. I have to prepare for the class. Fortunately, I won't talk about this topic. I can take a break for a while. It's my first year. And it's online class. It's my first time to have online class. It's a matter of face. Of course, I will prepare for the online class. I will do it for you. I hope you can understand. This class is very complicated. For example, you can learn how to operate a system, how to use language, how to write a program, how to use the Internet. You can learn a lot of things. You can learn a lot of things. You can learn a lot of things. You can learn a lot of things. You can learn a lot of things. But this class is much more difficult than the previous classes. There is nothing to refer to. I'm not satisfied with these materials. I have to make an example. This class is really hard. This class is really hard. You have to think about how to make it beautiful. You have to think about how to make it beautiful. You have to think about how to make it beautiful. When I designed this class, The initial intention for this class was not to make it complicated. I'm glad if you know this class. I'm glad if you know this class. We designed this class with Tan Tian. We designed this class with Tan Tian. This is the core idea of this class. Otherwise, many people lost interest in this class. Otherwise, many people lost interest in this class. I think this class was very boring. so we designed this class according to this idea. But once you have this core idea, But once you have this core idea, It will be hard to design a class. It will be hard to design a class. It will be hard to design a class. Sometimes I feel that it is better to reverse the class. Often I feel that it is better to reverse the class. Actually, it is very normal to reverse the class. So it is hard to make a good class. I think all teachers face this problem. I think all teachers face this problem. So please forgive the teacher. You have to ask for funds to take students to study, and prepare the class. It's not easy for everyone to prepare the class. It's not easy for everyone to prepare the class. What should we do to prevent this from happening? What should we do to prevent this from happening? I'd say we would go to RAS. I'd say we would go to RAS. We are going to board a plane for the Chinese way to the university. We are going to board a plane for the Chinese way to the university. I'm quite sure of it. I'm quite sure of it. I'm quite sure of it. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone. Hello, everyone.\n"
     ]
    }
   ],
   "source": [
    "audio_file_3 = open(\"./11-Audio-Summary/audio/lec06/lec06-50m-75m.m4a\", \"rb\")\n",
    "translation_3 = openai.Audio.translate(\"whisper-1\", audio_file_3)\n",
    "print(translation_3['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1ef2cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me explain it to you. I can tell you the answer directly, I will just tell you what is the relationship. But you can only remember it later, it's not interesting. You have to know it. You have to remember it. You will know the principle. It's very simple. I will use the previous mathematical concepts. By the definition of the least upper bound, we have this. You are the least upper bound, and the least upper bound is also an upper bound. Therefore, x becomes y, both x and y are upper bounds. It doesn't matter. The deviation represents an upper bound. Because the transfer function is monotonic, it's monotonic, because the data flow message is monotonic. So what conclusion do we have? Let's imagine that a is less than or equal to b, then f of a is less than or equal to f of b. This is also less than or equal to b, then f of a is less than or equal to f of b. Therefore, f of x, because it's monotonic, is less than or equal to f of x y. Similarly, f of y is less than or equal to f of x y. Now let's look at what this means. According to the relation of the deviation, f of x y is bigger than f of x y, and bigger than f of x y, and bigger than f of x y. According to the relation of the deviation, it is the upper bound. We know that f of x y is the upper bound of f of x, and f of y is the upper bound of f of x. No problem, right? Because f of x and f of y are the least upper bound, according to the definition of John, so what? What is this? This is the least upper bound, right? This is the upper bound, right? Then f of x and f of y must be less than or equal to any other upper bound. So what is their relationship? This is what we want to say. On the left is MOP, and on the right is OR. In this case, OR is MOP, and they are of a small relationship. In other words, they are in a relation of the deviation. So what does this relation mean? Let's imagine that if this is a male, and we say that John is a male, and the ball is the least upper bound, and the ball is the upper bound. So what is the relationship between them? Let me ask you, which one is more accurate? Look at the picture in front of me, which one is more accurate? You see, the ball is the upper bound, so which one is more accurate, the upper bound or the lower bound? Now imagine, tell me, MOP and OR are of the same relationship. Who is more accurate, the MOP or the OR? In the previous lecture, we said that the upper bound is the upper bound, and the lower bound is the lower bound. Now we say that the upper bound is not accurate, and the lower bound is not accurate. So which one is more accurate, the upper bound or the lower bound? The upper bound is not accurate, so MOP is more accurate. So OR is less precise than MOP. Very good. Now, this is a partial relationship. What is a partial relationship? It has a self-relation. x can be less than or equal to x. What does this mean? You can think of it as my analysis is always less than or equal to MOP. It is like this. Now, normal people will ask, in what situation can OR be equal to MOP? In fact, if it is equal to MOP, there is another concept. When this function is distributive, it has a distribution. It should be translated like this. Distribution. That is, the OR in front of us is MOP. But if the function is distributive, that is, fx normal y is equal to fx normal fy, then the OR of MOP is normal. This is the definition. We can see that MOP is here. When the function is distributed, we find that MOP is accurate. We find that OR can be as accurate as MOP. Ok? Now, I want to ask if all the functions before are distributive? Rich indefinite, I can tell you clearly that when our function is distributive, the result of our iterative algorithm will be as accurate as MOP. In fact, all the false analysis we encountered before are distributive. What is our analysis called? It is also called bit vector. It is also called giant q problem. It has a feature. It is not that only giant q is called giant q problem. Many data flows can use giant q. In the end, the collection operation can be used by the union and intersection of the collection. This kind of data flow is called big vector problem. It is also called giant q problem. What are these kinds of function? Distributive. In other words, the result of our iterative algorithm is as accurate as MOP in the end. It is quite accurate. However, is there any function that is not distributive? Yes, there is. Next, let's talk about a function that is not distributive. It is called constant propagation. It is also our first experiment paper. We will post the paper on this weekend. We will post it on our website. Since we are going to do this paper, I will not go into details. I will let you think about the concept of constant propagation. Actually, you can find a lot of references on the Internet. Let me introduce you the concept of constant propagation. What is constant propagation? It is a very basic optimization that is done by the Y.X is guaranteed to hold a constant value at P. For example, when X is at a certain point P, is it guaranteed to point to a certain constant? Actually, it has a meaning. Does it sound more like MERS or MERS? Answer me. Do you think it sounds more like MERS or MERS? Let's try it. It sounds more like MERS. Why? Because it means it is certain. So let's imagine we want to know X is equal to X is equal to 1 in the middle X is equal to 2 in the right X is equal to 4 in the back It is not a constant. Some parts are equal to 1, some are equal to 2. So it means all the parts have to be equal to 1. It is a bit like MERS. But concept propagation is a bit like the traditional union set. The combination of union and set. The intersection is not the same. It is not a traditional bit vector problem. We will talk about it later. It is not like we used to say it is either the intersection or the union. It is not like that. It is a bit special. But when you think about it, you can imagine it as a MERS message. We can think of it as a MERS message. It is a special analysis. Actually, the out is a bit special. The out of each node in CIFG includes a set of pairs. In my data flow, it is not like definition, expression, variables. It is a set of pairs. The pair is x, y. x is each variable. v is the value. If you are a constant, your x value is 1. Then you should use x1. We are not talking about whether x is a constant or not. We are talking about the value. If you have a constant, x is equal to 100, x is equal to negative 100. You want the value. So there is a pair. The data flow value is a pair. Each variable corresponds to its value. We have talked about it before. Since we have learned about the lattice, we have talked about it before. This is one of the slides and one of the pictures. Let's review it. A data flow lattice framework is also a data flow lattice framework. There are three elements. The first is direction, the second is lattice, and the third is transfer function. What is the direction of constant propagation? It is easy to understand. It is a forward. I don't know anything from the beginning. I want to know what happened before x came. Is it pointing to 1 or 2? It is a normal forward. Next, what is the constant propagation lattice? What is the transfer function? Let's look at it. There are two elements in the lattice. First, there is a domain, y6. There is another one. If we want to get meet between the different y6s on the lattice, we need to get meet. What should we do when we get meet? In other words, what should we do when we get meet in the control flow merge? How can we combine the data flow information? This is the meet operator. The domain looks like this. It is a bit special. The length is very short. As we said before, what is the initialization plan? The initialization plan is the ND plan. It goes from top to bottom. The more we go, the more unsafe it is. Why is it unsafe? Because all the variables are not constants. This is very safe. You can see if it is a constant. If it is a constant, you can do the optimization. If it is not, it is safe, but it is useless. Some students ask if they can understand that this is safe and useless. The more we go, the less accurate it is. The more we go, the less accurate it is. If it is a constant, it is not accurate. For TOG, all the variables are constants, right? This is unsafe. Why does it say ND plan? This is what I said before. Constants are a bit special. It is not a constant. It is a pair. It needs a variable and a specific value. What is the value of the initialization plan? It is like a variable. You haven't run a program yet. You want to know what the value of the initialization plan is. It is like a ND plan. This is a bit special. But it is still the same as what we talked about before. It is just that the initialization plan is a bit special. Ok, after this, let's look at MIT. After we know this, we will look at MIT. Data abstraction is either a ND plan or it is not a constant. Either it is not accurate or it is a specific constant value. We will look at how to combine these values when we want to control data values. We will look at how to combine a not constant with any value. For example, x is not a constant. We don't know what the value is. Is x a not constant? Because you want a safe approximation. You don't need to be wrong. So it is not a constant. If you combine it with a not constant on another path, it is a safe approximation. Ok, let's say x is a ND plan, and we combine it with any variable, such as 1, 0, or 1, which is a constant value. What do we combine it with? We combine it with 1, 0, or 1, which is a constant value. At this point, you may find that the left side is a ND plan, and the right side is a V plan. Let's say the left side is a constant value, and the right side is a negative 12. If we look at the initialized variable, we will find that the left side is a V plan, and the right side is a constant value. It is not a V plan. This is wrong. I want to tell you a common view in dataflow analysis. For example, in an initialized variable, who do you assign a meet and transfer function to? It is designed for constant propagation. You are focusing on constant propagation analysis. Therefore, initialized variables analysis is not the focus of your analysis. When we do constant propagation, we assume that the program is correct. What does this mean? If the path is indeed an ND plan, then you can imagine that in constant propagation, there will not be a path. For example, if you have a path, then you have to optimize the path. In this way, every analysis does one thing. Therefore, you can separate the two. If you want to monitor both initialized variables and constant propagation, you can change the meet. If you want to have initialized variables analysis, then you have to modify the meet. Otherwise, you will be exposed. In general, all the materials are designed in this way. We only focus on constant propagation. Now let's look at non-constant and end-to-end. The length is represented by c. The length is represented by c. The length is represented by c. The length is represented by c. The length is represented by c. The length is represented by c. The length is represented by c. The left side is the S1, the right side is the S2. C1 and C2 are X. The length is different. So it is not a constant. These are all meet. These are all meet. All of them are considered. Let's define the Meet operator. Let's define the Meet operator. It is not the site union. It is also not the intersection. It is a special meet operator. Some students asked if meet and join can be used to combine meet and join. You can do that but in reality it is not. It is a lattice operation. Let me summarize. At each pass conference PC we should apply meet for all variables in the incoming dataflow values and get PC. Let's consider all variables and see if they are constant. All variables. Let's see if all variables are constant. After seeing the lattice, let's see the transfer function. What is the transfer function? Actually it is also a definition. We want to know if all variables are constant. We use assignment. We define the transfer function as x. We define the transfer function as f. Is it similar? For example, if we give it an int s, we get q. What are the ints and outs? They are all dataflow values. The pair is the value corresponding to the variables. This is a common pair. No matter what the value is, we will get rid of it. Why? Because we have a new value after the previous one. After we get rid of it, we generate a new value. This new value is based on the constant transfer function. What is the rule? Before I explain the rule, I want to show you a helpful function. We use var value. What does var x mean? It is the lattice value that the variable x holds. I want to know what is the value of the variable x. It must have a pair and a value. How do we get rid of the value? We use var. This is a very common form of formalization. If we want to design a transfer function, we need to consider all the conditions. If x is a constant, then what is the gem? It is a pair of x. The value of x is c. If c is 1, then x is 1. If c is 100, then x is 100. If y is a non-constant, then it is a congenial situation. It can also be a constant. What if it is not? In this case, what is x? What is the value of x? If y is a non-constant, then the value of var is also a non-constant. The value of var is the value of the value of y in the output. If y is 100, then x is 100. If var is 100, then y is 100. Let's continue. If you are a two-dimensional operation, which is very common, for example, then the result must be a function related to y and z. I will explain it directly because it is intuitive. First of all, if the value of y and the value of z are both constants, for example, if y is 1 and z is 2, then what is the value of x? What is the value of x and the value of z? It is f of y and z. If y is 1 and z is 2, then what is the value of x? It is f of y and z. If y is 1 and z is 2, then what is the value of x? It is f of x and z. So both the y and z values are constants. If the value of y and the value of z is not a constant, then x is not a constant. If you add another number to non-constant, then x is also not a constant. This is a very intuitive way of thinking. So what does it mean by otherwise? Imagine that both values are constants. In this case, any one of them is not a constant. In this case, if one of the values is a constant and the other is undefined, or if both are undefined, then it is otherwise. In this case, we define both as undefined. Pay attention to this. This is a tricky part. Of course, you can just remember this. But I want to tell you why. If the value of y and z is undefined, then the value of y and z is undefined. It can be undefined as a constant, and the two constants can be substituted. Of course, undefined plus undefined is undefined. Or it can be undefined plus a constant. This is also intuitive. Undefined plus a constant must be undefined. But from the side, if undefined plus a constant is a constant, then this is a function. You can imagine where the lattice is. It is not monotonic. Let's talk more about this. After this, we have defined the transfer function. Now, let's look at the assignment statement. If it is not an assignment statement, then what is f? What does it mean? In other words, when we meet a statement, we apply the transfer function. If it is an assignment, we pay attention to whether x is a constant. If it is not an assignment, then it does not matter whether it is a branch, an if, or a condition. What is identity? Just pass it on. It does not affect any of the variables. This is the transfer function of constant propagation. So far, we have talked about constant propagation very quickly. We have talked about the core. We have talked about the core. We have talked about constant propagation. It is not a distributed function. It is a non-distributed function. Let's see why. Let's see why. Let's take an example. The left side is a0e, b0e. The right side is a0e, b0e. The left side is x, the right side is y. We want to use constant propagation to choose c. Let's see if it is distributed. Let's see if it is distributed. If they are equal, then the function f is a satisfied distribution. Let's see if they are equal. After x is added to y, which is our traditional way, we merge the data from x and then apply the function. This function is c equals a plus b This is the transfer function f. Let's see. The left side is a0e, b0e. The right side is a0e, b0e. I ask you, what is the result of fx plus y? You answer c. You answer fx plus fy. You answer fx plus fy. You answer fx plus fy. You answer fx plus fy. You answer fx plus fy. You tell me what the value of c is. What is the value below? What is the value below? Tell me. Good. OK. The value below. But I don't need to write it down. We only care about c. So what is the result of this out? What is a? We say x is a0e, b0e. y is a0e, b0e. What do we do first? First, let's meet it. If the left side is a, and the right side is y, then we turn it into a0e. So a is a0e, and b is a0e. If a and b are a0e, a0e plus a0e, then c is a0e. But what is the value below? We say c is 10. Why? Because it is fx first.\n"
     ]
    }
   ],
   "source": [
    "audio_file_4 = open(\"./11-Audio-Summary/audio/lec06/lec06-75m-100m.m4a\", \"rb\")\n",
    "translation_4 = openai.Audio.translate(\"whisper-1\", audio_file_4)\n",
    "print(translation_4['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0644864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In other words, we first apply the x to the function f, and then we say that 1 plus 9 is equal to 10. The right side is also equal to 10. c is also equal to 10. c is also equal to 10. c is also equal to 10. f x meet y is not equal to f x meet f y. This is why we say that it is not distributive. We can see that it is not. We can deny it. Actually, you can think about it. Let's look at the lattice. I ask you which one is more accurate. You see which one is more accurate. It is always the one with MOP. Why? From the perspective of the lattice, if we think about it from the perspective of the lattice, where is this? This is above the lattice. Do you think what this value is? The value on the left is not constant. This value is 10. Not constant is at the bottom. When we look at the top-down, imagine that we have a graph on top and the graph on the bottom is going down. The lower the graph is, the less accurate it is. The value at the bottom is not constant. The value at the bottom of the lattice is 10. So the value at the bottom is not constant. The value at the bottom is what we want. So we are not as good as MOP. This is why we deny it. Because the previous graph was also very intuitive. You can think about which one is more accurate. In fact, it is not only about accuracy. It can also show a monotonic function. You can verify it by yourself. It is not important. In fact, the transfer function we defined earlier is monotonic. Including our meet value. Our meet value and transfer function are monotonic. OK. This is the first paper. Specifically, Mr. Tan Tian is designing a paper for you. He is very hardworking. He is in charge of the paper. He writes the paper. He will publish the paper at the weekend. He will publish the paper at the weekend. He will publish the paper at the weekend. OK. Let's move on to the last part. Worklist algorithm. In fact, we talked about the iterative algorithm in the previous part. Now we are talking about the worklist algorithm. In fact, the real data from the lattice will not use the iterative algorithm. Why? Because the worklist algorithm can be seen as an optimization of the iterative algorithm. In the worklist algorithm, it is a more commonly used algorithm. However, their basic nature is the same. It is just an optimization. As we said earlier, the iterative algorithm has the worklist algorithm. Why? If we talk about the basic iterative algorithm, the worklist algorithm has the basic iterative algorithm. But the worklist algorithm is an optimization. How is it faster than the iterative algorithm? Let's review the iterative algorithm. Let's review the iterative algorithm. This is what we have been talking about in the previous two classes. This is what we have been talking about in the previous two classes. Let's take the example of the formal lattice. The main lattice is strong. Let's look at the initialized pattern. Let's look at the initialized pattern. What do we see next? The initialized pattern has a condition. If any node's out If any node's out does not change, the algorithm will stop. If there is only one change, each basic block will be replaced and re-calculated. This is a great honor. This is a great honor. What is the purpose? The algorithm will stop if any node's out. But even if there are 1000 nodes, and each node's 0 becomes 1, we still need to apply the 1000 node transfer function. Isn't this a great honor? The core of the worklist algorithm is the optimization. We only need to calculate and apply the functions. We only need to calculate and apply the functions. We only need to change the functions. We only need to apply the transfer functions. Let's take a look at how to do it. Let's take a look at how to do it. The yellow lines are the worklist's Let's take a look at how to do it. Let's first initialize the worklist. We have to add all the basic blocks to it. So when the worklist is not empty, it will not be empty. If we add all the basic blocks, there is no node, but only the worklist. Let's pick a basic block B. When you initialize it, you must take out the value. The value must be different. Right? If you initialize it, the value is empty. In other words, when you take out the value, it is the same as when you initialize it last time. You take out the out value. We will compare it later. Let's do it again. Let's do it again. Let's take out the value. Let's run it. Then we take out the new value. Let's compare it with the last time. There is no change. If there is no change at all, then we don't care. When do we care? If there is no change, it means there is no change. If there is no change, it means there is no change. So what we do? Add all successors of B to the work list. Why add successors? Because if the out value of B changes, it means there is no change for all the in values. Right? Then we said If all in values do not change, when you apply the transfer function, the out value will not change. What do you need to apply the transfer function for? Isn't it easy? Therefore, we only apply the basic block that changes the in value. Then the out value will change. When does the in value change? If the out value of a basic block changes, then all the in values of the successors will change. So you add all the in values of the successors to the work list. If the work list becomes empty, it means there is no change for any basic block. Therefore, if the out value does not change, then the fix point is reached. This is why we said we only calculate the out value of the basic block that changes the in value. This way, we can avoid the iterative algorithm that we talked about before. Alright? For our first assignment, we still want you to be familiar with the iterative algorithm. We will use the work list to write the algorithm. Alright? To sum up, I will show you what we talked about in these two lessons. The first part is the K-tab. In fact, we talked about the product lattice. Then we talked about the dot function. The dot function also helps us to understand different principles. Then we talked about the data flow lattice. We talked about the lattice, complete lattice, product lattice, and semi-lattice. We also talked about the upper and lower bounds. Then we talked about the lattice. Then we talked about the dot principle. If the monotonic lattice is finite, the complete lattice will apply the function from the top to the largest dot. After we talked about the dot principle, we applied the iterative algorithm to the fixed point theorem. The fixed point theorem is that we can express the nature of the algorithm through the dot principle. Therefore, we answered three general questions. 1. Can we stop the algorithm? 2. Can we reach the dot? 3. If we can stop it, how many dots can we reach? We asked for the smallest and largest dot. We also explained the most precise result of the iterative algorithm. In order to save time, we put all the knowledge on the screen. For example, what is the difference between MegaMassLattice and LatticeFixedPoint, what is the relationship between LatticeFixedPoint and LatticeFixedPoint, and what is the relationship between LatticeFixedPoint and LatticeFixedPoint We need to understand all these parts. If you want to understand 1-7, you need to understand the first two parts in English. After the 8th part, we looked at the accuracy from another perspective. We introduced a classic concept called MOP. We found that when the central function is distributed, the MOP result is the same. But not all dataflow assets are distributed. We introduced the concept of constant propagation. We also showed why it is not distributed. At the end of the course, we talked about worklist as an iterative algorithm. We have all the worklist algorithms, but the worklist algorithm is a more efficient algorithm. We explained why it is more efficient. I think the explanation of worklist is quite intuitive. It is easy to understand. Well, that's all about the foundation. What do you need to know about the foundation? What do you need to know in the final exam? First, you need to understand the functional of KTab and ProductList. I will make some articles about this. If you want to understand, you don't need to know how to change it. You don't need to know how to change the core design. Then you need to understand the lattice, the complete lattice. You don't need to know the lattice concept. The whole Fixed Point Theorem is based on the lattice. But you need to understand the Fixed Point Theorem. The most important thing is you need to draw the matrix of MAC, MAX, and LATTICE. You need to summarize it. We will make some articles about this. Don't worry. Then you need to understand the relationship between MOP and iterative algorithm. When are they equal? When are they more precise? Who is more precise between MAC and MAX? Why? You need to understand this. You need to understand the worklist algorithm. You will need to understand the worklist algorithm in the future. These are the key points. Alright. We have finished the four classes for today. I want to tell you that the first homework will be done soon. Mr. Tan will be in charge of the document part. He will prepare the interprocedural analysis. In the last class, Mr. Tan wanted to talk about the interprocedural analysis, but he had a tight schedule. He had to prepare for the next class. We will discuss about this later. We will discuss about this later. We will discuss about this later. The Education Department has agreed. We will stop the class now. In the next class, Mr. Tan will talk about the interprocedural analysis. After Mr. Tan talks about the interprocedural analysis, he will talk about the four to five classes. After that, he will talk about the FDS and the S&S. After that, he will talk about the FDS and the S&S. I will talk about both classes. That is all for today. Thank you very much for your support and encouragement for these six classes in the past six weeks. Thank you very much. Although the original intention of our course design is a bit difficult, our original intention is to make it easy to understand. However, due to my limited ability, I am not sure if I can make it easy to understand in the past six classes and if I can make it systematic. I think there are still many shortcomings. However, I would like to thank you for your support. Lastly, I would like to tell you that we hope that you can learn knowledge from this course and get some benefits from it. For example, you will be happy to be a member of the R&D committee of a big company because you will be able to learn a lot from this course. I hope you can learn some knowledge from this course and get some benefits from it. I hope you can learn some knowledge from this course and get some benefits from it. Of course, if you are interested in PL or in modern programming analysis, I hope you can learn from this course and gain more confidence from this course. With this confidence, I hope you can work harder in the future. I think confidence is very important no matter if you are a programmer or not. Once you have this confidence, you will be more active and positive. Then you will have more positive feedback. Then you will be happier and more confident. Then you will have an interest in this field and it will become what you like. No matter how bad your skills are, how many games you play, how old you are, don't compare yourself with them. You are facing a professional programmer. You are facing knowledge. As long as you learn from knowledge, you will be better. You will have a reason to be more confident. Remember this confidence and move on in your life with this confidence. See you in the class of Nanjing University. Thank you. I will give you 5 more minutes to answer your questions. Is there any problem? If there is no problem, I will go ahead. Oh my god. I am so happy. I finally finished. I am so happy. Other than the class, do you have any experience in learning? You can come to my office and talk to me. I will be happy to help you. Thank you. You can come to my office and talk to me. No problem. Will the MOP result be saved? Meet over process will the MOP result be saved? This question is similar to the previous one. We are talking about transfer function. In MOP, you are using transfer function. Save or not depends on the principle of transformation. The pressure is on Mr. Tang. Of course. Mr. Tang's part is very difficult. It is complicated. But I know Mr. Tang is very serious. But I know Mr. Tang is very serious. Please look forward to it. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Bye-bye. Bye-bye. Bye-bye. Thank you. Bye-bye. Thank you. Thank you.\n"
     ]
    }
   ],
   "source": [
    "audio_file_5 = open(\"./11-Audio-Summary/audio/lec06/lec06-100m-end.m4a\", \"rb\")\n",
    "translation_5 = openai.Audio.translate(\"whisper-1\", audio_file_5)\n",
    "print(translation_5['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e66688e",
   "metadata": {},
   "source": [
    "## Lec07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efbd081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好了 我们现在正式开始上课 同学们好 从今天这节课开始 接下来几节课由我来给大家继续来讲 软件分析 那么前面几节课 李老师讲的非常好 设定一个很高的标准 让我压力山大 那么我也是第一次上课 所以如果有讲的这个不是特别清楚的地方 同学们也包含一下 那么今天我们学习的内容是interprocedural analysis 就是过程间分析 那么在这节课中 我会首先给大家讲为什么我们需要过程间分析 然后会给大家讲解过程间分析需要的一个必要的东西 code graph是怎么构造的 然后我会讲过程间的control flow graph 这个概念 因为这是过程间分析需要的一个必要的一个程序结构的一个表示 然后最后就给大家讲一个过程间分析 这数据流分析它应该大概应该怎么做 那么我们从第一部分开始讲 那么目前为止我们学的所有分析都是intraprocedural 就是过程内的分析 那么在以往的这个我们目前学习的分析当中 我们是不处理这个方法调用的 那么如果我们碰到有程序当中肯定是有很多meta code 那么遇到这些调用的时候 我们应该怎么分析呢 那么在过程内分析的这个情况下 我们通常的做法就是说我们对这个方法调用做最保守的一个假设 这是为了这个safe approximation 也就是说我们假设你这个方法调用你可以做任何事情 那么对于这个常量传播的例子来说 我们看到这有两个调用 第一个这个n需要一个方法tend它的返回值 另外我们再看底下这个y等于x加1 这个x它是参数也是涉及到方法调用 那么我们所谓对于常量传播最保守的假设 那我们假设就是说你这个传来的数量数字可能是任何一个值 所以它肯定是不是一个constant 那么在这个例子当中我们最后常量传播的结果就是说 n包括x以及x加1得到的y它都不是constant 那么因为我们至于过于保守的假设 就是说很容易导致这个imprecision 因为对这个例子来说显然n的值它就是10是个常量 那么x也是个常量 它的值就是42 但是因为过程内分析它不处理方法调用 我们做这个最保守的假设 所以我们只能假设它不是常量 因此就丢失了精度 那么为了更好的这个精度 我们就会需要这个过程间分析 那么过程间分析具体来说 就是说它跟过程内分析做这个保守假设不同 当它遇到方法调用的时候 它就会传就是说它会有过程间的这些边 比如说这有个call edge 或者说这个return的话 它控制流会有return到add1这么一条边 那么过程间分析它就会顺着这些边来传递这个数据流 因此我们得到的结果 对于过程间分析它会把42这个具体的数据流传到x 或者它会把10传到这个n这个地方 因此我们做过程间分析 我们传递数据流 这样的话我们就可以避免过度假设造成的这个精度的丢失 那么我们也就可以得到一个比过程内分析更好的一个精度 那么做过程间分析需要的一个 一个必要的一个信息就是call graph 因为我们知道这些call edge 就是说这些调用边 我们需要有call graph来告诉我们 每个调用它会去到哪些目标的方法里头 所以我们接下来要学习就是说我们如何构造程序的调用图 那么什么是调用图 其实我想同学们应该学过编程也至少有两三年三四年 他们同学们应该都听过 其实都听过这个概念 那么具体来说 调用图就是说程序当中调用关系的一种表示 本质上它就可以看作是一个调用边的集合 那么每个调用边从它的调用点连接到它目标方法 那么我们叫target beta或者也叫call list 那么我们用刚才这个见到的程序举个例子 那么这个程序有三个方法 不方法跟tent还有add1的三个方法 不方法当中有两个callsite 那么它的调用图就是说从这两个调用点会连有边 连接到他们的相应的目标方法当中 那么这个就是左边这段程序的调用图 那么调用图这个东西它是有非常重要的东西 首先它有非常多的用途 它不仅是理论上所有的跨函数分析的过程间分析的一个基础 因为你要跨函数 你首先就知道每个调用点它会调到别的哪些方法 此外它对于程序的优化 理解 debug debugging包括测试 它都有很重要的发挥很重要的作用 所以调用图本身是一个非常重要的一个关于程序的信息 那么因此构造的调用图也是静态分析当中一个非常重要的议题 那么我们在这个课程当中 我们主要针对的是对于OO语言的调用图的构造 因为我们现在虽然程序语言大家知道有很多 不同的流派有C或者OO的或者functional等等 但是目前可以说在应用程序中单据比较统治地位的 份额上最大的还是面向对象语言 那么在这个课程中我们又选择面向对象语言 代表Java作为我们分析的语言 来讲述如何构造调用图 那么在过去这些年中有很多构造调用图的各种算法来提出 那么这里我列出的是四个比较具有代表性的算法 那么这些方法越往下方法它的精度就越高 那么越往上的速度就越快 那么我们在课程中不会学习所有的一些方法 我们选择我们学习最上面速度最快的 在这些课当中我们要学习的class hierarchy analysis 那么在接下来的几节课中我们会来学习 通过指针分析point analysis来构造调用图 那么要学习构造调用图 首先我们要了解Java当中的调用 那么熟悉Java的同学应该都知道 Java的调用分为主要分为三大类 SteadyCode, SpecialCode和VirtualCode 对应只有JVM的这4种指令 那么对于Java从Java 8开始还引入了一个emoc dynamic 但那个是为了有特殊用途的 那是专门用来主要是用来实现在JVM上实现动态类型语言的 所以那个不在我们的讨论范围之内 我们的关注重点就是这三种 和Java的调用 那么这几种我们一个一个来看 首先SteadyCode它的对象就是它调的目标方法 就是静态方法 所以它是没有receive object 那么SpecialCode和VirtualCode调用的都是instance方法 调用的实例方法 那么SpecialCode它是有三个用途 一个是用来调构造函数 第二个是用来调类自己的自由的实例方法 第三个就是用来调用它副类的实例方法 那么其他情况下你要调用的实例方法情况下 就是会用到的是VirtualCode 那么这几种方法的目标方法的个数 静态方法它就只有一个方法 那么这个是编译器可以确定的 SpecialCode它调用的对象个数也是只有一个方法 也是可以在编译器能够确定的 那么VirtualCode就比较特殊 实际上这是为了实现OO的一个典型的特征 实现多态来实现用于实现多态的这么一个特性 那么在一个VirtualCode 我们知道在程序的运行的不同的阶段 它根据它调用点Receiver Object类型的不同 它是实际上它是可能调用到不同的目标方法 所以说一个VirtualCode 一个Coresight在程序调用一个执行期间 它的一个目标方法是可能是大于一个的 那么至于VirtualCode它调用的具体方法 它是要实际上等到运行时候才能决定 它是取决于你Receiver Object的具体类型 那么对于构造电容图这件事情来说 真正的关键就在于你如何去处理VirtualCode 因为我们知道StaticCode和SpecialCode 它们的目标就是说目标方法只有一个 它是比较trivial的 就是说比较好处理的 真正比较难以处理的在于VirtualCode 所以VirtualCode是对于OO语言构造电容图的一个关键所在 那么这里我们先来了解一下 VirtualCode当中一个关键的步骤叫做Method Dispatch 我们知道在程序运行时候 比如说我们这里有个Coresight 一个VirtualCode 那么VirtualCode它具体调用的方法 它是动态时候需要去解它的目标方法的 那么这个过程就是说涉及到两个要素 第一个就是说这个Receiver Object它具体的类型 比方这个例子当中就是变量O指向对象的具体类型 第二个要素就是说Coresight这一点 你这个方法它的签名 那么求解它动态时候去解它具体目标方法的过程 我们也叫Method Dispatch 那么我们这里提到它取决于方法的签名 那么这个signature在不同的参考文件当中 不同的资料里头它可能有不同的含义 那么在这节课当中 我们signature定义我们是按照这个方式来定义的 就是说一个signature它可以充当一个类 一个方法的一个identifier 就是说通过一个signature 你可以唯一的确定一个具体的方法 那么signature它有三个部分组成 第一个是它这个方法的ClassType 也就是说这个方法具体定义在哪个类当中 第二个部分是它的方法的名字 第三个部分就是它的Descriptor Descriptor有两部分组成 就是说一个是方法的返回类型 一个是它的参数的类型 那么对于底下这个方法 复方法来说 它的signature就包括C它的ClassType 它的名字复 以及它的返回类型和它的参数类型 那么这个格式实际上是 这个sort这个工具当中取用采取的格式 那么我们每次写一个方法写这么多会比较长 所以说在这个课程当中我们会用它 在没有歧义的情况下我们会缩写 就是说通过一个类型 点加上它这个名字 以及参数类型写在括号当中这种形式 作为一个方法类型的缩写 那么接下来我们就可以定义一个函数Dispatch 这个函数它是模拟了动态时去Dispatch 一个Cos它具体方法的过程 那么它有两个参数 这两个参数也就是我们前面的两个要素 就是说C就是Receiver Object的类型 M就是这个Cos这一点的方法的签名 那么它具体的过程这个如下所示 我们从DispatchC M 那么如果这个Class C里头包含 一个非抽象的方法M一撇 并且M撇有着跟M一样的名字 以及Descriptor 那么就直接返回M撇 我们就认为这Dispatch找到了它的目标函数 那么为什么我们需要一个非抽象的一个方法呢 因为我们知道Dispatch它的目的是为了找到一个 能够要被调用的方法 那么这个能被调用的方法 它必须是一个具体的方法 必须是有方法体的方法 所以说它的返回的方法必须是一个非抽象的方法 那么如果C类当中没有这个符合条件的方法 那么它就会对它的C撇也就是C的副类 去调用这个Dispatch 也就是重复这个过程 就是说如果C自己没有这个类没有这个方法 它就去其他的副类去找 然后去重复这个过程 副类的副类 直到它找到第一个满足条件的方法为止 那么这就是Dispatch的过程 那我们看到在方法签名当中 体积而定性作用的就是在于它的名字 以及Descriptor 那么这就是我们用这个函数Dispatch用来 用来模拟动态的 用来表示动态Method Dispatch的过程 那接下来我们来用个例子来 解释一下 或者说考考同学们 看大家有没有掌握这个Dispatch 那么这个例子当中有三个类ABC 那么继承关系就如这个图所示 其中A类自己有个复方法 并且C类复写了这个复方法 那么好接下来这个调用x.foo 那么它的Dispatch的结果 它Dispatch应该是根据这个Receiver的类型 这里是New B 所以它是Dispatch B 再加上这个方法的Coset这一点的签名 那同学们你们在弹幕中打出来看看 这个Dispatch的结果应该是哪个方法 这个Dispatch它的结果 就是对于这个x.foo 它的结果就是A.foo 因为它会去B类 首先对B类自己去Dispatch 但是因为B类没有这个复方法 所以它会去A类里头去找 找到的结果就是A类的复方法 那么接下来再看下面这个调用y.foo 那么y.foo它的Receiver Object 它的类型是C 因为它指向一个New C这个类 那么接下来同学们 考考同学们 那么Dispatch C A.foo 它的结果应该是谁 没错 这个Dispatch C它的结果就是C的复方法 因为它会从C开始去Dispatch 因为它自己就有这个方法 所以它Dispatch的时候 它第一步它就返回了这个C当中的复方法 那么C当中复方法它的签名 它的名字以及它的参数 和它的Descriptor跟A类都是一样的 所以它立体就返回了它要调的复方法 那么好 有了Dispatch 我们接下来可以来介绍 Class Hierarchy Analysis 这个方法简称CHA 那么这种方法是用这种Analysis 是用来解程序当中 Core Graph的一个方法 那么它需要程序当中的信息 就是说它需要整个程序的Class Hierarchy Information 就是说这些类继承的信息 它需要知道每个类它的副类是谁 它的子类有哪些 需要这个信息 那么它的核心思想就是 对于一个Watcher Code 它基于这个Watcher Code 这个Receiver Variable 它的Declare的类型 以及根据这个类型来去解它的目标方法 那么对于这个例子来说 我们看到这有个Cos A点复 那么A这个变量的Declare Type 它的声明类型是A 那么CHA就会根据A的方式 去算它的目标方法 那么具体的思想就是说 CHA它做一个假设 它假设你这个变量A 它可以指向A类 以及A所有子类的对象 就是说它假设你这个A可以 只要是A能指向的对象 这个A它都有可能指 包括A自己以及它所有子类的对象 因此CHA它的 去解它的目标方法的过程 实际上就是 它去查询这个A整个类的继承结构 从这个A和它子类去找的继承结构 来去找它的目标方法是谁 那么具体方法我待会会说 那么这篇论文发表在1995年 发表在 eCoop这个会议上 这个eCoop是欧欧语言它的顶级的会议 那么一座大家可能觉得名字会比较眼熟 Jeff Dean 他就是在谷歌的带领谷歌开发 Mac Produce等这些大工程的大佬 那么他博士期间做的 就是正儿八经的静态分析 包括程序优化 那么这个例子也告诉我们 学静态分析这个前途也是可以很光明的 那么好接下来我们来用一个算法来 来描述这个CHA具体的过程 那么我们定义一个函数ResolveCS 就这个函数本身就是CHA去求解 这个一个Cos它的目标方法的这个函数 那么其中它的参数CS就表示一个Cos 那么一行一行来看这个算法 那首先它初始化了一个变量T 这个T它就是说要装的这个Cos 它的target method 它的目标函 它的目标方法 那么最后算法结果反而也是这个T 那么然后我们取出在这个Cos 调用点是这个方法的签名 因为这个签名我们等一下需要根据 这个签名的信息来算它的目标方法 那么这个算法的结构其实就是由三个 分支来构成 分别对应三种情况 也就是说static call Virtual call和Virtual call 这三种情况 那我们一个一个来看 那首先对于static call 它的这个它的返回 就是说static call它的目标方法 也就是这个写在这个Cos的这个方法 那么我们看右边这个例子 假如说这个class C里头有一个复方法 我们写了一个调用C.复 那么它对应这个Cos它的目标方法 就是这写在这一点的这个方法 也就是C类当中的复方法 这个static call是最简单的 就是非常trivial的 那么接下来是special call 我们前面说到special call 它需要处理三种情况 就是说构造函数 它这个私有方法以及它的傅类方法 那么我们这里以它的傅类的方法为例 来介绍这个special call这种情况 那么假如我们看到这里类型C 里头有个super call 有个super调用 调用了复方法 那么它继承的是C继承自B类 所以说super b,super 傅这一点 它的签名实际上是B类的 复方法的签名 我们看到这里 那么我们要解这个special call 我们首先要取出这个方法M 它的class type 也就是CM 在这个例子当中也就是B类 因为它这里是调用了B类方法 所以它的签名这里是B类 那么接下来我们对这个CM和M方法 做dispatch 那么也就是说我们去B类去找这个M方法 那么有些同学可能心里会有疑问 为什么我们不直接就取它的B类的方法 B类的复方法 而还要做一次所谓的dispatch 这是因为这个super方法 你当使用super的关键字时候 它的傅类B里头可能并没有这个方法 实际上可能B又继承自A 在A里头的复方法才是你真正的目标 所以说当你使用special call的时候 你仍然需要dispatch这么一个过程 去往上从傅类开始找 找它的真正的目标方法 那么我们前面说过 这个special call处理三种类型 它可能是私有方法或者调用构造函数 那么对于这两种情况 实际上它的目标方法M跟steady call一样 就是你写在quotie的签名的M 但是因为我们前面说到需要处理 对于super就找傅类的方法情况的话比较特殊 所以说为了能够处理这三种情况 我们就使用dispatch这个函数来处理special call 而对于私有方法和构造函数的情况 你dispatch的时候 它立马都可以在签名类的方法 调用点这个方法当中立即能够找到 它的目标方法 所以说dispatch可以处理这三种情况 那么又因为dispatch它使用在special call 情况下它使用类它是固定的 对于private就是说私有方法 或者说构造函数的情况下 这个类就是你签名这个类 而对于傅类的话 它的dispatch类就是它super它的傅类 也就是说dispatch给予的类是唯一的\n"
     ]
    }
   ],
   "source": [
    "audio_file_1 = open(\"./11-Audio-Summary/audio/lec07/lec07-0m-26m.m4a\", \"rb\")\n",
    "translation_1 = openai.Audio.transcribe(\"whisper-1\", audio_file_1)\n",
    "print(translation_1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1df28d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所以说它返回的目标方法也是唯一的 这就是为什么我们前面说它的special core 它的目标方法只有一个 并且这个目标方法它是编译器 它就可以确定下来 那么这是处理special core的方式 那么最后我们来看最tricky的处理 处理virtual core的方式 那么我们以这个例子为例 这个class c里头有一个复方法 那么假设我们要处理c.v这个调用 那么它的方式就是说首先它会取出 这个receiver变量它的声明类型 那么这个情况就是说c的声明类型 也就是大写的c 那么它会对这里我们看到它会对c 自己以及c所有的子类都调用 这个dispatch的方式 那么这里的c'表示c或者c子类 当中的任意一个类 它都调用dispatch 并且把得到的结果全部加入到 这个集合t当中 而这里注意一下这个子类 c'不仅仅是c直接的子类 还包括子类的子类 也就是说c所有的继承书上的所有的子类 它都要对它进行一个dispatch方式 那么这种方式也就是说符合我们前面 说到ch的一个假设 它就假设你这个c 它可能可以指向任何c或者c子类的对象 所以它通过这种方式 就把整个继承书上的所有子类 它dispatch的结果加入到了 这个目标函数目标方法当中 那么最后它就返回了这个t 那么这就是ch处理三种meta code的方式 那么接下来再用一个例子来解释 同时也是考考同学们对ch掌握的怎么样 那么在这个例子当中有4个类 a b c d它们继承结构就是右边这个数表示的 其中a自己有个复方法 然后c d的这两个子类又分别复写了复方法 那么好我们这里看这里有三个coresight 我们一个一个来看 首先对于第一个coresight c.f 那么同学们认为用ch去解它的目标方法 应该是谁应该是哪些方法 同学们把自己的答案思考一下 然后把自己的答案在弹幕上打出来 就一位同学答案吗 对答案是c.f 我们看有一些同学的答案里头还包含a.f 那么我们再回过头来看一下具体的方法 就是说你调用watcher 你去解一个watcher core的时候 它是把c和c的子类进行dispatch 就c和c的子类 那么我们看到这个c和c的子类 那c没有子类也就是说 对求解c的时候只能判断它 就只能根据它自己开始 去解它的去调用dispatch 那么因为c自己就有负 所以它的返回的结果就是c.f 那么有些同学问怎么判断是不是虚方法调用 这是说这是根据java编译出来的字节码 就是说它语法可以决定 那么接下来我们看第2个调用 就是说我们看a.f a的说明类型是大写的a 那么同学们思考一下a.f这个调用 如果用chh解它的结果 那么它应该有哪些目标方法 对我看到同学们都打出了正确答案 而这里前面有个同学问是不是为了应对函数返回 负类的状态 我要解释一下 因为这个java的类型系统决定了你 就是说回到刚才我们看c.f的情况 那么c.f就这个c因为是c类型 所以它决定了这个c只能指向c类型的对象 它不可能指向负类的对象 就因为c自己有负方法 所以说它dispatch的结果就必然只有c负自己 所以说这一点它是不可能返回负类的情况 不可能返回负类的负方法 那么接下来同学们再看第3个调用b.f b的类型也就是它的receiver类型就是大写的b 那么b.f同学们想一想它的用chh解它的结果 应该是哪些目标方法 同学们开动脑筋想一想 非常遗憾了 几个同学打出来的答案都是错误的 所以b.f的结果也是acd 有个同学答对了 为什么呢 我们回过头来再看一下 这个chh处理握球扣的方式 我们注意这里它是对 首先它取出这个双名类型c 就是这里的c 它是对c自己以及c所有的子类进行dispatch 注意是c自己 就是这个类自己和它所有的子类 那么再回过头来看这个例子 b.f它的双名类型是大b 那么实际上要对b自己以及c和d三个类型做dispatch 那么对于c和d做dispatch 就是c.f,d.f这个没有问题 那么我们对b类做dispatch的结果是什么呢 假设应该是a.f 因为b自己没有这个复方法 所以它去它的a类去找 所以说对于b,c,d三个类做dispatch的结果是a.f,d.f和d.f 那么再考一下同学们 假如这句话写的b等于6b 那么b.f如果这个调用 如果用chr来解 它的结果应该是什么呢 随便想一想 假如这句话写的就是b等于6b 那么chr的结果是什么 我们看到有些同学给出了正确答案 有些同学给出了错误答案了 注意chr它的 我们还是回过头来看它的算法 chr的方法它是根据c它的声明类型去判断 并且根据它声明类型取出它所有的子类 和它自己进行dispatch的结果 也就是说chr它只考虑变量它的声明类型 换句话说 对于这个情况 即使你代码明明白白写的b等于6b 那么在b.f这一点 chr还是去根据b它的声明类型 也就是大b去解它的目标方法 也就是说对于这个corset 然后corset即使你写等于6b 它的chr它的结果 它还是a.f c.f和b.f 那么当然这也是暴露chr一个问题 就是说c.f和b.f对于这个情况来说 它是假的这个目标函数 它是不程序运行 所以它不会调用这两个方法 那么到目前为止 同学们理解chr的思想 理解就打1 没理解或者说不完全理解就可以打0 我就把你们的问题说出来 就是说你们理解chr 它是具体如何去解一个corset 具体去解一个调用点 算法还有问题 好 我们就回去看 我们把算法再讲一遍 那么我们现在讲chr怎么处理一个watcher call 那么举这个例子来说 就是说b.f 我们看算法 它是首先如果它c corset是一个watcher call 它会取出你这个corset 这个receiver object 就是说receiver边量 这里的c 它会把你的声明类型取出来 你就说这里它声明的c 它首先把这个c取出来 然后它去你这个程序的继承结构去看你c 以及c所有的子类 就是说它把这所有c和继承书上所有子类取出来 然后对这些类都使用dispatch的方式 因为它所有子类 你就可以理解成 它假设你这个c可以指向所有c或者c子类的对象 那么对这些对象的具体的目标方法 也就是对这些相应的类型 对对象的类型去做dispatch的一个过程 来把它所有的可能的目标方法全部取出来 这就是ch它的思想 这就是为什么 它对于a点负b点负这些这样的调用 它考虑着声明类型 比如说a或者说这里的b 根据声明类型去求解它的所有的目标方法 求解的方式也就是说去扫它的子类 去构造去继承书上扫的 去把这些子类全部拿起来 包括它自己 然后去dispatch去取它们的可能的目标方法 那么这就是ch的核心思想 好 如果还有不明白的同学回过头来 在课后再去看科建或者说再复习这一段 那我们继续 好的 好 明白就好 那么我们来讲一下ch它有什么特征 首先它的好处及优势就在于快 因为它只需要考虑你的 这个receiver variable它的声明的类型 然后它就只看你这个类型 然后去查这个继承数就可以了 它求解过程中它不管你data flow control flow 也就是说它不管你这个调用点有什么东西 有什么对象留到你这 它这些信息它都忽略 所以说它可以很快的得到你一个调用点 它的目标方法 那么它的缺点我们刚才看到了 就是它不准 因为它只可它忽略了这些很多信息 这样这个数据流这些信息 所以它比较容易就导致一些假的目标方法 就我们刚才看到的 那么对于这种解决这种缺陷的方法 我们会在接下来几节课说 就是说用别的方法 它可以避免ch方法这种缺陷 通过指针分析的方式 那么大家平时与这种CHA这个距离最近的 你应该就是在IDE里头 就是说大家写代码经常会需要IDE 去问IDE你每个cos可能有哪些方法 那么CHA这个两个特点刚好就决定它比较适合IDE 因为首先你 你query IDE一个调用点 它的目标函数你需要很快得到结果 不然它可能会你写代码的思路可能会被打断 另一方面就是说IDE它给出的结果是给你人看的 所以说你对程序是你是理解的 所以说你不一定会被它的一些给出的 一些假的一些目标函数所干扰 所以说CHA它就非常适合在IDE当中使用 那么我们这里以IntelliJ IDEA做一个例子 那么我们在IntelliJ IDEA里头 打算我们刚才那一段同样的代码 那么我们去问IDE这个b.foo的方法是谁 那么右边 右边的话就是说就是IDE给出的结果 我们可以看到它的code list of foo 就写了hierarchy 那么显然IDE它就是使用CHA的方式 去解它的目标方法 所以它给的它的结果跟我们刚才看到的一样 比如说a c d三个类的符号 它都认为是b.foo它的目标方法 那么同样它也不准 CHA它这里我们看到它也有一些假的目标函数 Steady如果子类调用傅类 如果你调用傅类的话 你会你调用傅类的话 你写的那个Cosine的 你会写傅类的方法 比如说你a继承b继承a 那你子类调你实际上你要调傅的话 你会直接写的a.foo 所以说实际的方法是不存在继承的 那么好我们现在已经看了已经学习如何用CHA 去解一个单个的一个调用点 那么接下来我们来看如何用CHA 构造你整个程序的一个电容图 以至我们看如何给全程序来构造电容图 那么它的步骤其实也比较好理解 那我们构造会从程序的入口方法开始 那么是这里为了简单 就是说你就理解成比如说教育里头的闷方法 就从这些方法作为出发点去构造 一步一步构造你整个电容图 那么你在构造过程中 你会有一些可达的方法 就是说你会发现一些电纹边 那么你根据电纹边 你就可以达到一些新的一些方法 这些就可达方法 你可以理解成在这个图上 电纹图在这里举个例子是个电纹图 这些箭头就是那些电纹边 那么从闷方法可达的 你就认为是可达方法 那么对于每遇到一个可达的方法的时候 它就对于这个方法当中的Coside 使用CHA就是我们前面的Resolve这个函数 对于每个电纹点去解它们的目标方法 那么你解到新的目标方法之后 你把这些边就连起来 然后你又对新的这些方法去重复前面的步骤 就是说你每遇到一个方法 你都用CHA去解这些方法当中 电纹点的目标方法 那么以此往复 直到你把所有可达的方法全部都已经分析完之后 那么这个算法就可以停止 那么你就可以得到一个电纹图 那么对于这个程序来这个例子来说 假如说从这是这些方块 就是程序当中的方法 那么从某个方法开始出发去解 就会形成一些电纹边 并且会达到一些可达方法 那么程序结束之后 算法结束之后 可能就会有一些方法 你没有办法reachable 比如说他们就从来没有可能电纹他们的电纹点 所以说用CHA构造程序当中的电纹图之后 可能会有一些方法是不可达的 那么接下来我们来讲解用CHA构造全程序电纹图的具体的算法 我把这算法名字叫做BuQ graph 那么它的参数就是这个程序的入口方法 那么我们一行一行来看这个算法 首先第一行算法做了一个初始化 就这个算法做了初始化 那么我们看到这里涉及到三个 这个三个集合 三个数据结构 第一个WL它就是worklist 这就是跟李老师前面讲的worklist算法 用data flow算法起到了一个类似的作用 这个worklist里头它存的就是你需要被处理的一些方法 那么最开始我们把这个入口方法加进去 就是说告诉我们一开始你的入口方法就需要处理 那么接下来CG这是一个集合 它就是QGraph 这个集合里头存的就是一个电纹边 就是从一个电纹点到它目标方法这样的电纹边 那么第三个集合RM它就是reachable method的集合 就是说它可达方法的集合 那么一个方法在算法的过程中 它进入了这个集合 表示说这个算法目前已经分析到你了 你就已经可达了 那么这个RM这个reachable方法一个很重要的作用 我们待会会算法也会再看到 就是说一个方法它进入到reachable之后 说明它已经分析过了 它就不需要再对它进行分析了 那么待会我们也会具体看到它起的作用 那么整个算法的它的过程 接下来我们看是一个大的一个while循环 它实际上就是不断的从这个worklist 从这个里头取方法出来 然后处理这个方法 处理的过程中可能又会把一些新的方法 加到这个worklist里头 那么它就重复这个循环的过程 直到你的worklist里头所有的方法你都分析完了 那么我们看循环内部它的这个过程 那么首先就是说从这个worklist取一个方法出来 那么如果你这个方法不属于reachable 就是说你还没有处理过 那么我接下来怎么自己还是会处理它 我待会就会讲具体怎么处理 就是说如果一个方法它已经在这个reachable里头 说明你已经处理过了 我就没有必要再把你处理一遍 那么这个时候就直接会循环 这一次循环就会结束到下一次循环 这么一个过程 那么好我们接下来看它是如何处理一个新的方法 那么首先拿到一个方法 你不是reachable 那么我遇到你了 那么我现在知道你可达了 我就把你加入到这个集合当中 然后对于这个方法m 这就是我们前面从worklist取的方法 对这个方法m 我们把你这个m里头所有的core set全部取出来 对于你每一个core set 我们都用刚才我们前面讲过的resolve CHA的方法 把你的目标方法全部取出来 那么我们知道你取出来之后 这些t就是前面目标方法的集合 那么t里面就是你的目标方法了 那么接下来我们要做就是说 你现在就把这个core set到目标方法 np 这个np就是集合m里面t里面的目标方法 就把这些core set到它目标方法这些边 加入到cg 就是加入到core graph里头 那么这就是说我们core graph里面加边了 逐渐的构造core graph 那么对于每个方法加上边之后 我们还知道就是说你现在又发现了一个新的方法 就发现了一些方法np 这些方法可能是你前面没有处理过的方法 所以说为了将来我要处理你 就是说我也要处理你np里面的方法 那么这里我们就需要把np也加到 这个worklist当中 换句话说我们在建 这个调一边建构造图的过程中 我们也会逐渐一些发现一些新的方法 然后我们会把这些方法加到这个worklist里头 然后我们在后面的循环当中 又会把这些新的方法取出来一个一个处理 一直到我们把所有可达的方法处理完之后 那么我们算法就会停止 最后就会返回 这个core graph 也就是说把这些调一边构成的集合把它返回 那么这就是这个core graph 这个构造它的算法整个过程 那么接下来我们用一个具体的例子来讲这个过程 然后让同学们更好的去理解 整个程序的电量图是怎么一步一步用 解决的方式去把它构造起来 那么在这个例子当中有 要不同学们先休息5分钟 然后回来我们来接着上课\n"
     ]
    }
   ],
   "source": [
    "audio_file_2 = open(\"./11-Audio-Summary/audio/lec07/lec07-26m-52m.m4a\", \"rb\")\n",
    "translation_2 = openai.Audio.transcribe(\"whisper-1\", audio_file_2)\n",
    "print(translation_2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_3 = open(\"./11-Audio-Summary/audio/lec07/lec07-52m-78m.m4a\", \"rb\")\n",
    "translation_3 = openai.Audio.transcribe(\"whisper-1\", audio_file_3)\n",
    "print(translation_3['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c08b819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个数据流a等于6 表示a这个variable它是值 现在是一个constant是6 那么这个信息它就会传到下一个节点 b等于n1 也就是说它的inflow就是a等于6 那么我们对这个字句语句做transform 它的结果还是a等于6 我们前面提到过对于一个调用 我们要把它的left hand side variableq掉 但它的这个时候b的进来也没有值 就说它出来的 它不影响outflow这个情况 也就是说这个语句 它的outflow还是a等于6 那接下来 我们要处理 这条call edge我们看到吗 call edge 我们前面说到对于常量传播来说 call edge它的transform是要传递 传参数 所以说对于这条edge 我们的edge transfer function 就是说让x也就是它的 行参x的值就等于a的值 所以说这就是它的这条edge transform 这个东西我们在过程内分析是没有的 因为它没有这样的edge 过程间分析我们需要处理这个数据流通 一个方法流到另一个方法之间 我们要处理这个过程 那么对于常量传播的时候 这个会引起参数的值的一个传播 所以我们要处理 这个传参 这就是我们的这条边edge transfer 那么参数传过来之后 我们得到它的flow了 那就是x这时候x等于6了 因为x它的参数来自于a x就等于6 那么我们接下来继续做数据流传播 那么这个entry node 它没有任何语义 所以它出来的outflow跟 这个inflow是一样的 那么这个inflow就传到了y等于x等于加1 那么这个时候我们还是同样 就是说还是用普通的 我们前面学的node transfer 得到的结果就是说 x等于6 那么接下来我们要产生新的一个 产生了新的这个data flow 也就是说现在我们知道y等于7了 那么就接着把这个值往下传 那么好 现在我们来到了return 语句的结尾 我们前面说过 core edge要有transfer return 语句也要transfer 那么现在同学们你们思考一下 这个return edge的transfer应该是什么 同学们把你们的 先思考一下 然后把你们的答案打在弹幕上 你们可以参考core edge的方式 来想一想return edge 它应该它要传return value 它应该长什么样子 好 我看到有同学已经打出正确答案了 就是b等于y的value 因为他知道 y的value实际上是要负给b的 所以他回到返回点的时候 他要把y的value传递给b 也就是b等于y的value 因为有一位同学还打了一个a等于value x 这是不对的 为什么 因为return这个语句 它只会影响b的值 它是没法影响a的值的 所以a的值的话 它这个return edge的 它的转换函数是不能修改a的值的 也就是说它只有b等于y的value 那么这里我要解释 我要回答 对 它就是它这个return edge 它只考虑你最后return的东西 它不考虑别的东西 这里要回答一下 刚才可能留下的疑问 就是说为什么我们还需要这条边 就是说从一个core side到 它返回return side这条边 那么在ICFG当中 我们把这样的边 就是从core side到return side这样的边 我们把它起名叫core to return edge 而产量传播它是直传递 有同学提到它是直传递 那么core to return edge的话 我这里简单点只考虑直传递的情况 你用传递那确实比较复杂 我们这里只考虑直传递的情况 那么这样的边 我们把它叫做core to return edge 那么这样的边 它可以让我们去传播local 本地的数据流 在ICFG上传播本地的数据流 那么什么叫本地的数据流 你就可以理解成这个函数内部 就是函数自己内部的数据流 在这个例子当中 a等于6 这个local的数据流 就是我们要顺着这条边要传播的 为什么是local的 因为这个a它是说明在这个方法们内部的 别的函数是访问不了它 所以它的范围只能在local里头 就是local variable 那么有这个core to return edge 我们就可以顺着这个edge传播 local的本地的数据流 但假如我们把这个边拿走 把这个边删掉 那么如果没了这条边 我们就需要把这个数据流 绕着就是说让它穿越到别的方法 就像出国了 别的数据出到别的方法 出国了 远渡重洋 绕一圈 然后才能回到祖国的怀抱 回到它下面那个return side 那么这种做法是非常低效的 因为我们可以看到为了传播这个数据流 a等于6 它会就是说它去到目标方法中的 每一个语句的flow这里头 它都得它要顺着这些flow 每个点的flow要顺着它一直传过来 然后才能回到这个回到这个返回点 那么因此它的目标方法 每一个点的flow它都有额外的负担 它都增加了这个a等于6的信息 但实际上这是完全没有必要的 这也是不该传出去的 因为这是本地的信息 按理说它不应该传到别的方法 因为这只会带来性能上的负担 所以在实际方法就实际的 我们做这个过程间分析的时候 我们总是会保留这条边 那么有了这条边 我们就可以传播本地的这个数据流信息 这样的话就避免它留到一些它不该留的地方 然后造成性能上的一些负担 那么底下这条边也是同理 就是所有的所有的call to return edge 都是为了这个目的 我们把它留下来 留下来之后 我们就可以做这个本地的传播本地的数据流 那么接下来我们看到这个这句话 c等于b.3 那么它的数据流a等于6流过来 b又等于y的value也是7 b等于7流过来 所以它的inflow 也就是说这两个数据流的汇合 也是a等于6 b等于7 那么接下来就继续做 n1的x被修改 这个不影响 x被修改 它只是x是n1的本地变量 它被修改了 它本地修改 它被修改不会影响到外面的地方 那么继续做 那么接下来我们做这个继续做数据流分析 那么我们还是用我们前面学上一节课学的 这个no transfer 对于这句话c等于b.3 那就做一个普通的no transfer 我们就知道现在c它也是一个常量 我们得到它的值等于4 7-3等于4 所以说它的offload就有了 新加了一个c等于4 这么一个信息 然后接下来往下传到了b等于10 那么好 我问一下同学们 那么b等于10它的offload应该是什么呢 就它的b等于10这个蓝色它的outflow应该是什么内容 对我们就是我们前面说到要把b的q掉 也就是最后得到的结果 a等于6c等于4 我想问一下同学们知不知道为什么这么做原因 思考一下想想为什么要把b的q掉 没错 就是前面其实也解释过了 b的值它会顺着return edge过来 那么接下来看 那么这时候控制流进到n10里头 因为没有参数 所以不需要transfer 它没有参数 必须要不需要传参 并且它也没有变量 所以说没有什么outflow 那么这时候它的返回 这个返回我们接下来顺着走到返回边 我们要处理它返回边 它的edge transfer 因为它总是return 10 所以我们就可以直接确定的写它的返回的函数 就是b等于10 那么这个b等于10 这个边它会和local的边这个数据流汇合 汇合之后就是a等于6 b等于4 那么如果我们不把这个b的值q掉 就前面b的值q掉 有同学说讲合并的规则 合并规则跟我们之前学的 你们以前学的肯定photograph一样的 它也是把这些边 这些传过来的数据流 join 用join操作把它汇合起来 因此如果我们保留b等于7 在b等于10这句话结尾保留b等于7 那么b等于7这个信息会跟b等于10 这两个数据流汇在这个地方交汇 这两个一join的话 它就会认为b它不是一个content 但实际上b它就是一个content 因为b等于7这个值不应该从上面留下来 这就是刚才有个同学说的 它是应该被返回值覆盖的 所以为了做到这 就是它如果不覆盖它就会导致这个 丢失精度 所以说为了实现这一点 我们会把我们前面会把这个b的值把它q掉 这样的b唯一的值就是它来自于返回值 也就是它真正的值 这样的话就可以避免一些精度上的一些损失 那么到了最后 这句话结束之后 c等于a乘b我们再做一个transfer transfer跟我们之前做的是一样的 前面学的一样的 那就是说对它做个常量的一个计算 a跟b都是常量 所以a乘b等于60 那么就这样我们这就是 这个程序的过程间 常量传播它的结果 然后我们在走这个例子的过程中 我们也理解了 就是说在call edge你要做什么transfer 你在return edge你需要做什么transfer 为什么我们需要保留这些call to return的边 为什么要保留它 以及为什么要在call之后 把left hand side variable的值给q掉 就是说这个例子把这些点都有覆盖到 那么在这个例子大家都理解了吗 有什么有没有什么不明白的地方 理解的话就打1 那么这里要点题回到我们这个开始故事的开始 假如我们对这个程序做 用我们以前的方式做过程内分析 那么会得到什么结果 首先过程内分析它就没有这些call 不是ICFG它就三个CFG 那么前面最开始的时候 这些课就开始有提到过 在做过程内分析的时候 如果遇到方法调用 遇到函数调用 我们是做最保守的假设 比方说对于这个b等于n1这么一句调用 我们因为过程内分析 它不会分析n1里头做什么 它就要假设你n1可能 add1可能会返回任何的值 所以作为最保守的假设 过程内分析它会认为 b等于n1 constant 你可以返回任何值 所以肯定不是一个constant 那么这些值传到下面之后 这就是一个不precision的来源了 那么这个来源会随着数据流传播 会到处传播的 我们看接下来传到下句话 c等于b-3 因为我们认为过程内分析认为 b它不是constant 所以b-3的结果也不是constant 所以说这个时候它会认为 b跟c它都不是constant 那么这个信息就会往下传 并且传到另外一个调用 同样它也认为你b不是constant 继续传 那么传到最后这个函数 最后我们就只有a是一个constant 这个过程内的常量传播会认为只有a 是常量 b跟c都不是常量 这就显然不准了 那么我们对于这个 a1这个方法也是一样的 我们在做过程内的常量传播的时候 我们遇到一个 那么最开始它有个参数x 因为它不分析 方法调用 所以它要假设它做最保守的假设 就是你x可能是你别的方法给你传来任何值 所以x也肯定不是常量 这是它过程内分析的假设 那么x不是常量 它的导致结果这里 y等于x加1 它也认为你y也不是常量 所以说对于这个函数的过程内分析 整个就是说认为你全都不是常量 但我们回到这个程序当中 我们可以看得很清楚 唯一传给x的值只有一个a 就是6 x肯定是常量 y也肯定是常量 但是我们做过程内分析的时候 因为对于函数方法调用做了最保守的假设 或者说最坏的假设 所以我们在做过程内分析的时候 我们为了safety safe approximation 就假设这些返回值以及参数都不是常量 所以我们就会得到的结果就不精确 但是我们做回到这 但是我们对比过程间分析 我们会确实的把我们在每个函数内部分析 得到的信息会传到别的函数去 这样的话它就不需要做假设 就你传给我是啥 就是啥我不用假设 所以说过程间分析就可以得到比过程内分析 更加精确更加准确的结果 这就是为什么我们需要学习过程间分析 因为它可以克服 或者说解决过程内分析的一些 精度上的一个缺陷 那么以上就是这一课的主要内容 那么在这一课中 你需要掌握以下几个知识点 第一个是重点要掌握 就是说你要理解到底如何通过CHA 去给一个程序建一个core graph 这个是重点 这一课的一个重点 因为我们把具体的算法我们都 我们都讲出来都学习了 那么接下来你需要掌握ICFG的概念 就是说interprocedural control graph 就是它是怎么建的 它里头应该有哪些要素 其实其实我想这个也比较简单 就是大家前面都看到 它你就可以理解成 ICFG就是每个函数的每个方法的CFG 然后用core edge和return edge 把它们串联起来 那么在这个基础上 你就要理解过程间数据分析的一个概念 就是说这里不要求掌握 你具体怎么去实现 这个不需要你去掌握 但你需要掌握 就是说一个过程间分析 它大概需要处理有哪些关键的地方 它与过程内分析有哪些区别 一个是需要同学们去理解的 那么最后就是说还 我们还讲你要学习同学们要理解 这个过程间的产量传播是怎么做的 它是主要重点是它怎么处理 函数调用和函数返回 以及怎么处理在一些关键的地方上 怎么去处理它值的变化 那么这个就是以上的这些课的重点内容 你要掌握的一些知识点 那么在后面的课程中 我们会学到以下两个跟本节课内容相关的内容 首先是接下来我会讲指针分析 指针分析它是下节课就开始讲了 就是说你可以理解成这是最基础的一个进展分析 那么指针分析它可以用来 建core graph 而且它可以建比CHA更准的core graph 这只是它的其中一个用途 指针分析有非常多用途 那么但是它这一点是建CHA这个课程 跟这些课是有关联的 另外一个后面李老师会给大家讲 一种通过graph reachability 就是说用图可达性的方式来 做过程间数据流分析的这么一种方式 那么这种技术对于一类问题叫FDS problem 就是你现在必须要理解 你就知道对于这类问题 用图可达性的方法可以非常 就是说可以既精确又高效的求解出 可以做过程间的数据流分析 这是我们后面还会学到的 像在这节课我们没有定表学习一个具体的算法 怎么做过程间数据流分析的算法 但是在后面我们学着李老师讲的console 他会告诉大家怎么具体的做实现一个 就是说具体的做一个用图可达性的方式 做数据流分析过程间的数据流分析 那么以上就是今天要讲的内容 同学们有什么问题可以关于这个课程 今天这门课的课程的可以问 你可以交流一下 还有一点时间 同学问的问题很好 一下就问到了一个比较关键的问题 就是说如果这样多次的话 就是说如果这样多次的话 你的意思就是说他可能对 就是说他每次参数不一样的话 他可能就不是constant 那么这个问题实际上 后面只能分析包括李老师讲的方法 都会解都会处理你说的问题 就是说假如我们就直接做普通的分析 像我这么这节课给大家讲的话 如果add1掉用次数多次每次给他传不一样的值 那他这些值会会会合起来 他就认为你不是 你不是constant 但是有一种技术叫做上下文敏感技术 context sensitivity 那么用那种技术的话 他的思想会在就是说会你这么理解 对于每次调用的数据流他会分开分析 那样的话他可以得到一个 他可以一定程度上可以避免这个问题 就是说他每次调用就有产生不同上下文 他的思想就是说不同上下文 他就给你分开分析 这样的话他在每个上下文里头 他还是一个constant 那么具体的方式包括指针分析也会 涉及到这个问题 所以说我们会在后面的课程当中 学习到我们怎么处理这样的问题 同学问的问题非常好 一个cos有多个target怎么做闪亮传播 那就把这个cos到每个target的边都连起来 也就是他传 这coedge他会一个边会生出多个coedge 然后他就把实参的值会顺着 这多个coedge一起传出去 CHA的special call 同学可以把问题具体说一下 地归函数怎么处理 地归函数的话还是正常处理 你这么理解就是说如果有地归函数 那么ICFG上会形成环 那么形成环 我们还是照样做数据的传播 那么你可以就类似于理解 你做constant propagation里头 碰到loop怎么办 或者就是说过程内分析碰到loop一样 我们还是顺着边去传播 只不过顺着图去传播 然后传播到fixed point为止 没有问题的话就准备下课 那这一课就到这里 同学们再见 下周见 本职工作 请打开注意 大家再见\n"
     ]
    }
   ],
   "source": [
    "audio_file_4 = open(\"./11-Audio-Summary/audio/lec07/lec07-78m-end.m4a\", \"rb\")\n",
    "translation_4 = openai.Audio.transcribe(\"whisper-1\", audio_file_4)\n",
    "print(translation_4['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a1a80",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08cd4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert on Warren Buffett and good at creating summaries.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize the following transcript into key bullet points:\\n{transcript['text']}\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f956f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- People often get taken advantage of in financial transactions\n",
      "- Frictional costs and unnecessary charges are a big problem\n",
      "- Warren and Charlie have had good luck buying businesses and trusting people, but they filter out a lot of people\n",
      "- People often give themselves away, and it's important to assess individuals accurately when buying businesses\n",
      "- They can't identify every fraud, but there are certain ones that jump out\n",
      "- Warren has seen frauds in financial statements, especially with loss reserves\n",
      "- Promoters often play games with the numbers\n",
      "- There are many accounting games played, and adjustments are made to make the company appear to be earning more than it really is\n",
      "- Private equity firms often add percentages to projections to offset Warren's perceived conservatism\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1022fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_summarizer(audio_file_path,system_prompt):\n",
    "    audio_file = open(audio_file_path, \"rb\")\n",
    "    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Summarize the following transcript into key bullet points:\\n{transcript['text']}\"}\n",
    "        ]\n",
    "    )\n",
    "    print(response['choices'][0]['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
